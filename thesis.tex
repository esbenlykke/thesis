% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  9pt,
]{scrbook}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[]{EB Garamond}
  \setsansfont[]{Montserrat}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=20mm,paperwidth=17cm,paperheight=24cm]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{caption}
\usepackage{longtable}
% Page setup and typography
 \usepackage[margin=20mm, paperwidth=17cm, paperheight=24cm]{geometry}
 \pagestyle{plain}
 \usepackage{sectsty}
 \allsectionsfont{\sffamily}
 \usepackage{multicol}

 % Landscape handling
 \usepackage{lscape}
 \newcommand{\blandscape}{\begin{landscape}}
 \newcommand{\elandscape}{\end{landscape}}

 % Captions and listings
 \usepackage[font=small,labelfont=bf]{caption}
 \captionsetup{font=footnotesize}
 \usepackage{longtable}

 % Other utilities
 \usepackage{pdfpages}
 \usepackage{hyperref}
 \usepackage{afterpage}
 \usepackage[nottoc,numbib]{tocbibind}
 \newcommand{\aftertocpagenum}{
   \cleardoublepage
   \pagenumbering{arabic}
 }

 % Continuous numbering for figures/tables
 \usepackage{chngcntr}
 \counterwithout{figure}{chapter}
 \counterwithout{table}{chapter}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  colorlinks=true,
  linkcolor={DarkSlateBlue},
  filecolor={Maroon},
  citecolor={DarkSlateBlue},
  urlcolor={DarkRed},
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}
  \frontmatter
  
  
\pagenumbering{roman}

\includepdf[pages=-]{titlepage.pdf}

\newpage

\textsf{\textbf{\Large{Supervisor}}}

\vspace*{\baselineskip}

Associate Professor Jan Christian Brønd, PhD

Research Unit for Exercise Epedimiology, Centre of Research in Childhood Health, Department of Sports Science and Clinical Biomechanics, University of Southern Denmark, Odense, Denmark

\vspace{2cm}

\textsf{\textbf{\Large{Assessment Committee}}}

\vspace*{\baselineskip}

\textbf{Chair}

Professor WSR Jasper Schiperijn, PhD

Research Unit of Active Living, Danish centre for motivation and behaviour science, Playground Research, Department of Sports Science and Clinical Biomechanics, University of Southern Denmark, 5230 Odense, Denmark

\bigskip

\textbf{Opponents}

\begin{multicols}{2}

Associate Professor Samuel Emil Schmidt, PhD

Department of Health Science and Technology, Aalborg University, Denmark

\columnbreak

Associate Professor Alex Rowlands, PhD

Diabetes Research Centre, NIHR Leicester Biomedical Research Centre - Lifestyle Theme, University of Leicester, United Kingdom

\end{multicols}

\vspace{2cm}

\textsf{\textbf{\Large{Funding}}}

\vspace*{\baselineskip}

The research presented in this thesis was generously funded by TrygFonden, under grant numbers ID 130081 and 115606, and by the European Research Council, under grant number 716657. Additional support was provided by a one-year scholarship from the Faculty of Health Sciences, University of Southern Denmark.

\newpage

%----------------------------------------------
  %   Preface
%----------------------------------------------
  
\textsf{\textbf{\Large{Preface}}}

\vspace*{\baselineskip}

The present thesis delves into the objective measurements of physical behavior and sleep, a subject that has captivated me since my Master's program. This work represents a fulfilling journey marked by exploration, discovery, struggles, and both personal and professional growth.

The thesis is based on data from several different studies and is the product of collaboration with numerous internal and external co-authors. It employs machine learning and advanced statistical methods on accelerometer data to bring new insights into the field of sleep and physical behavior.

This thesis comprises three distinct papers, each focusing on improving and validating methods for leveraging accelerometer data in the study of human behaviors—particularly sleep and physical activity. Each paper applies innovative methods, such as machine learning techniques, to enhance the utility, reliability, and accuracy of free-living accelerometer data in large-scale studies. Two of these papers have already been published in peer-reviewed journals, and the third is under preparation. These works are integral to this thesis and are included as appendices.

My research journey began during my Master's program, where I was introduced to the capabilities of accelerometer data. This early exposure culminated in the publication of my Master's thesis and solidified my desire to pursue a career in research. Embarking on my PhD, I faced a series of challenges. Initially, my limited experience with programming and machine learning posed a steep learning curve. However, persistent effort enabled me to acquire the necessary skills for data analysis. A significant hurdle arose during the data collection phase of my main paper. I attempted to collect overnight polysomnography data, along with readings from multiple accelerometers and wrist photoplethysmography, from 55 children in their homes. Regrettably, the sensitive nature of EEG electrodes did not mix well with children, resulting in data that was largely unsuitable for model development. Fortunately, I could turn to the SCREENS trial for alternative data, allowing me to complete the third paper.

The PhD experience has fundamentally shaped my approach to work and life, instilling in me qualities like discipline, precision, and a keen attention to detail. This journey has been as much about professional development as it has been a personal voyage of self-discovery and growth.

As I stand on the threshold of new beginnings, I am filled with excitement about the future possibilities. This thesis reflects the lessons and experiences gathered along the way and serves as a stepping stone for further exploration in this rapidly evolving field.

Enjoy reading.

\newpage

%----------------------------------------------
  %   Acknowledgement
%----------------------------------------------
  
\textsf{\textbf{\Large{Acknowledgment}}}

\vspace*{\baselineskip}

As I reflect on the transformative journey that my PhD has been, I find myself indebted to numerous individuals whose support, guidance, and inspiration have been instrumental in shaping both my professional and personal growth.
First and foremost, I extend my deepest gratitude to my Main Supervisor, Jan Christian Brønd. Your unwavering guidance and patience have not only nurtured my development as a researcher but also as a lecturer. Our collaborative dialogues, whether they took place in the office or during examinations, have been a cornerstone in my academic development.
To my co-supervisors, Anders Grøntved and Niels Christian Møller, your expert insights and unique perspectives have enriched my work immeasurably. My gratitude also extends to my colleague Jesper Schmidt-Persson, whose contributions have consistently elevated the quality of my research.
Being part of an internationally recognized and experienced research group has been an enriching experience. It afforded me the privilege to work alongside some of the most brilliant minds in my field. This collective experience has not only broadened my understanding but also contributed significantly to our shared goal of advancing knowledge in our discipline.
At the core of this journey has been the unceasing support of my family. To my wife, who has been the bedrock of our family, your constant support and curiosity about my work have been my emotional mainstay. The joy and love I've received from our four children have been ceaseless fountains of inspiration and motivation.
This PhD journey has taught me more than just academic rigor; it has molded my approach to work and life in ways that are ineffably valuable. The discipline and precision inherent in research have permeated my daily life, influencing my problem-solving and decision-making processes. This endeavor has been much more than an academic pursuit; it has been a voyage of self-discovery.
Whether it was solving a complex analytical problem, having my work accepted for publication, or receiving positive feedback, such milestones have fueled my motivation and are poignant reminders of the impact and importance of my work.
In conclusion, I want to express my heartfelt gratitude to everyone who has supported me through this transformative period of my life—supervisors, colleagues, friends, and family. Your faith in my abilities and continuous encouragement have been the backbone of this journey, and I hope that the work presented in this thesis is a testament to that.

I am incredibly grateful for all the support and wisdom I have been fortunate to receive, and it is my earnest hope that this thesis stands as a tribute to each of you. Thank you.

\newpage

\textsf{\textbf{\Large{Included Papers}}}

\vspace{2cm}

\begin{center}

Paper I

\textsf{Manual Annotation of Time in Bed Using Free-Living Recordings of Accelerometry Data}

published in \href{https://doi.org/10.3390/s21248442}{Sensors}

\vspace{2cm}
Paper II

\textsf{Generalizability and Performance of Methods to Detect Non‑Wear with Free‑Living Accelerometer Recordings}

published in \href{https://doi.org/10.1038/s41598-023-29666-x}{Scientific Reports}

\vspace{2cm}
Paper III 

\textsf{Improving Sleep Quality Estimation: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking}

In preparation for \href{https://academic.oup.com/sleep}{SLEEP}

\end{center}\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables
\mainmatter
\aftertocpagenum

\hypertarget{english-summary}{%
\chapter{English Summary}\label{english-summary}}

\textbf{Introduction}

Sleep is an important element in promoting health, and the
quantification of sleep has been improved with modern technology.
Polysomnography, considered the gold standard, provides in-depth insight
into sleep but is costly. In contrast, accelerometry is a cheaper and
less invasive method, especially for longer home-based recordings.
Machine learning is a tool that has the potential to automate and
facilitate the estimation of sleep from accelerometer data. However,
there are three challenges: producing reliable training data, ensuring
data integrity through accurate removal of non-wear, and effectively
using data to estimate sleep. Firstly, it is necessary to have
sufficient and accurate annotations in the data for effective machine
learning, emphasizing the importance of methods for manual annotations
based on accelerometer data. Secondly, it is essential to detect and
remove periods when the device is not worn to perform accurate analyses.
Identifying periods of non-wear is challenging, as traditional methods
like logbooks can be prone to bias. Existing algorithms removes bias,
but their accuracy is still debated. Finally, once data is correctly
collected and processed, it is crucial to apply it effectively. Current
methods for estimating sleep using accelerometers are based on data from
wrist-worn and hip-worn devices, while data from thigh-worn
accelerometers remains largely untapped for sleep estimation.

\textbf{Aims}

This thesis has the following objectives. Firstly, we will assess the
accuracy of manual annotation of bedtime in raw accelerometer data
compared to EEG-based bedtime and sleep diaries. Secondly, we will
assess heuristic algorithms and machine learning models for detecting
non-wear. Finally, we will develop machine learning models for sleep
classification and the estimation of sleep quality metrics using data
from thigh-worn accelerometers and compare them with EEG-based sleep
recordings. Overall, this thesis aims to understand the potential and
challenges of using machine learning to estimate sleep via
accelerometry.

\textbf{Methods}

Data for the papres in this thesis was sourced from the SCREENS pilot
trial (Paper I), the Physical Activity in Schools After the Reform
(PHASAR) study and an in-house validation study (Paper II), and the
SCREENS trial (Paper III). All accelerometer data were collected using
the Axivity AX3 triaxial accelerometers and sleep was recording using
the EEG-based Zmachine® Insight+ alongside sleep time diaries, with
parents documenting for their children. Data for Paper I consisted of 14
children and 19 adults. Participants wore the accelerometers for a week
on their right hip and thigh. Simultaneously, EEG sleep recordings and
sleep time diaries were collected. Utilizing Audacity, an open-source
audio editing software, three raters annotated each accelerometer
recording, marking in-bed and out-of-bed timestamps, and conducted two
rounds of annotations for reliability testing. The ground truth was
based on EEG sleep recordings. Nights with sensor issues at recording
starts or ends, were excluded. Agreement was measured using the
intraclass correlation coefficient (ICC) and Bland--Altman analysis.
Paper II employed accelerometer data from sensors placed on the wrist,
thigh, and hip. Raw data from 64 PHASAR participants and 42 participants
of the in-house study was examined, with non-wear episodes manually
annotated similarly to the methodology outlined in paper I. Decision
tree models, developed from hip and thigh data, used 12 features derived
from the acceleration sensor data. Training employed 79.2\% of this
data, using the remaining data for testing. Model hyper parameters were
optimized through a five-fold cross-validation. Three models were
evaluated against benchmark methods: one decision tree trained on all
features, one utilizing the six most important features, and one
omitting skin temperature. External validation was performed on the
wrist data from 42 participants of the in-house validation study. All
models were evaluated using metrics derived from confusion matrices.
Paper III of this thesis analyzed acceleration and sleep data from
children aged 4-17 (mean age: 9.1 years). We categorized the EEG-based
sleep data output into ``awake'' and ``asleep'', simplifying the
classification task. Data preprocessing involved a low-pass Butterworth
filter, non-wear data exclusion, and feature extraction, yielding 64
features from accelerometer and temperature signals and
sensor-independent features. The sleep recordings underwent 5-minute and
10-minute median filtering before model training to better capture true
awakenings. We employed two modeling strategies. The first utilizing a
sequential approach with binary classifiers. After predicting `in-bed'
time this data was extracted and then served as input to the second
model in sequence further used for predicting sleep whilst in bed. We
utilized four machine learning algorithms for this approach: Logistic
regression; decision trees; single-layer feed-forward neural networks;
and XGBoost. The second strategy utilized a bidirectional Long
Short-Term Memory (biLSTM) neural network as a multiclass classifier,
predicting three classes, ``out-bed-awake'', ``in-bed-awake'', and
``in-bed-asleep''. Data for the four pairs of sequential models, was
split into training and testing sets, ensuring data from the same night
wasn't in both sets. Hyper parameter optimization was done using 10-fold
Monte Carlo cross-validation. After determining the best
hyperparameters, models were fitted to the entire training set. A data
imbalance issue was corrected on the extracted in-bed data with the
awake class only constituting about 15\% of training data using the
synthetic sinority over-sampling technique. The F1 score was our
optimization metric. Separately, data to train the biLSTM model was
divided into a 50/25/25 split for training, validation, and testing. The
Adam optimizer and cross-entropy loss function were used. Performance
was tracked using the F1 score, and early stopping was employed. To
assess performance on all models, we used standard metrics derived from
confusion matrices. To understand our models' effectiveness in
estimating sleep quality metrics, we utilized Bland-Altman plots and
Pearson correlations. Sleep quality metrics, following ZM definitions,
included Sleep Period Time (SPT), Total Sleep Time (TST), Sleep
Efficiency (SE), Latency Until Persistent Sleep (LPS), and Wake After
Sleep Onset (WASO).

\textbf{Results}

In paper 1, we compared manual annotations with the ZM and sleep
diaries. The results indicated excellent inter- and intra-rater
agreement. Furthermore, the Bland--Altman limits of agreement were
approximately ±30 min, showcasing only a minimal mean bias. In paper 2,
our focus was on non-wear detection. For non-wear periods longer than 60
minutes, the established consecutive zeros algorithms were the most
effective, registering F1-scores above 0.96. However, for durations
shorter than 60 minutes, decision trees stood out, achieving F1-scores
of over 0.74 across all sensor locations. Notably, the newly developed
deep learning and random forests models couldn't match these
performances. Paper 3 delved into sleep classification and the
estimation of sleep quality metrics using thigh-worn accelerometers.
Here, the XGBoost model excelled, especially when analyzing 5-minute
filtered data. The model demonstrated small discrepancies in several
sleep metrics: sleep period time (0.2 minutes), total sleep time (-7.0
minutes), sleep efficiency (-1.1\%), and wake after sleep onset (-0.9
minutes). Additionally, this model exhibited a strong correlation of
0.66 with total sleep time. It's worth noting that the limits of
agreement in our findings mirrored those in previous studies on hip and
wrist devices. Specifically, total sleep time exhibited LoAs of
(95\%CI): -95.5 (-105.2 to -88) minutes to 81.4 (72.4 to 92.5) minutes.

\textbf{Conclusions}

Overall, the findings of this thesis underscore the reliability and
precision of emerging technological methods in sleep and non-wear
detection research. Paper 1 validated the credibility of manual
annotation techniques, reinforcing their alignment with traditional
benchmarks. Paper 2 emphasized the nuances of non-wear detection,
revealing clear strengths in certain algorithms for specific durations
and highlighting areas where newer models need enhancement. Paper 3
highlights the XGBoost model for sleep assessment with thigh-worn
accelerometers, situating it as a valid alternative compared to methods
machine learning models employed on thigh and wrist accelerometer data.
However,challenges remain in identifying in-bed awake periods and in
assessing individual sleep quality metrics, consistent with previous
findings from wrist and hip-worn devices.

\hypertarget{dansk-resume}{%
\chapter{Dansk Resume}\label{dansk-resume}}

\textbf{Introduktion}

Søvn er et vigtigt element i sundhedsfremme og kvantificeringen af søvn
er blevet forbedret med moderne teknologi. Polysomnografi, betragtet som
guldstandarden, giver en dybdegående indsigt søvn, men er
omkostningsfuld. Omvendt er accelerometri en billigere og mindre invasiv
metode, især til længere optagelser i hjemmet. Maskinlæring er et
værktøj, der har potentialet til at automatisere og lette arbejdet med
at estimere søvn fra accelerometridata. Dog er der tre udfordringer: at
producere pålidelig træningsdata, sikre integriteten af data og
effektivt bruge data til at estimere søvn. For det første er det
nødvendigt at have tilstrækkeligt med nøjagtige annotationer i data for
effektiv maskinlæring, hvilket understreger vigtigheden af metoder til
manuelle annotationer baseret på accelerometridata. For det andet
essentielt at detektere og fjerne perioder, hvor apparatet ikke er
båret, for at udføre korrekte analyser. Det en udfordring at
identificere perioder, hvor apparaterne ikke bæres, da traditionelle
metoder som logbøger kan være fejlbehæftede. Eksisterende algoritmer kan
forbedre denne detektering, men deres nøjagtighed er stadig genstand for
debat. Endelig, når data er blevet korrekt indsamlet og bearbejdet, er
det afgørende at anvende det effektivt. Nuværende metoder til at
estimere søvn ved brug accelerometre er baseret på data fra håndleds- og
hoftebårne apparater, mens data fra accelerometre, der bæres på låret,
stort set er uudnyttede i forhold til at estimere søvn.

\textbf{Formål}

Denne afhandling har følgende formål. For det første vil vi vurdere
præcisionen af manuel annotation af sengetider i accelerometridata
sammenlignet med EEG-baserede sengetider og søvndagbøger. For det andet
undersøger vi algoritmer og maskinlæringsmodeler til at detektere
perioder, hvor accelerometeret ikke er båret. Endeligt vil vi udvikle
maskinelæringsmodeller til søvnklassifikation og estimering af
søvnkvalitetsmål ved brug af data fra accelerometre, der bæres på låret
og sammenligner med EEG-baserede søvnoptagelser. Samlet set søger denne
afhandling at forstå potentialet og udfordringerne ved at anvende
maskinlæring til at estimere søvn via accelerometri.

\textbf{Metoder}

Data til artiklerne i denne afhandling blev indsamlet fra SCREENS
pilotundersøgelsen (artikel I), Physical Activity in Schools After the
Reform (PHASAR) studiet og en intern valideringsundersøgelse (artikel
II) samt SCREENS-undersøgelsen (artikel III). Alle accelerometerdata
blev indsamlet ved hjælp af Axivity AX3 triaksiale accelerometre, og
søvnen blev registreret ved hjælp af EEG-baserede Zmachine® Insight+
sammen med søvntidsdagbøger, hvor forældre dokumenterede for deres børn.
Data til Paper I bestod af 14 børn og 19 voksne. Deltagerne bar
accelerometrene i en uge på deres højre hofte og lår. Samtidig blev der
indsamlet EEG-søvnregistreringer og søvntidsdagbøger. Ved hjælp af
Audacity, en open-source lydredigeringssoftware, annoterede tre
bedømmere hver accelerometeroptagelse ved at markere tidspunkter for,
hvornår personen var i sengen, og hvornår de var ude af sengen. Der blev
udført to runder med annotationer for at teste pålideligheden. Sandheden
blev baseret på EEG-søvnregistreringer. Nætter med problemer med
sensorerne i starten eller slutningen af optagelserne blev udelukket.
Overensstemmelse blev målt ved hjælp af
intraklassekorrelationskoefficienten (ICC) og Bland-Altman-analyse.
Paper II anvendte accelerometerdata fra sensorer placeret på håndleddet,
låret og hoften. Rådata fra 64 PHASAR-deltagere og 42 deltagere i den
interne undersøgelse blev undersøgt, og perioder uden brug af sensorerne
blev manuelt annoteret på samme måde som metoden beskrevet i Paper I.
Beslutningstræmodeller, udviklet ud fra data fra hoften og låret, brugte
12 funktioner udledt fra accelerationsensordata. Træning benyttede
79,2\% af disse data, og de resterende data blev brugt til test.
Modelhyperparametre blev optimeret gennem en femfoldig krydsvalidering.
Tre modeller blev evalueret mod benchmarkmetoder: en beslutningstræmodel
trænet på alle funktioner, en der brugte de seks vigtigste funktioner,
og en der udelod hudtemperatur. Ekstern validering blev udført på
håndledsdata fra 42 deltagere i den interne valideringsundersøgelse.
Alle modeller blev evalueret ved hjælp af metrikker udledt fra
forvirringsmatricer. Paper III af dette speciale analyserede
accelerations- og søvndata fra børn i alderen 4-17 år (gennemsnitlig
alder: 9,1 år). Vi kategoriserede EEG-baserede søvndata som ``vågen'' og
``sov'', for at forenkle klassificeringsopgaven. Dataforbehandling
omfattede et lavpas Butterworth-filter, udelukkelse af perioder uden
brug af sensorerne og funktionsekstraktion, hvilket resulterede i 64
funktioner fra accelerometer- og temperatursignaler samt
sensoruafhængige funktioner. Søvnoptagelserne blev underkastet
medianfiltrering i 5 og 10 minutter inden modeltræning for at fange
sande opvågninger bedre. Vi anvendte to modelleringsstrategier. Den
første anvendte en sekventiel tilgang med binære klassifikatorer. Efter
forudsigelse af `i seng'-tiden blev disse data udtrukket og tjente som
input til den næste model i sekvensen, der yderligere blev brugt til at
forudsige søvn, mens man var i sengen. Vi anvendte fire
maskinlæringsalgoritmer til denne tilgang: Logistisk regression;
beslutningstræer; single-layer feed-forward neurale netværk; og XGBoost.
Den anden strategi anvendte et bidirektionelt Long Short-Term Memory
(biLSTM) neuralt netværk som en multiklasseklassifikator og forudsagde
tre klasser: ``ude af sengen - vågen'', ``i seng - vågen'' og ``i seng -
sovende''. Data til de fire par sekventielle modeller blev delt op i
trænings- og testsæt, så data fra den samme nat ikke var i begge sæt.
Hyperparameteroptimering blev udført ved hjælp af ti-fold Monte Carlo
krydsvalidering. Efter bestemmelse af de bedste hyperparametre blev
modellerne tilpasset hele træningssættet. Et problem med ubalance i data
blev løst ved hjælp af teknikken med syntetisk overvægt for klassen
`vågen', der kun udgjorde cirka 15\% af træningsdataene. F1-score var
vores optimeringsmetrik. Separat blev data til træning af
biLSTM-modellen opdelt i et forhold på 50/25/25 for træning, validering
og test. Adam-optimereren og krydsentropi tabsefunktionen blev brugt.
Præstationen blev overvåget ved hjælp af F1-score, og tidlig stop blev
anvendt. For at vurdere præstationen på alle modeller blev der anvendt
standardmetrikker udledt fra forvirringsmatricer. For at forstå
effektiviteten af vores modeller til at estimere søvnkvalitetsmål
anvendte vi Bland-Altman-plots og Pearson-korrelationer.
Søvnkvalitetsmål i henhold til ZM-definitioner omfattede Sleep Period
Time (SPT), Total Sleep Time (TST), Sleep Efficiency (SE), Latency Until
Persistent Sleep (LPS) og Wake After Sleep Onset (WASO).

\textbf{Resultater}

I Paper 1 sammenlignede vi manuelle annotationer med ZM og søvndagbøger.
Resultaterne viste fremragende enighed både mellem bedømmere og inden
for samme bedømmer. Derudover var Bland-Altman-aftalegrænserne cirka ±30
minutter, hvilket kun viste en minimal middelværdibias. I Paper 2
fokuserede vi på registrering af perioder uden brug af accelerometrene.
For perioder uden brug længere end 60 minutter var de etablerede
algoritmer med på hinanden følgende nuller de mest effektive og opnåede
F1-score over 0,96. Imidlertid skilte beslutningstræer sig ud for
perioder kortere end 60 minutter og opnåede F1-scorer på over 0,74 på
tværs af alle sensorplaceringer. Bemærkelsesværdigt kunne de nyudviklede
dyb-læring og random forest-modeller ikke matche disse resultater. Paper
3 beskæftigede sig med søvnklassifikation og skøn over søvnkvalitetsmål
ved hjælp af accelerometre, der var båret på låret. Her udmærkede
XGBoost-modellen sig, især når den analyserede data filtreret i 5
minutter. Modellen viste små afvigelser i flere søvnmetrikker:
søvnperiodetid (0,2 minutter), samlet søvntid (-7,0 minutter),
søvneffektivitet (-1,1\%) og vågen efter søvnstart (-0,9 minutter).
Derudover viste denne model en stærk korrelation på 0,66 med samlet
søvntid. Det er værd at bemærke, at aftalegrænserne i vores resultater
afspejlede dem i tidligere studier af hofter og håndledsenheder.
Specifikt viste samlet søvntid aftalegrænser på (95\% CI): -95,5 (-105,2
til -88) minutter til 81,4 (72,4 til 92,5) minutter.

\textbf{Konklusion}

Samlet set understreger resultaterne af dette speciale pålideligheden og
præcisionen af nye teknologiske metoder inden for forskning om søvn og
registrering af perioder uden brug. Paper 1 bekræftede troværdigheden af
manuelle annotationsmetoder og bekræftede deres overensstemmelse med
traditionelle referencepunkter. Paper 2 fremhævede nuancerne ved
registrering af perioder uden brug og afslørede tydelige styrker i visse
algoritmer for specifikke varigheder, samtidig med at det fremhævede
områder, hvor nyere modeller har brug for forbedring. Paper 3 fremhæver
XGBoost-modellen til vurdering af søvn med accelerometre på låret og
placerer den som et gyldigt alternativ i forhold til metoder, der
anvender maskinlæringsmodeller på data fra hofter og håndled. Dog er der
stadig udfordringer med at identificere perioder, hvor man er vågen i
sengen, og med at vurdere individuelle søvnkvalitetsmål, hvilket er i
tråd med tidligere fund fra enheder, der bæres på håndleddet og hoften.

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

The rapidly growing field of wearable technology presents unparalleled
opportunities for acquiring accurate and objective data on human
behavior, particularly in the context of free-living accelerometer
recordings. This encompasses sleep patterns and physical activity among
other metrics. However, several challenges exist, especially when the
data is collected in free-living conditions as opposed to controlled
settings. Issues related to data annotation, the detection of periods
when the device is not being worn (non-wear time), and the optimal
sensor location for accurate assessments are all more complex in
free-living scenarios. This thesis aims to tackle these challenges
through a series of studies that employ machine learning techniques and
robust analytical methods. The primary focus is on the development and
validation of innovative approaches for manually annotating sleep data,
identifying non-wear time, and optimizing the use of thigh-worn
accelerometers specifically for sleep assessment in free-living
conditions.

\hypertarget{why-track-sleep-in-health-research}{%
\section{Why Track Sleep in Health
Research}\label{why-track-sleep-in-health-research}}

Physical behaviors throughout a day encompass a range of activities,
including sleep, physical activity (PA), and sedentary behavior. A
plethora of research over the past decade has strongly emphasized the
health benefits of optimal sleep, high PA levels, especially
moderate-to-vigorous physical activity
(MVPA)\textsuperscript{\protect\hyperlink{ref-kraus_physical_2019}{1},\protect\hyperlink{ref-lee_effect_2012}{2}},
minimal sedentary
periods\textsuperscript{\protect\hyperlink{ref-wilmot_sedentary_2012}{3}},
and adequate
sleep\textsuperscript{\protect\hyperlink{ref-cappuccio_sleep_2010}{4}}.
These findings have informed public health guidelines, such as the
American recommendation of 150 minutes of MVPA per
week\textsuperscript{\protect\hyperlink{ref-kl_physical_2018}{5}}, and
the Danish guideline suggesting 30 minutes of MVPA daily for
adults\textsuperscript{\protect\hyperlink{ref-el-zine_fysisk_nodate-1}{6}}
and 60 minutes for
children\textsuperscript{\protect\hyperlink{ref-el-zine_fysisk_nodate}{7}}.
The integration of sleep tracking in health research is increasingly
crucial for a comprehensive understanding of individual well-being.
Sleep and physical activity are instrumental in influencing a broad
spectrum of health aspects, ranging from mental
health\textsuperscript{\protect\hyperlink{ref-biddle_physical_2011}{8}}
to physical
fitness\textsuperscript{\protect\hyperlink{ref-warburton_health_2017}{9}},
and even extending to disease
prevention\textsuperscript{\protect\hyperlink{ref-strath_guide_2013}{10},\protect\hyperlink{ref-arem_leisure_2015}{11}}.
With advancements in wearable technology and tracking systems, we now
have tools that enable in-depth investigations into the complex
interplay between sleep, physical activity, and general
health\textsuperscript{\protect\hyperlink{ref-rollo_whole_2020}{12}}.
Given the significance of sleep and physical activity in overall health,
as backed by extensive research and public health guidelines, the need
for focused studies on sleep becomes even more compelling. The
incorporation of sleep tracking into broader health research allows us
to delve deeper into how sleep quality and duration impact various
aspects of our well-being, such as mental health, physical fitness, and
disease prevention. Advanced wearable technologies and tracking systems
now provide us with unprecedented capabilities to examine the intricate
relationships between sleep, physical activity, and general health.
Hence, an intensive study of sleep is not just beneficial but essential
for a holistic understanding of what makes for a healthy life.

We spend approximately one-third of our lives asleep, yet much about
this state of consciousness remains elusive, including its biological
function and what defines its
quality\textsuperscript{\protect\hyperlink{ref-ma_sleep_2017}{13}}.
However, what is clear is the essential role of adequate sleep in
maintaining both physical and psychological well-being, consolidating
memories, and regulating
emotions\textsuperscript{\protect\hyperlink{ref-worley_2018}{14}--\protect\hyperlink{ref-scott_2021}{16}}.
On the flip side, insufficient sleep has been linked to a range of
negative health outcomes such as weight gain, obesity, heart disease,
stroke, impaired immune function, and even an elevated risk of
death\textsuperscript{\protect\hyperlink{ref-consensus_conference_panel_recommended_2015}{17}--\protect\hyperlink{ref-hale_2020}{19}}.
The impact of sleep deprivation is felt not just in the long term but
also immediately. Short-term consequences include reduced alertness,
heightened stress levels, diminished concentration, delayed reaction
times, and a propensity for risk-taking
behavior\textsuperscript{\protect\hyperlink{ref-shochat_2014}{20}--\protect\hyperlink{ref-bonnet_1985}{23}}.
When poor sleep becomes a chronic issue, it can severely affect one's
quality of life. For example, daytime sleepiness increases the risk of
accidents in occupational settings and while driving, as well as
negatively impacts academic and work performance, with broader social
and economic repercussions like school dropouts or job
loss\textsuperscript{\protect\hyperlink{ref-connor_2002}{24}--\protect\hyperlink{ref-roth_1996}{26}}.
The concern over daytime sleepiness becomes particularly acute given
that it is widespread, affecting around 10-20\% of
society\textsuperscript{\protect\hyperlink{ref-wang_2019}{27}}. Various
factors contribute to this, ranging from lifestyle choices like
irregular bedtime and shift work to medical conditions that affect the
central nervous system and certain
medications\textsuperscript{\protect\hyperlink{ref-roth_1996}{26}}.

\hypertarget{the-gold-standard-for-measuring-sleep}{%
\section{The Gold Standard for Measuring
Sleep}\label{the-gold-standard-for-measuring-sleep}}

The challenge of studying sleep has become significantly more manageable
due to advancements in technology and our understanding of neuroscience.
It wasn't until the 1950s that sleep study became scientifically
feasible, thanks to the pioneering work of Nathaniel Kleitman and Eugene
Aserinsky\textsuperscript{\protect\hyperlink{ref-aserinsky_1953}{28}},
who demonstrated the brain's active involvement in sleep. Utilizing
electroencephalography (EEG), Kleitman and Aserinsky were able to
measure brain activity and identified that it synchronizes over multiple
regions, predominantly within specific frequency bands. This
groundbreaking discovery enabled them to define distinct ``sleep
stages'' that the brain cycles through, fundamentally transforming the
way sleep is measured and understood. A visual example of these sleep
stage cycles can be seen in Figure~\ref{fig-hypno}. Therefore, measuring
sleep, given its complexities, not only is critical but also possible
thanks to these technological and scientific milestones.

In a relaxed wakeful state, the EEG predominantly displays alpha
activity within the frequency band of 8-10 Hz and amplitudes usually
ranging from 10-50 μV. As an individual begins to fall asleep, they
enter the non-rapid eye movement (NREM) sleep stage 1 (N1). During this
drowsy phase, the brain's EEG activity transitions to the theta range
frequencies of 4-6 Hz. Simultaneously, muscle relaxation is evident,
respiratory rates decelerate, and there's a drop in both distal body
temperature and heart rate. This initial stage is followed by NREM sleep
stage 2 (N2), where the EEG spectra frequencies are further reduced.
This stage introduces sleep spindles---periodic high-frequency waves
oscillating between 12-14 Hz lasting for 0.5-1.5 seconds---and
K-complexes, which are characteristic reactive EEG elements of N2 sleep.

Progressing deeper into sleep, one enters NREM sleep stage 3 (N3), often
termed ``deep sleep''. Here, the EEG mainly exhibits high-amplitude
oscillations within the delta band of 1-4 Hz. Following these NREM
stages, the sleep cycle culminates in REM sleep. Interestingly, the EEG
patterns during REM sleep closely resemble the alpha activity seen in
wakeful states. This stage is marked by evident rhythmic eye movements,
while the respiration and heart rate display enhanced amplitudes and
variability. The brain stem suppresses most voluntary body movements at
this time, making it a period of relative physical inactivity. Dreaming
tends to be more frequent during REM sleep. A single REM episode can
span a few minutes and tends to extend in duration during the latter
part of the night. On average, an entire sleep cycle, from N1 to REM,
spans 90-110 minutes and is typically repeated multiple times throughout
the night.

\begin{figure}

{\centering \includegraphics{figures/hypnogram.pdf}

}

\caption{\label{fig-hypno}Sample hypnogram showing the sleep stage
cycles of an eight-hour polysomnography recording. The sleep stages
(REM, NREM 1-3) and arousals are shown.}

\end{figure}

Polysomnography (PSG) is a gold-standard technique in sleep research,
allowing simultaneous assessment of various physiological signals
influenced during
sleep\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{29}}. PSG
gathers electrophysiological data from the brain using a 6-channel EEG,
specifically from locations F3, F4, C3, C4, O1, and O2, contrasted
against the contralateral mastoids (M1, M2). In addition, it uses
electrooculography (EOG) to gauge eye movements, electromyography (EMG)
to track chin muscle tone and occasional arm and leg movements, and
electrocardiography (ECG) to monitor heart rate. The study is augmented
by methods that evaluate respiratory airflow, effort indicators, and
peripheral pulse oximetry
(PPG)\textsuperscript{\protect\hyperlink{ref-ibuxe1uxf1ez_2018}{30}}.
For enhanced data interpretation, an infrared-equipped video camera
captures the sleeping subject. Typically, PSG is carried out overnight
in a specialized clinical sleep laboratory, assisting in diagnosing
various sleep disorders. This technique furnishes detailed insights into
an individual's sleep architecture, revealing sleep and wake durations
as well as aiding in the classification of sleep
stages\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{29}}. Sleep,
as per standard PSG scoring, is classified into four distinct stages:
three stages of non-REM (NREM) sleep and one stage of rapid-eye-movement
(REM) sleep\textsuperscript{\protect\hyperlink{ref-roebuck_2014}{31}}.
Such detailed data enables accurate clinical research and the diagnosis
of various sleep disorders, such as sleep apnea and periodic movements
during sleep\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{29}}.
Moreover, PSG proves instrumental in examining excessive daytime
sleepiness. Following a PSG-monitored night, individuals undergo a
multiple sleep latency test where they're presented with multiple
chances to fall asleep throughout the day. Both the time taken to fall
asleep (latency) and the characteristics of ensuing sleep stages, as
captured by PSG, are
evaluated\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{29}}. While
PSG offers an unparalleled depth of sleep data, essential for diagnosing
an array of sleep disorders, it comes with its own set of limitations.
The procedure can be costly, often restricted to one or two nights in a
specialized setting under a technician's supervision. This controlled
environment may not truly mirror natural sleep
conditions\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{29}}.
Moreover, PSG necessitates specialized personnel to oversee, score, and
interpret the data, making it less feasible for expansive or free-living
studies\textsuperscript{\protect\hyperlink{ref-girschik_validation_2012}{32}}.
Hence, while invaluable, PSG is predominantly reserved for individuals
presenting sleep-related complaints and for the conclusive diagnosis of
sleep disorders.

\hypertarget{physical-activity-questionnaires-and-diaries}{%
\section{Physical Activity Questionnaires and
Diaries}\label{physical-activity-questionnaires-and-diaries}}

In the realm of epidemiological studies, researchers frequently utilize
self-report methods, encompassing PA questionnaires and diaries, as
their primary tools for data collection. Their popularity stems from
several distinct advantages: they are cost-effective, user-friendly, and
uniquely capable of capturing both the type and the contextual backdrop
of physical activity
(PA)\textsuperscript{\protect\hyperlink{ref-westerterp_2009}{33}}. Yet,
despite their convenience, these self-report tools are not without their
challenges. For instance, they are susceptible to various biases,
particularly those related to reporting inaccuracies and potential
misinterpretation. Their reliability can sometimes come under question,
especially when respondents aren't meticulous or transparent in their
entries\textsuperscript{\protect\hyperlink{ref-westerterp_2009}{33}}.

When it comes to assessing subjective sleep quality, instruments like
the Pittsburgh Sleep Quality Index play a pivotal role. This tool
doesn't just measure sleep duration; it offers insights into an
individual's overall satisfaction with their sleep over a defined
timeframe, often a
month\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{29}}.

In broader population-based studies, self-report sleep assessments
emerge as the go-to method, yet they come with their own set of
limitations. Notably, there's a tendency for these tools to give a
slightly embellished picture of sleep duration. Moreover, they may
sometimes fail to provide a nuanced capture of sleep quality and
intricate sleep patterns. Part of the challenge is their design: they
often consolidate and summarize sleep data over a span of one to two
weeks. This approach inherently exposes the data to recall biases,
especially when participants try to remember sleep patterns from several
days ago\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{29}}.
Intriguingly, the veracity of these self-reports can be swayed by
certain personal traits and sleep behaviors, ranging from a
participant's weight status and ethnicity to their routine sleep
duration\textsuperscript{\protect\hyperlink{ref-lauderdale_2008}{34}}.

Stepping away from these broad self-reports, sleep diaries stand out as
a more detailed and structured tool. Often hailed as the ``gold
standard'' in subjective sleep assessment, they dive deep into various
sleep parameters, like total sleep duration, efficiency, onset latency,
and wake periods post sleep onset (WASO). Their strength lies in
offering a day-by-day account, making it easier to spot disturbances,
ascertain precise sleep timings, and decipher the rhythm of daily
sleep-wake patterns over an extended
duration\textsuperscript{\protect\hyperlink{ref-ibuxe1uxf1ez_2018}{30}}.
However, like all tools, they aren't perfect. Their accuracy hinges on
participants' memory retention and commitment to regular, detailed diary
entries. From the researchers' standpoint, sifting through these
extensive diaries can be time-intensive and, for participants, the
process can sometimes be seen as taxing, potentially affecting their
consistency in logging
entries\textsuperscript{\protect\hyperlink{ref-thurman_2018}{35}}.

\hypertarget{objective-alternatives-to-psg-and-sleep-diaries}{%
\section{Objective Alternatives to PSG and Sleep
Diaries}\label{objective-alternatives-to-psg-and-sleep-diaries}}

Wearable sensor systems are emerging as a promising counterpart to
traditional laboratory sleep measurements. These compact devices enable
longitudinal observation of sleep and wake patterns over extended
periods ranging from days and months to even
decades\textsuperscript{\protect\hyperlink{ref-borbuxe9ly_decades_wrist_2017}{36}}.
Historically, the inception of these devices led to the adoption of
activity-based sleep measurement, commonly known as actigraphy,
complementing polysomnography in both sleep research and medicine. The
fundamental premise of actigraphy is straightforward: periods of
movement suggest wakefulness, while prolonged stillness implies sleep.
Employing movement sensors like accelerometers and inertial measurement
units (IMUs), typically attached to the wrist, it becomes feasible to
monitor sleep and wake cycles under natural, everyday conditions.
Several sleep-wake detection algorithms, supplied by both commercial
entities like ActivePal, ActiGraph, Fitbit and many more and publicly
accessible sources (such as the Cole--Kripke and Sadeh algorithms),
facilitate this
process\textsuperscript{\protect\hyperlink{ref-cole_automatic_1992}{37}--\protect\hyperlink{ref-jean-louis_2001}{39}}.

The past decade has witnessed a surge in new wearable sensor systems
designed to monitor sleep and related bio-signals. This proliferation is
fueled by endeavors to encompass the multifaceted nature of sleep,
combined with advances in miniaturized, cost-effective
electronics\textsuperscript{\protect\hyperlink{ref-tobin_2021}{40}}.
Conceptually, these wearables are electronic microprocessor-driven
devices that gather, process, and transform diverse data---including
biometric, biospecimen, and environmental information---into insightful
trends\textsuperscript{\protect\hyperlink{ref-hollimon_2022}{41}}. They
are designed to be worn close to or directly on the skin. In the context
of this thesis, a device is deemed ``wearable'' if it meets specific
criteria: it should be suitable for daily wear, usable at home without
technical assistance, and capable of delivering continuous measurements
spanning multiple
days\textsuperscript{\protect\hyperlink{ref-schutte_2021}{42}}.

The dynamic field of sleep monitoring is evolving rapidly, with
innovations in sensor modalities, electrode types, and processing
algorithms. Given the breadth of this domain, only a selection of
representative literature is provided here, with more extensive reviews
available in other
sources\textsuperscript{\protect\hyperlink{ref-hollimon_2022}{41},\protect\hyperlink{ref-kwon_2021}{43}--\protect\hyperlink{ref-grandner_2019}{45}}.

Central to sleep monitoring is the EEG. Sleep is primarily defined based
on EEG measurements, and wearables now strive to harness this. Modern
systems employ miniaturized electrodes positioned in the ear, embedded
in headbands, or applied directly to the scalp. They capture EEG, EOG,
or a composite cortical signal from which sleep quantity and stages are
inferred\textsuperscript{\protect\hyperlink{ref-mikkelsen_2019}{46},\protect\hyperlink{ref-levendowski_2017}{47}}.

The autonomic nervous system's role in sleep physiology has spurred
interest in cardiorespiratory signal monitoring. The shift between
sympathetic and parasympathetic control during different sleep stages
affects cardiorespiratory
signals\textsuperscript{\protect\hyperlink{ref-tobaldini_2013}{48},\protect\hyperlink{ref-somers_1993}{49}}.
Measures like heart rate variability (HRV) have been explored for sleep
stage detection and sleep quality
assessment\textsuperscript{\protect\hyperlink{ref-radha_sleep_2019}{50},\protect\hyperlink{ref-kuula_2021}{51}}.
Wearables employing ECG electrodes, photoplethysmography (PPG), and
sensors to gauge oxygenated haemoglobin levels (SpO2) provide metrics
like heart rate (HR), HRV, or even approximate indicators for sleep
stage
classification\textsuperscript{\protect\hyperlink{ref-kinnunen_2020}{52}--\protect\hyperlink{ref-braun_2020}{54}}.
Additionally, respiratory characteristics, captured using PPG,
accelerometers, magnetometers, or strain gauges, aid in identifying
irregular breathing patterns and respiratory
rates\textsuperscript{\protect\hyperlink{ref-preejith_2017}{55}--\protect\hyperlink{ref-jarchi_2018}{59}}.

Environmental factors also play a role in sleep quality. Wearables
equipped with temperature and light sensors provide insights into the
sleeping environment. Data on room lighting, for instance, can improve
sleep-wake detection accuracy, given that subjects usually switch off
lights before sleeping and turn them on upon
waking\textsuperscript{\protect\hyperlink{ref-price_2012}{60}}.

The realm of activity-based sleep monitoring also continues to expand.
Traditional actigraphy remains a cornerstone for detecting sleep and
wake states\textsuperscript{\protect\hyperlink{ref-chase_2022}{61}}.
However, newer devices now incorporate accelerometers to differentiate
between sleep
stages\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{62}}.
For more nuanced movement analysis, like identifying movement-related
sleep disorders such as periodic limb movements disorder, sensors with
higher spatiotemporal resolutions and electromyography have
emerged\textsuperscript{\protect\hyperlink{ref-jortberg_2018}{63},\protect\hyperlink{ref-athavale_2017}{64}}.
Furthermore, inertial measurement units (IMUs) offer insights into body
position or even correlate sleep quality with daytime
activity\textsuperscript{\protect\hyperlink{ref-razjouyan_2017}{65}}.

Despite the plethora of methods available, a comprehensive comparison is
challenging due to varying evaluation standards and target populations.
Typically, EEG-based methods offer the most precise insights into sleep
stages and duration. However, their placement on the head can hinder
user acceptance and consistent use. A growing consensus suggests that
combining multiple sensor modalities, such as integrating wrist-worn
accelerometers with other devices, could be
beneficial\textsuperscript{\protect\hyperlink{ref-dezambotti_2019}{66},\protect\hyperlink{ref-imtiaz_2021}{67}}.

\hypertarget{machine-learning-in-health-research}{%
\section{Machine Learning in Health
Research}\label{machine-learning-in-health-research}}

The availability of large datasets from wearable devices has set the
stage for the incorporation of machine learning techniques into health
research. These algorithms have the capability to analyze vast and
complex data sets, delivering insights that were previously difficult or
impossible to discern. Whether it's recognizing subtle patterns
indicative of sleep apnea for timely
intervention\textsuperscript{\protect\hyperlink{ref-cappuccio_sleep_2010}{4}},
or evaluating the effectiveness of antidepressant medications in
patients with sleep
disturbances\textsuperscript{\protect\hyperlink{ref-paruthi_consensus_2016}{68}},
machine learning adds a layer of precision and depth to data analysis.In
the context of preventive healthcare, which is becoming increasingly
focal in today's medical landscape, machine learning can serve as a
robust tool for early warning systems. By analyzing regular tracking
data of sleep and physical activity, machine learning algorithms can
identify potential health risks long before they evolve into severe
conditions. For example, sustained inactivity patterns could be
predictive of future obesity or heart disease
risks\textsuperscript{\protect\hyperlink{ref-tremblay_sedentary_2017}{69}}.
Early detection through such sophisticated data analysis enables timely
interventions and preventive measures, further substantiating the role
of machine learning in modern health
research\textsuperscript{\protect\hyperlink{ref-liguori_evolving_2023}{70}}.

Machine learning emerges from the confluence of statistics, focused on
understanding relationships within data, and computer science, which is
devoted to the development of efficient computing
algorithms\textsuperscript{\protect\hyperlink{ref-hastie01statisticallearning}{71}}.
This interdisciplinary field is particularly fueled by the computational
demands of constructing statistical models from large-scale data sets,
sometimes comprising billions or even trillions of data points. Within
machine learning, various learning types exist, notably supervised and
unsupervised learning. However, when examining the impact of machine
learning on medicine, it can be helpful to divide tasks into two broad
categories: those that medical professionals already excel at, and those
where success has been limited. Understanding machine learning through
this lens allows us to explore its potential contributions to different
areas of medicine, pinpointing where these advanced computational
methods can offer significant benefits.

\hypertarget{sleep-assessment-with-accelerometry}{%
\subsection{Sleep Assessment with
Accelerometry}\label{sleep-assessment-with-accelerometry}}

Wrist-worn accelerometers have become increasingly popular for PA
assessment. They have been developed separately from clinical wrist
actigraphy but offer the potential for dual PA and sleep data
collection(90). New algorithms, like the GGIR-package in R, combine
24-hour activity data, but they often require a sleep log for
accuracy(92). Some algorithms can detect sleep periods even without
sleep diaries, but their validation remains limited(93).

\begin{itemize}
\tightlist
\item
  Gold standards
\item
  Traditional methods and their limitations
\item
  polysomnography
\item
  self-reported diaries
\item
  The emergence and potential of wearable accelerometers and some kind
  segway to machine learning models in this field.
\end{itemize}

Some of these limitations can be addressed with 24-hour
accelerometer-based protocols, especially those worn on the
wrist\textsuperscript{\protect\hyperlink{ref-rosenberger_24-hour_2019}{72}}.
Wrist accelerometers are small, non-invasive,
waterproof\textsuperscript{\protect\hyperlink{ref-welk_reliability_2004}{73}},
allowing for continuous, 24-hour wear with minimal disruption to the
wearer, and permit uninterrupted activity measurement throughout the
day, thereby tracking and analyzing daily changes in PA and sleep
behaviors. Furthermore, the latest accelerometers supply raw
acceleration data that can be processed using open-source analytical
techniques to produce estimates of sleep, sedentary behavior, and
PA\textsuperscript{\protect\hyperlink{ref-migueles_comparability_2019}{74}}.
Simultaneous measurement of physical behaviors, particularly feasible
with wrist accelerometry, can offer a better comprehension of the
influence of these behaviors on health indicators and their
interrelationships. This data could be critical in shaping future health
recommendations or interventions.

\begin{itemize}
\tightlist
\item
  Supervised learning and annotation of data sources
\end{itemize}

Machine learning stands at the crossroads of statistics and computer
science. It embodies the principles of discerning patterns and
relationships from data, a foundational tenet of statistics, while also
leveraging the power of efficient computing algorithms, a core concept
in computer
science\textsuperscript{\protect\hyperlink{ref-hastie01statisticallearning}{71}}.
With the surge in data scale, encompassing billions or even trillions of
data points, this synergy becomes essential to navigate the intricate
landscape of data analysis.

One of the primary branches of machine learning is supervised learning.
Its primary objective is to predict known outputs based on inputs.
Real-world applications of supervised learning span across various
domains. For instance, in machine learning competitions, challenges
often include tasks such as handwriting recognition, image
classification (e.g., discerning between a cat and a dog), and document
categorization (e.g., differentiating between a clinical trial on heart
failure and a financial report). These tasks aim to emulate or even
surpass human capabilities in specific areas. Supervised learning
essentially revolves around two core concepts: classification
(categorizing data into predefined groups) and prediction (estimating
unknown parameters).

Delving deeper into its applications, consider the realm of physical
activity and sleep research. Here, supervised learning plays a pivotal
role. For instance, algorithms can automatically classify activity
levels---from sedentary to vigorous---using data from accelerometers.
Similarly, in sleep studies, such algorithms can discern between various
sleep stages like light sleep or REM, using accelerometer or actigraphy
data. While these machines emulate human analysts, their capabilities
can extend beyond, unveiling insights or patterns not immediately
visible to human researchers. A predictive model, for example, might
forecast the risk of metabolic syndrome based on sedentary time patterns
or predict sleep disorders from sleep pattern variations. (REFS PÅ HELE
AFSNITTET)

The utilization of machine learning to decipher sleep and physical
activity from accelerometry data is gaining traction. Its capability to
model intricate non-linear relationships is unparalleled compared to
traditional statistical methods like linear
regression\textsuperscript{\protect\hyperlink{ref-fiorillo_automated_2019}{75}}.
Yet, the success of supervised learning hinges on abundant and
accurately annotated data for ensuring both precision and
applicability\textsuperscript{\protect\hyperlink{ref-van_der_ploeg_modern_2014}{76}}.

The significance of sleep, especially for children's health and
development, is
well-established\textsuperscript{\protect\hyperlink{ref-chaput_systematic_2017}{77}--\protect\hyperlink{ref-st-onge_sleep_2016}{79}}.
Healthy sleep encompasses several factors like duration, timing, and
quality\textsuperscript{\protect\hyperlink{ref-gruber_position_2014}{80}}.
Yet, the potential of advanced machine learning in evaluating sleep
using accelerometer data is still largely
untapped\textsuperscript{\protect\hyperlink{ref-haghayegh_application_2020}{81}}.

Despite the supremacy of Polysomnography (PSG) as the gold standard for
objective sleep analysis, its high costs, and intrusive nature
underscore the value of accelerometry---a less invasive and more
cost-effective
alternative\textsuperscript{\protect\hyperlink{ref-vaughn_technical_2008}{82}}.
Recent endeavors in this domain include PSG-assessed sleep-wake
classification using wrist-worn accelerometers. For example,
Sundararajan et
al.\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{62}}
leveraged a random forest machine learning algorithm, achieving
commendable results. Yet, issues like high false discovery rates point
to challenges such as limited subject variation.

To address these challenges, there's a clear imperative to diversify the
sample base and extend recording durations. While accelerometry has its
limitations, its feasibility for prolonged, out-of-lab recordings makes
it
invaluable\textsuperscript{\protect\hyperlink{ref-van_de_water_objective_2011}{83}}.
Given these dynamics, the focus should lean towards sleep timing
algorithms rather than sleep staging.

A crucial aspect of deciphering sleep/wake cycles from accelerometry
data is the annotation of time in bed, which, although not indicative of
actual sleep duration, provides crucial insights. Such annotations can
stem from individual sleep diaries, EEG-based
recordings\textsuperscript{\protect\hyperlink{ref-younes_staging_2016}{84}},
or systems capturing tracheal
sounds\textsuperscript{\protect\hyperlink{ref-dafna_sleep-wake_2015}{85},\protect\hyperlink{ref-montazeri_ghahjaverestan_sleepwakefulness_2020}{86}}.
Given its practicality, accelerometry continues to be a staple in sleep
research, echoing its immense potential and
adaptability\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{87}--\protect\hyperlink{ref-barouni_ambulatory_2020}{90}}.

\hypertarget{importance-of-accurate-data-annotation}{%
\subsection{Importance of Accurate Data
Annotation}\label{importance-of-accurate-data-annotation}}

The utilization of wearable technology in sleep research and other
behavioral studies largely depends on the accuracy of the annotated
data. Inaccurate or imprecise annotations could significantly impact the
effectiveness of machine learning models trained on these datasets.
Hence, the need for innovative and reliable annotation methods is more
pressing than ever.

Human-in-the-loop

\hypertarget{challenges-in-non-wear-detection}{%
\subsection{Challenges in Non-Wear
Detection}\label{challenges-in-non-wear-detection}}

For wearable physical activity sensors to provide meaningful data, it is
crucial to accurately distinguish between wear and non-wear times.
Traditional heuristic algorithms have limitations, and thus there is a
need to explore machine learning solutions that offer better performance
and generalizability.

ensure integrity of the data

\hypertarget{sensor-placement-for-sleep-assessment}{%
\subsection{Sensor Placement for Sleep
Assessment}\label{sensor-placement-for-sleep-assessment}}

While wrist and hip-worn devices are commonly used in sleep research,
alternative placements like thigh-worn devices remain relatively
unexplored despite their potential advantages. Additionally, traditional
methods like polysomnography are impractical for large-scale studies,
necessitating the investigation of cost-effective alternatives.

\begin{itemize}
\tightlist
\item
  Nonwear
\item
  Sleep
\end{itemize}

\hypertarget{scope-and-relevance}{%
\subsubsection{Scope and Relevance}\label{scope-and-relevance}}

\begin{itemize}
\tightlist
\item
  The need for cost-effective, reliable, and practical alternatives for
  large-scale studies.
\item
  The potential of free-living accelerometers, and why they are a
  compelling subject of study.
\end{itemize}

\hypertarget{existing-challenges}{%
\subsubsection{Existing Challenges}\label{existing-challenges}}

\begin{itemize}
\tightlist
\item
  Discuss the challenges with existing methods, such as identifying
  non-wear time, annotating in-bed periods, and classifying awake
  periods during in-bed time.
\item
  Address the lack of exploration of certain sensor locations, like the
  thigh.
\end{itemize}

\hypertarget{thesis-goals-and-objectives}{%
\subsubsection{Thesis Goals and
Objectives}\label{thesis-goals-and-objectives}}

\begin{itemize}
\item
  Clearly state the aim and objectives of your thesis.

  create data -\textgreater{} ensure integrity of data -\textgreater{}
  build models
\item
  Explain how your thesis will address the identified challenges,
  including improving the manual annotation of in-bed periods, enhancing
  non-wear detection, and estimating sleep quality metrics.
\end{itemize}

\hypertarget{overview-of-the-papers}{%
\subsubsection{Overview of the Papers}\label{overview-of-the-papers}}

\begin{itemize}
\item
  Briefly introduce each paper, highlighting the key research question,
  methods, and findings.
\item
  Explain how each paper contributes to your thesis goals and
  objectives.
\end{itemize}

\hypertarget{thesis-structure}{%
\subsection{Thesis Structure}\label{thesis-structure}}

Provide an outline of the subsequent chapters of your thesis.

\newpage

\hypertarget{paper-i-manual-annotation-of-time-in-bed-using-free-living-recordings-of-accelerometry-data}{%
\chapter{Paper I: Manual Annotation of Time in Bed Using Free-Living
Recordings of Accelerometry
Data}\label{paper-i-manual-annotation-of-time-in-bed-using-free-living-recordings-of-accelerometry-data}}

This segment of the thesis encompasses the methods, results, and
discussion for Paper I. The study underscores the importance of
effective machine learning algorithms for sleep/wake cycles, which
ideally necessitate correct data annotations over a span of 7-10 days.
Although sleep diaries or EEG recordings can annotate `time in bed',
many researches predominantly rely on accelerometry. This emphasizes the
imperative for enhanced annotation techniques and their validity. Our
objective is to introduce a manual annotation method, gauge its
precision, and determine its consistency. Some of the details presented
here were previously mentioned in the published version of Paper
I\textsuperscript{\protect\hyperlink{ref-skovgaard_manual_2021}{91}}.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{study-population}{%
\subsection{Study Population}\label{study-population}}

The data for this study was sourced from the SCREENS pilot trial
(www.clinicaltrials.gov, NCT03788525), a two-arm parallel-group
cluster-randomized trial with two intervention groups, conducted between
October 2018 and March
2019\textsuperscript{\protect\hyperlink{ref-rasmussen_feasibility_2021}{92},\protect\hyperlink{ref-rasmussen_short-term_2020}{93}}.
There was no control group in this trial.

Families from the Middelfart municipality in Denmark were approached for
participation if they had a child aged between 6 to 10 years living with
them, out of a total of 1686 families. To qualify, the parent's screen
media usage had to exceed the median of 2.7 hours per day, based on
survey responses from 394 respondents. Additionally, all children in the
household needed to be older than 3.9 years to ensure that sleep
measurements weren't disrupted by the nocturnal awakenings typical of
infants or toddlers. For a comprehensive list of inclusion and exclusion
criteria, refer to Pedersen et
al.\textsuperscript{\protect\hyperlink{ref-pedersen_self-administered_2021}{94}}.

The study ultimately included data from 14 children and 19 adults. These
participants weren't advised to alter their sleep or bedtime routines
for the interventions. While the study focused on nightly sleep time as
recorded by the EEG-based sleep staging system, any napping behavior of
the participants was deemed irrelevant.

All data collection procedures were reported to the local data
protection department, SDU RIO (ID: 10.391), in compliance with the
Danish Data Protection Agency's regulations.

\hypertarget{actigraphy}{%
\subsection{Actigraphy}\label{actigraphy}}

Both adults and children participated in 24-hour accelerometry
recordings using two triaxial accelerometers, Axivity AX3 (Axivity Ltd.,
Newcastle upon Tyne, UK). The Axivity AX3 is a compact device, measuring
23 mm × 32.5 mm × 7.6 mm and weighing just 11 g. It was set with a
sensitivity of ±8 g and a sampling frequency of 50 Hz.

Participants wore the accelerometers at two specific anatomical
locations. The first was positioned on the right hip, secured in a
pocket attached to a belt around the waist, ensuring the USB connector
faced outward from the body's right side. The second accelerometer was
placed midway between the hip and knee on the right thigh, housed in a
pocket on a belt, with the USB connector also facing away from the body.

For both the baseline and follow-up, the devices were worn for a
duration of one week (seven consecutive days). This duration aligns with
the recommended number of days to reliably gauge habitual physical
activity\textsuperscript{\protect\hyperlink{ref-jaeschke_variability_2018}{95}}.

\hypertarget{zmachine-insight-sleep-assessments}{%
\subsection{Zmachine® Insight+ Sleep
Assessments}\label{zmachine-insight-sleep-assessments}}

Both adults and children were assessed for their sleep patterns using
the Zmachine® (ZM) Insight+ model DT-200 (General Sleep Corporation,
Cleveland, OH, USA), Firmware version 5.1.0. This assessment was
concurrent with the accelerometer recordings. At the baseline, the sleep
assessment spanned 3--4 nights, while during the follow-up, it was
conducted over 3 nights.

The ZM device operates by measuring sleep through a single-channel EEG,
specifically from the differential mastoid (A1--A2) EEG location,
evaluated on a 30-second epoch basis. Designed for use in everyday
settings, the ZM provides an objective measurement of various sleep
parameters, including sleep duration, sleep stage classification, and
latency to different sleep stages.

The ZM's algorithm has been benchmarked against polysomnography (PSG) in
laboratory settings for both adults with and without chronic sleep
issues\textsuperscript{\protect\hyperlink{ref-wang_evaluation_2015}{96},\protect\hyperlink{ref-kaplan_performance_2014}{97}}.
Our findings indicate that the ZM is effectively applicable to both
children and adults for multi-day measurements in real-world
settings\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{87}}.
Notably, the device showcased a high accuracy in distinguishing between
sleep and wakefulness, with sensitivity, specificity, positive
predictive value, and negative predictive values being 95.5\%, 92.5\%,
98\%, and 84.2\%,
respectively\textsuperscript{\protect\hyperlink{ref-kaplan_performance_2014}{97}}.

For the assessment, three electrodes (Ambu A/S, Ballerup, Denmark, type:
N-00-S/25) are positioned on the mastoids (for signal) and the nape (as
ground). About half an hour before their intended sleep time,
participants' skin areas are cleaned with alcohol swabs, after which the
electrodes are affixed. An EEG cable connects these electrodes to the ZM
device. A preliminary sensor check ensures all electrodes are correctly
mounted; any issues are promptly addressed by replacing the problematic
electrodes. Additionally, participants, or parents on behalf of their
children, recorded their sleep and wake times daily in a dedicated
diary.

\hypertarget{audacity}{%
\subsection{Audacity}\label{audacity}}

Audacity®️ is a distinguished free audio editing
software\textsuperscript{\protect\hyperlink{ref-audacity}{98}}. The
genesis of Audacity can be traced back to the fall of 1999, when it
emerged as an innovative project led by Dominic Mazzoni and Roger
Dannenberg at Carnegie Mellon University. By May 2000, it was unveiled
to the world as an open-source audio editor. Since its inception,
Audacity has undergone significant evolution. The software, developed
collaboratively by the community, now boasts of hundreds of unique
features, offers complete support for professional-grade 24-bit and
32-bit audio, has a comprehensive manual available in multiple
languages, and has witnessed distribution in the millions. Today, a
dedicated team of volunteers from various corners of the globe continues
to maintain and enhance Audacity. It is disseminated under the GNU
General Public License, granting everyone the freedom to utilize the
software for personal, educational, or commercial endeavors.

In the realm of accelerometer data analysis, Audacity stands out. It
furnishes researchers with the capability to meticulously scrutinize
high-resolution raw accelerometer data with unparalleled precision.
Users can quickly zoom in to delve deeper into specific segments of the
recording, like certain patterns around bedtime, or zoom out for a
broader perspective, such as data spanning a week. Furthermore,
Audacity's sophisticated labeling function is pivotal for annotating the
accelerometry data. Any generated labels can be preserved in an
individual file and later integrated into machine learning algorithms.
This level of detailed manual inspection of high-resolution
accelerometer data offered by Audacity is, based on our knowledge,
unparalleled by any other software.

Within the Audacity interface, there's the possibility of amalgamating
over 100 channels of data. This aids in the merging of distinct signal
features derived from acceleration. The integration of multiple signal
features is intriguing as it might enhance the visual comprehension and
classification of inherent behaviors. Nevertheless, an excessive
conglomeration of signal features might obscure the precise
identification of targeted behaviors. For our study, we incorporated a
total of seven distinct signal features. The criteria for classifying
``lying'' in the first feature are explicit: if the inclination of the
hip accelerometer surpasses 65 degrees and the thigh accelerometer
simultaneously identifies as ``sitting'' based on Skotte et al.'s
activity type classification
algorithm\textsuperscript{\protect\hyperlink{ref-skotte_detection_2014}{99}}.
The other signal features, barring ``time'', are directly procured from
Skotte et al.'s algorithm. These features, delineated in
Table~\ref{tbl-man_signal_features}, concern the longitudinal axis of
the body. Data derived from accelerometry undergoes processing using a
window length of two seconds (60 samples) and has a 50\% overlap (30
samples), ensuring a resolution of one second. The methodologies from
Skotte et al.~and those generating the first feature rely exclusively on
the accelerometer's inclination(s). Hence, while they can determine time
in bed and participant's posture, they aren't precise indicators for
pinpointing exact in-bed and out-of-bed moments.

To provide a visual perspective, Figure~\ref{fig-screen_full} and
Figure~\ref{fig-screen_night} depict the Audacity interface displaying
all seven signal features as cataloged in
Table~\ref{tbl-man_signal_features}. Figure~\ref{fig-screen_full} offers
a glimpse of a week's data, whereas Figure~\ref{fig-screen_night} zooms
into an approximate 24-hour span, showcasing a single annotated night.

\newpage

\begingroup

\footnotesize

\hypertarget{tbl-man_signal_features}{}
\begin{longtable}{lll}
\caption{\label{tbl-man_signal_features}Summary of the specific signal features utilized in Audacity for the
accurate detection and analysis of in-bed periods. }\tabularnewline

\toprule
Name & Description & Values \\ 
\midrule
Lying & Classification based on thigh and back & 1: lying, -1: not lying \\ 
Activity & Activity type classification & 1: Standing, moving, 0: Sitting, -1: Other \\ 
Time & Time categorized into four-hour windows & Time categorized throughout 24 h cycle \\ 
Thigh-SDacc & Thigh longitudinal acceleration SD & -1: No movement \\ 
Thigh-Inclination & Thigh device inclination angle & Range: −180 to 180 degrees \\ 
Hip-SDacc & Hip longitudinal acceleration SD & -1: No movement \\ 
Hip-Inclination & Hip device inclination angle & Range: −180 to 180 degrees \\ 
\bottomrule
\end{longtable}

\endgroup

\begin{figure}

{\centering \includegraphics{figures/audacity_full_view.png}

}

\caption{\label{fig-screen_full}Screenshot of the Audacity interface
showing the seven horizontal panels representing the included signal
features. See Table~\ref{tbl-man_signal_features} for a detailed
description of the features.}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/audacity_single_night.png}

}

\caption{\label{fig-screen_night}Screenshot of the Audacity interface
when zoomed in on a single night for the labeling of the in-bed period.
The seven horizontal panels represent the included signal features. See
Table~\ref{tbl-man_signal_features} for a detailed description of
features.}

\end{figure}

\hypertarget{annotation-process-conducted-by-expert-raters}{%
\subsection{Annotation Process Conducted by Expert
Raters}\label{annotation-process-conducted-by-expert-raters}}

Three experienced researchers, well-versed in working with accelerometer
data, were chosen as raters. Their proficiency ensured that they had the
requisite knowledge to accurately interpret the various data channels
presented to them. Each rater meticulously reviewed and labeled each
wav-file, marking specific timestamps that indicated in-bed and
out-of-bed activities. These annotations were then saved as individual
text files. For ensuring consistency and reliability in the annotations,
each wav-file underwent two rounds of labeling. Importantly, at no point
during this process were the raters privy to any prior annotations,
either made by themselves or their colleagues.

\hypertarget{establishing-the-ground-truth-using-zm}{%
\subsection{Establishing the Ground Truth Using
ZM}\label{establishing-the-ground-truth-using-zm}}

The definitive ground truth for in-bed and out-of-bed time frames was
gleaned from the sleep staging data derived from the ZM. This was
established by identifying the first and last events at night that did
not present any sensor-related issues. Nights where the ZM detected
sensor problems, either at the onset or conclusion of the recording,
were excluded from further consideration. Such sensor issues typically
arise due to inadequate attachment of electrodes. To maintain accuracy
in data collection, all participants were meticulously instructed to
affix the ZM and activate it precisely at their bedtime and to detach it
upon waking. These crucial timestamps were then utilized as the ground
truth for the study.

\hypertarget{statistical-analysis}{%
\subsection{Statistical Analysis}\label{statistical-analysis}}

The statistical interpretations for this study were achieved using the R
statistical software (version 4.0.2, released on 22 June 2020) and its
complementary interface, RStudio (version 1.1.456). For continuous
variables, the descriptive attributes were gauged using medians and
interquartile ranges. Meanwhile, categorical variables were assessed
based on their proportions. To offer a clear distinction, the
characteristics for children and adults were presented separately.

The core of the statistical analysis encompassed agreement studies which
were executed using the intraclass correlation coefficient (ICC) and the
Bland--Altman analysis. Additionally, to provide a comprehensive visual
representation of the agreement and symmetry across methodologies,
probability density distribution plots were integrated. The ICC, as a
metric, goes beyond merely correlating two techniques; it evaluates if
they align in magnitude. The scale for interpretation is as follows:

\(ICC < 0.5\) signifies poor agreement

\(0.5 < ICC > 0.75\) indicates moderate agreement

\(0.75 < ICC > 0.9\) represents good agreement

\(ICC > 0.90\) underscores excellent agreemen

In this research, the ICC values were interpreted based on their 95\%
confidence intervals, adhering to recommended
guidelines\textsuperscript{\protect\hyperlink{ref-koo_guideline_2016}{100}}.
The Bland--Altman analysis, on the other hand, is a tool to measure the
concurrence between two measuring
techniques\textsuperscript{\protect\hyperlink{ref-bland_measuring_1999}{101}}.
It calculates the average of the differences (representing bias) between
the two methods, and also establishes the limits of this agreement. A
positive mean difference suggests an earlier underestimation of the
in-bed or out-of-bed timestamp relative to the ZM, while a negative
difference indicates a later overestimation.

\hypertarget{results}{%
\section{Results}\label{results}}

Descriptive characteristics of the included subjects of the current
study are reported in Table~\ref{tbl-man_describe}.

\begingroup

\footnotesize

\hypertarget{tbl-man_describe}{}
\begin{longtable}{ll}
\caption{\label{tbl-man_describe}Descriptive characteristics of the study participants. ISCE:
International Standard Classification of Education }\tabularnewline

\toprule
Characteristic &  \\ 
\midrule
\multicolumn{2}{l}{Children} \\ 
\midrule
N & 14 \\ 
Gender (\% female) & 28.6 \\ 
Age (years) & 9 (7–10) \\ 
\midrule
\multicolumn{2}{l}{Adults} \\ 
\midrule
N & 19 \\ 
Gender (\% female) & 57.9 \\ 
Age (years) & 42 (39–46) \\ 
Education Level &  \\ 
0–3 (\%) & 36.8 \\ 
4–6 (\%) & 47.4 \\ 
7–8 (\%) & 15.8 \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{intraclass-correlation-coefficient-analyses}{%
\subsection{Intraclass Correlation Coefficient
Analyses}\label{intraclass-correlation-coefficient-analyses}}

The analyses of Intra-Class Correlation (ICC) underscored an exemplary
consistency when comparing ZM's automatic in-bed annotations with manual
annotations. This was evident in both metrics assessed: time to bed and
time out of bed. The high agreement was consistent across both
evaluation phases---Round 1 and Round 2---and was observed in the
initial baseline as well as the subsequent follow-up assessments.
Reinforcing the robustness of these findings, the lower bounds of the
confidence intervals consistently remained above 0.9, suggesting a high
degree of reliability in the agreement. For a detailed breakdown of
these results, please refer to Table~\ref{tbl-man_icc_zm_man}.

\newpage

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_zm_man}{}
\begin{longtable}{llrl}
\caption{\label{tbl-man_icc_zm_man}Intraclass correlation coefficients between ZM and the average of the
manual annotations between the three raters. }\tabularnewline

\toprule
Action &  & ICC & 95\% CI \\ 
\midrule
\multicolumn{4}{l}{Baseline (n = 94 Nights)} \\ 
\midrule
To bed & Round 1 & 0.98 & (0.98; 0.99) \\ 
To bed & Round 2 & 0.98 & (0.96; 0.98) \\ 
Out of bed & Round 1 & 0.98 & (0.97; 0.99) \\ 
Out of bed & Round 2 & 0.98 & (0.96; 0.98) \\ 
\midrule
\multicolumn{4}{l}{Follow-Up (n = 54 Nights)} \\ 
\midrule
To bed & Round 1 & 0.96 & (0.94; 0.98) \\ 
To bed & Round 2 & 0.95 & (0.92; 0.97) \\ 
Out of bed & Round 1 & 0.98 & (0.97; 0.99) \\ 
Out of bed & Round 2 & 0.97 & (0.95; 0.98) \\ 
\bottomrule
\end{longtable}

\endgroup

In our analysis, we also identified a remarkable consistency between the
data from self-reports and the ZM measurements. This high level of
agreement was evident in both the initial baseline data as well as the
subsequent follow-up data. The strength of this agreement is underscored
by the fact that the lower limit of the 95\% confidence interval never
fell below a value of 0.94. For a detailed representation of this,
please refer to Table~\ref{tbl-man_icc_zm_self}.

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_zm_self}{}
\begin{longtable}{lll}
\caption{\label{tbl-man_icc_zm_self}Intraclass correlation coefficients between self-report and ZM. }\tabularnewline

\toprule
 & Baseline (N = 94) & Followup (N = 54) \\ 
\cmidrule(lr){2-2} \cmidrule(lr){3-3}
 & ICC (95\% CI) &  ICC (95\% CI) \\ 
\midrule
To bed & 0.98 (0.98; 0.99) & 0.96 (0.94; 0.98) \\ 
Out of bed & 0.98 (0.97; 0.99) & 0.98 (0.96; 0.99) \\ 
\bottomrule
\end{longtable}

\endgroup

Our analysis evaluated the agreement among three manual raters in
annotating timestamps for both `to bed' and `out of bed' events. The
Intraclass Correlation Coefficients (ICCs) from this evaluation
demonstrated strong consensus among the raters. Specifically, the lower
bounds of the 95\% confidence intervals were consistently strong, never
dropping below 0.88, highlighting both good and excellent agreement
levels. However, when analyzing the ICCs more closely, subtle variations
appear between the `to bed' and `out of bed' timestamps. This nuanced
observation is detailed in Table~\ref{tbl-man_icc_man_man}.

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_man_man}{}
\begin{longtable}{lll}
\caption{\label{tbl-man_icc_man_man}Intraclass correlation coefficients between manual raters. }\tabularnewline

\toprule
 & Round & ICC (95\% CI) \\ 
\midrule
\multicolumn{3}{l}{Baseline} \\ 
\midrule
To bed & Round 1 & 0.91 (0.88; 0.94) \\ 
Out of bed & Round 1 & 0.93 (0.9; 0.95) \\ 
To bed & Round 2 & 0.92 (0.89; 0.94) \\ 
Out of bed & Round 2 & 0.97 (0.96; 0.98) \\ 
\midrule
\multicolumn{3}{l}{Follow-Up} \\ 
\midrule
To bed & Round 1 & 0.94 (0.9; 0.96) \\ 
Out of bed & Round 1 & 0.97 (0.96; 0.98) \\ 
To bed & Round 2 & 0.97 (0.95; 0.98) \\ 
Out of bed & Round 2 & 0.98 (0.98; 0.99) \\ 
\bottomrule
\end{longtable}

\endgroup

The test-retest reliability exhibited good to excellent ICC agreement
for each rater between the first and second rounds, applicable to both
baseline and follow-up data (refer to
Table~\ref{tbl-man_icc_test_retest}). This robust reliability is further
evidenced by the 95\% confidence intervals having lower limits not less
than 0.86. While the ICCs across raters are broadly consistent, there's
a distinction: Raters 1 and 3 had slightly reduced agreement in their
baseline to-bed annotations relative to subsequent ones. In contrast,
Rater 2's ICC scores remained stable and didn't reflect this trend.

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_test_retest}{}
\begin{longtable}{lcccc}
\caption{\label{tbl-man_icc_test_retest}Test--retest intraclass correlation coefficients between the first and
second round of manual annotations. }\tabularnewline

\toprule
 & \multicolumn{2}{c}{Baseline (N = 110)} & \multicolumn{2}{c}{Followup (N = 62)} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
 & To Bed
ICC (CI 95\%) & Out of Bed
ICC (CI 95\%) & To Bed
ICC (CI 95\%) & Out of Bed
ICC (CI 95\%) \\ 
\midrule
Rater 1 & 0.91 (0.87; 0.94) & 0.98 (0.98; 0.99) & 0.96 (0.94; 0.98) & 1 (0.99; 1) \\ 
Rater 2 & 0.97 (0.96; 0.98) & 0.91 (0.87; 0.94) & 0.91 (0.86; 0.95) & 0.99 (0.98; 0.99) \\ 
Rater 3 & 0.91 (0.87; 0.94) & 0.96 (0.94; 0.97) & 0.98 (0.97; 0.99) & 0.98 (0.97; 0.99) \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{bland-altman-analyses}{%
\subsection{Bland-Altman Analyses}\label{bland-altman-analyses}}

Table~\ref{tbl-7} presents the bias and its corresponding confidence
intervals, as well as the upper and lower limits of agreement, comparing
manual annotation and self-report to ZM. The bias for manual annotation
relative to ZM ranges from -6 minutes to 5 minutes. In contrast, the
self-report exhibits a slightly smaller bias when compared to ZM.
Notably, the magnitude of the limits of agreement appears consistent
across both methods of comparison.

\begingroup

\footnotesize

\hypertarget{tbl-7}{}
\begin{longtable}{lccc}
\caption{\label{tbl-7}Bland--Altman analysis was conducted to assess the inter-method
agreement. This analysis compared manual annotation to ZM and also
compared self-report to ZM. All the measurements in the analysis are
presented in minutes. }\tabularnewline

\toprule
Method & Bias & Lower\_LOA & Upper\_LOA \\ 
\midrule
\multicolumn{4}{l}{Baseline, to bed, n = 94} \\ 
\midrule
Manual, round 1 & 3.02 (-0.44; 6.47) & 36.07 (30.15; 42) & -30.04 (-35.96;-24.12) \\ 
Manual, round 2 & 0.48 (-2.42; 3.39) & 28.27 (23.29; 33.24) & -27.3 (-32.28;-22.32) \\ 
Self-report & 1.23 (-1.57; 4.03) & 28.02 (23.21; 32.82) & -25.56 (-30.37;-20.76) \\ 
\midrule
\multicolumn{4}{l}{Baseline, out of bed, n = 94} \\ 
\midrule
Manual, round 1 & 0.53 (-2.34; 3.4) & 27.96 (23.05; 32.88) & -26.9 (-31.82;-21.99) \\ 
Manual, round 2 & 0.98 (-1.47; 3.43) & 24.45 (20.24; 28.66) & -22.49 (-26.7;-18.28) \\ 
Self-report & -2.79 (-5.26; -0.32) & 20.87 (16.63; 25.11) & -26.45 (-30.69;-22.21) \\ 
\midrule
\multicolumn{4}{l}{Follow-up, to bed, n = 54} \\ 
\midrule
Manual, round 1 & -6.08 (-11.34; -0.83) & 31.64 (22.61; 40.67) & -43.81 (-52.84;-34.77) \\ 
Manual, round 2 & -0.4 (-5.3; 4.51) & 34.8 (26.37; 43.23) & -35.6 (-44.03;-27.17) \\ 
Self-report & 0.77 (-4.08; 5.62) & 35.59 (27.25; 43.93) & -34.06 (-42.4;-25.72) \\ 
\midrule
\multicolumn{4}{l}{Follow-up, out of bed, n = 54} \\ 
\midrule
Manual, round 1 & 4.95 (0.65; 9.25) & 35.85 (28.45; 43.25) & -25.95 (-33.35;-18.55) \\ 
Manual, round 2 & 2.57 (-0.76; 5.89) & 26.44 (20.72; 32.15) & -21.3 (-27.02;-15.59) \\ 
Self-report & 0.56 (-3.62; 4.74) & 30.57 (23.39; 37.76) & -29.45 (-36.64;-22.26) \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{density-plots}{%
\subsection{Density Plots}\label{density-plots}}

Figure~\ref{fig-ridge_plot} presents the probability density
distribution of the differences between the ``to-bed'' and
``out-of-bed'' scorings, comparing manual annotations and self-reports
to ZM. These plots offer a visual illustration of the bias and spread
arond zero, showcasing how manual annotations and self-reports diverge
from ZM, as previously highlighted
in\textsuperscript{\protect\hyperlink{ref-van_hees_estimating_2018}{102}}.

\begin{figure}

{\centering \includegraphics{figures/paper1_ridge_plot.pdf}

}

\caption{\label{fig-ridge_plot}Probability density distributions for
differences between manual in-bed annotations and self-report compared
to ZM.}

\end{figure}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

In this study, we introduced a methodology for manually annotating
periods spent in bed using accelerometry data. The accuracy of this
method was rigorously evaluated through multiple raters and then
compared to sleep assessments made with EEG-based Zmachine Insight+®
(ZM) and self-reported sleep data. When examining the lower limit of the
95\% confidence interval in Intraclass Correlation Coefficient (ICC)
analyses, we found several noteworthy results. First, the method
exhibited good-to-excellent interrater reliability. Second, intra-rater
reliability also showed good to excellent agreement across all three
raters between their first and second rounds of annotations. Third, when
compared to ZM, the average manual in-bed annotations from all raters
ranged from good to excellent in terms of agreement. Fourth, the
self-reported in-bed timestamps were also in good to excellent agreement
with ZM. Additionally, Bland-Altman analysis indicated that the mean
bias between both the manual annotations and self-reported sleep times
compared to ZM was within a range of ±6 minutes, with Limits of
Agreement (LOA) not exceeding ±45 minutes. Probability density
distribution plots further substantiated these findings, showing
comparable symmetry, spread around zero, and positioning of outliers
when the manual annotations and self-reported sleep times were compared
to ZM.

The high accuracy observed in the prospective sleep diaries in this
study can be attributed to their being synchronized with Zmachine
Insight+® (ZM). Having participants manually start and end ZM recordings
every morning and evening enhances their ability to accurately recall
their times of going to bed and getting out of bed. This minimizes the
usual discrepancies often seen between objectively and subjectively
measured sleep
durations\textsuperscript{\protect\hyperlink{ref-aili_reliability_2017}{103}}.
If participants had been instructed to log their sleep using only
subjective measures without these protocol anchors, we would not expect
to see such strong agreement between the manual annotations, sleep
diaries, and ZM data.

Compared to ZM, our study found that the manual annotation of in-bed
periods was more prone to errors when estimating the time of going to
bed. This issue mainly arose from raters' difficulties in
differentiating between inactive behaviors before sleep and actual sleep
time. Despite this significant limitation, the manual annotation method
displayed reassuring accuracy, especially considering the limited formal
training provided to the raters. This ease of use was aided by the
specific signal features we selected for study in Audacity, as evidenced
by the excellent ICC scores among raters.

Interestingly, our findings suggest a learning curve for the raters, as
evidenced by the narrower LOAs and the density plots in the second round
of manual scoring. These indicators suggest that additional rounds of
scoring could further improve result consistency or that preliminary
training could be beneficial for the raters. Consequently, future
research should explore methods to optimize the uniformity of these
manual annotations.

While there are various tools available for annotating time series data,
such as Label
Studio\textsuperscript{\protect\hyperlink{ref-label_studio}{104}} and
Visplore\textsuperscript{\protect\hyperlink{ref-visplore}{105}}, our
study found that Audacity was particularly well-suited for the task at
hand. Label Studio, for example, may struggle with handling week-long
accelerometer data consisting of over 100 million entries, whereas
Audacity excels in managing and navigating such large data sets. Our
feature selection was intentionally designed to avoid overwhelming the
raters with redundant information, opting for a limited but effective
combination of features based on domain knowledge. This approach could
be adapted for annotating other behaviors, like walking, though that
would necessitate a different set of features.

The raters in this study gained valuable insights despite the absence of
explicit guidelines for data annotation, highlighting the intuitive
nature of the method. It's important to note that labeling data
inherently involves a certain level of understanding of human behavior.
If such labels could be accurately determined based on a set of formal
rules, it raises the question of whether training an AI model would even
be necessary. Therefore, we recommend additional research to identify
the most critical features for successful manual annotations. Examining
the impact of varying feature sets could yield further insights that
would streamline the manual annotation of accelerometer time series
data.

To date, many studies comparing actigraphy and self-report methods to
polysomnography (PSG) or EEG-based methodologies have focused primarily
on evaluating aggregate sleep parameters. These include total sleep
time, wake after sleep onset, sleep latency, and sleep efficiency. These
aggregate measures incorporate both sleep onset and wake onset times,
analogous to the ``to-bed'' and ``out-of-bed'' timestamps used in our
current study. However, the precision of these specific time points is
rarely assessed, making direct comparisons with our study's measurements
challenging.

Our novel method for annotating time in bed has produced Intraclass
Correlation Coefficient (ICC) values that are on par with, or even
better than, previous studies that compared actigraphy sleep parameters
to
PSG\textsuperscript{\protect\hyperlink{ref-haghayegh_application_2020}{81},\protect\hyperlink{ref-yavuz-kodat_2019}{106}}.
One such study cited mean absolute errors of 39.9 minutes for sleep
onset time and 29.9 minutes for wake-up time, with 95\% limits of
agreement exceeding ±3 hours when comparing an algorithm to
PSG\textsuperscript{\protect\hyperlink{ref-van_hees_estimating_2018}{102}}.
In contrast, our methodology allows for a more precise estimation of
specific timestamps rather than durations of behaviors, resulting in
less room for error and better agreements.

Moreover, our manual annotation method demonstrated robust performance
across various age and gender groups. The study sample included both
children and adults of both genders, suggesting that our approach is
accurate regardless of the specific behaviors associated with different
developmental age groups and genders. This finding also indicates that
our manual annotation method may offer higher precision in estimating
exact time points compared to existing automated methodologies. Given
that the accuracy of sleep parameter assessments is often highly
contingent on the target population, the results of our study have
promising implications for their broad generalizability, particularly
among populations of normal sleepers.

Identifying sleep periods as opposed to merely lying down is a critical
aspect of 24-hour behavior profiling. Traditional studies on sleep
detection often rely on participants to self-report their time in bed,
sleep onset, and wake-up
times\textsuperscript{\protect\hyperlink{ref-girschik_validation_2012}{32},\protect\hyperlink{ref-littner_2003}{107},\protect\hyperlink{ref-lockley_1999}{108}}.
However, the manual annotation methodology using Audacity offers an
alternative that not only reduces the burden on participants but also
mitigates the recall bias inherent in self-reported measures. This
method can be easily applied to free-living data, making it incredibly
versatile for various applications beyond sleep detection.

For instance, the methodology is useful for annotating non-wear time,
manually synchronizing clocks across different devices, and validating
raw data. Its applicability also extends to multi-channel data,
providing a comprehensive overview that can incorporate variables like
orientation from gyroscopic data, temperature, battery voltage, and
light. Audacity stands out for its capability to handle large
multi-channel data files effortlessly. Researchers can quickly zoom to
any resolution and scroll through time without experiencing lag, which
makes it an ideal tool for adding labels. This fluidity in workflow
suggests that Audacity could become a standard tool for researchers
working with raw data and machine learning applications. Thus, the
incorporation of this Audacity-based methodology into raw accelerometer
data annotation is poised to significantly contribute to future human
behavior research.

For years, the transition from raw sensor data to operational predictive
models has relied on labeled data. Despite this, no previous research
has offered a methodology that allows researchers to optimally utilize
their available accelerometry data. Our study demonstrates that with a
judicious selection of features, manual annotation for identifying sleep
periods can yield results comparable to those achieved with EEG-based
sleep classification hardware. However, it's crucial to clarify that we
are not advocating for our manual annotation method to replace more
established techniques for sleep estimation, such as EEG or
tracheal-sound-based methods, in ongoing studies. Instead, our
methodology can be valuable as a post-hoc procedure to enrich existing
datasets with an additional measure of sleep.

This study boasts several strengths, notably the continuous, multi-day
data collection of accelerometry, sleep diary, and ZM recordings carried
out in participants' homes, which provides high-quality free-living
data. However, the study is not without limitations. One such limitation
pertains to rater generalizability. The three manual raters were fixed,
not selected randomly from a broader pool of eligible raters with
varying characteristics. Nevertheless, given the minimal pre-briefing
instructions for labeling raw data, we believe this methodology could be
generalizable to other researchers working with accelerometer data.

A logical next step in this research would be to create and validate a
standardized procedure for manual sleep annotation, akin to what is
available for EEG-based sleep annotation in the AASM Scoring
Manual\textsuperscript{\protect\hyperlink{ref-aasm}{109}}. This would
make the methodology more accessible to individuals with limited
experience in the field of accelerometry. Another concern is the
challenge of recording true free-living behavior using
participant-mounted devices like ZM, as wearing such a device during
sleep could affect participants' natural behavior, thereby posing a
study limitation.

Moreover, although the criterion measure in our study has been validated
against PSG, utilizing PSG as the criterion measure would have been more
optimal. Finally, the study did not consider napping behavior; its focus
was solely on sleep as it relates to circadian rhythms. As such, future
research is required to validate the utility of this manual annotation
methodology for detecting naps.

\hypertarget{conclusions}{%
\subsection{Conclusions}\label{conclusions}}

In summing up, our study demonstrates that the use of Audacity for
manually annotating in-bed periods based on thigh- and hip-worn
accelerometer data aligns well with objective EEG-based sleep device
estimates and prospective sleep diaries. Our findings reveal minimal
mean bias and acceptable limits of agreement when comparing time to bed
and time out of bed across these different methods. Additionally, the
manual annotation process proved highly reliable, exhibiting excellent
inter- and intra-rater agreement. Its accuracy in relation to EEG-based
assessments was also comparable to that of sleep diaries. Importantly,
the manual annotation method can be applied to pre-existing raw data
that may not have accompanying sleep records. This offers a significant
advantage for making better use of free-living data resources. The
increased availability of such annotated data can be particularly
beneficial when training data-intensive machine learning algorithms,
potentially enhancing their generalizability in objectively assessing
human behavior.

\newpage

\hypertarget{paper-ii-generalizability-and-performance-of-methods-to-detect-non-wear-with-free-living-accelerometer-recordings}{%
\chapter{Paper II: Generalizability and Performance of Methods to Detect
Non-Wear With Free-Living Accelerometer
Recordings}\label{paper-ii-generalizability-and-performance-of-methods-to-detect-non-wear-with-free-living-accelerometer-recordings}}

This segment of the thesis encompasses the methods, results, and
discussion for Paper II. Wearable sensors, commonly used to track
physical activity, face challenges in detecting ``non-wear'' times.
While traditional methods use fixed interval heuristic algorithms, this
study explored decision trees that use raw acceleration and skin
temperature data. By training on thigh- and hip-worn devices from 64
children and validating with wrist-worn data from 42 adolescents,
results showed traditional methods excel for non-wear durations over 60
minutes. However, for durations below 60 minutes, decision tree models,
especially those with the top six predictors, were superior. The study
emphasizes method selection's significance and promotes external
validation for machine learning models in this area. Some of the details
presented here were previously mentioned in the published version of
Paper
I\textsuperscript{\protect\hyperlink{ref-skovgaard_generalizability_2023}{110}}.

\hypertarget{methods-1}{%
\section{Methods}\label{methods-1}}

The classification and generalizability of non-wear classification
methods were evaluated using free-living data collected from
accelerometers positioned on the wrist, thigh, and hip. This data
amalgamated findings from the Physical Activity in Schools After the
Reform
(PHASAR)\textsuperscript{\protect\hyperlink{ref-pedersen_protocol_2018}{111}}
study, which provided hip and thigh data, with an in-house validation
study that used wrist-worn accelerometers.
Figure~\ref{fig-paper2_flowchart} illustrates the data utilization
process. By leveraging these datasets, we ensured that established
non-wear classification methods underwent assessment on an external
dataset. Moreover, our decision tree models were tested on an
independent external dataset, including wear locations not initially
considered during model development. Therefore, all machine-learned
models underwent evaluation using test data from various anatomical
positions, regardless of their inclusion in the model's initial
development.

\hypertarget{reference-methods}{%
\subsection{Reference Methods}\label{reference-methods}}

To thoroughly evaluate and compare the performance of our three newly
developed algorithms, we incorporated four additional non-wear
classification methods. The selection of these existing methods was
grounded in our aim to span a broad range of methodological flexibility.
We specifically targeted techniques ranging from the most simplistic and
commonly used to the most recent and sophisticated.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textsf{\textbf{Consecutive Zeros-Algorithm (cz\_60):}} Over the
  years, there have been various consecutive zero-algorithms designed
  for accelerometer data, with the aim of identifying non-wear periods
  within stipulated timeframes, such as 30-, 60-, or 90-minute
  intervals\textsuperscript{\protect\hyperlink{ref-hecht_methodology_2009}{112}--\protect\hyperlink{ref-choi_validation_2011}{114}}.
  In addition, van Hees and colleagues have developed non-wear
  algorithms for raw acceleration using a 30-minute
  interval\textsuperscript{\protect\hyperlink{ref-van_hees_estimation_2011}{115}}.
  They later expanded this approach to include a 60-minute
  interval\textsuperscript{\protect\hyperlink{ref-rasmussen_short-term_2020}{93}}.
  Another method utilizes a 135-minute interval with adjusted
  hyperparameters, as introduced by Syed et
  al.\textsuperscript{\protect\hyperlink{ref-syed_evaluating_2020}{116}}.
  In our study, we adopted a straightforward approach to this concept.
  Using Actigraphy counts, we identified periods of no movement that
  registered zero counts for at least 60 continuous minutes. Notably,
  these Actigraphy counts operate with a deadband set at 68 mg, which
  denotes the minimum detectable acceleration threshold.
\item
  \textsf{\textbf{Heuristic Algorithm (heu\_alg):}} As detailed by
  Rasmussen and
  colleagues\textsuperscript{\protect\hyperlink{ref-rasmussen_short-term_2020}{93}},
  this algorithm merges raw acceleration data with surface skin
  temperature measurements. Non-wear time is determined for periods
  surpassing 120 minutes with accelerations less than 20 mg. For
  durations between 45 to 120 minutes, non-wear is identified if the
  temperature falls below a personalized non-moving temperature
  threshold. Additionally, the algorithm can spot non-wear periods
  ranging from 10 to 45 minutes, but only if these intervals end within
  the anticipated awake hours.
\item
  \textsf{\textbf{Random Forests Model(sunda\_RF):}} Sundararajan et
  al.\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{62}}
  delineated a non-wear classification technique grounded in a random
  forest ensemble model. This model was informed by raw accelerometer
  data derived from 134 participants aged between 20 to 70 years. These
  subjects were fitted with an accelerometer on their wrist for a
  singular overnight PSG session. The verifiable labels for non-wear
  periods were anchored in the assumption that the accelerometer was
  donned only during the PSG. Any epoch with a standard deviation in the
  acceleration signal exceeding 13.0 mg outside the PSG was classified
  as wear time. The model utilized 36 predictors, and a nested
  cross-validation method was employed both to ascertain the model's
  generalization capability and to refine its hyperparameters.
\item
  \textsf{\textbf{Deep Convolutional Neural Network (syed\_CNN):}} This
  method, introduced by Syed et
  al.\textsuperscript{\protect\hyperlink{ref-syed_novel_2021}{117}},
  employs a unique approach. It's built upon a deep convolutional neural
  network (CNN) that diverges from traditional techniques. Initially,
  all potential non-wear episodes are discerned using a standard
  deviation threshold. However, instead of scrutinizing the acceleration
  within these intervals, the focus shifts to the signal shape of the
  raw acceleration immediately before and after a non-wear episode.
  Through the CNN, the method discerns non-wear periods by detecting the
  moments when the accelerometer is removed and reattached. For our
  study's purposes, we chose a window length of 10 seconds on each side
  of the identified non-wear episode, as this yielded the most accurate
  results. The training dataset that informed the CNN consisted of data
  from hip-mounted accelerometers worn by 583 participants. These
  individuals ranged in age from 40 to 84 years, with an average age of
  62.74 and a standard deviation of 10.25.
\end{enumerate}

\hypertarget{data-collection-and-devices-used}{%
\subsection{Data Collection and Devices
Used}\label{data-collection-and-devices-used}}

Both the PHASAR study and the in-house validation research utilized the
Axivity AX3 accelerometer (Axivity Ltd., Newcastle upon Tyne, UK) to
record raw acceleration data along with surface skin temperature. The
device, weighing a mere 11 g and with dimensions of 23 mm × 32.5 mm ×
7.6 mm, measures acceleration in gravity units (g) across three axes
(vertical, mediolateral, and anteroposterior). The sampling frequencies
were set at 50 Hz for the PHASAR study and 25 Hz for the in-house study.
However, all recorded data from both studies were uniformly resampled to
30 Hz.

\hypertarget{description-of-the-studies}{%
\subsection{Description of the
Studies}\label{description-of-the-studies}}

\emph{PHASAR Study:} The PHASAR study involved a representative sample
of over 2000 school-aged children from 31 public schools in Denmark. The
study, conducted between 2017 and 2018, captured data from 1,315 boys
(49\%) and 1,358 girls (51\%), aged between 8.1 to 17.9 years (mean age
= 12.14, SD = 2.40). Accelerometers were placed at two specific
anatomical sites: the right hip and midway on the right thigh. They were
worn for a recommended seven consecutive days to reliably estimate
habitual physical activity. For this analysis, data from 64 randomly
selected participants from the PHASAR cohort were used. A dataset
indicating genuine non-wear time was created via manual annotation, a
method elaborated in another publication. Essentially, non-wear periods
were determined by visually examining raw accelerations coupled with
skin temperature readings. True non-wear episodes with specific start
and end times were manually labelled in each dataset and were utilized
as reference labels in subsequent analyses.

\emph{In-House Validation Study:} This study consisted of accelerometer
data from 42 youth athletes, evenly split between boys and girls, aged
14.5 to 16.4 years (mean age = 15.4, SD = 0.37 years). These athletes,
part of a specialized talent program in the Region of Southern Denmark,
wore the Axivity accelerometer on their non-dominant wrist for 14
consecutive days. This study was initiated in the spring of 2021. A
dataset mirroring the one from the PHASAR study was created, including
all 42 participants.

\hypertarget{ethical-considerations}{%
\subsection{Ethical Considerations}\label{ethical-considerations}}

The PHASAR study was reviewed by the Regional Committee on Health
Research Ethics for Southern Denmark (ID: S-20170031) and was determined
not to require an ethics review, as per Danish regulations, which
mandate only biomedical research or risk-involved studies to undergo a
formal ethics review. Documentation regarding this decision is available
upon request from the principal author. Conversely, the in-house
validation study received an ethical approval waiver from the Research
\& Innovation Organization and the legal department of the University of
Southern Denmark. All participants, or their legal guardians, provided
written informed consent for both studies, which adhered to the Danish
Data Protection Agency (2015-57-0008) standards and globally recognized
guidelines like the Declaration of Helsinki.

\begin{figure}

{\centering \includegraphics{figures/paper2_flowchart.pdf}

}

\caption{\label{fig-paper2_flowchart}The flowchart depicts the division
of the PHASAR dataset into training and testing segments. On the left,
boxes signify 79.2\% of the PHASAR data designated for training across
five-fold resamples. On the right, the yellow and blue boxes
collectively represent 20.2\% of the PHASAR data, specifically
delineating the hip and thigh data for testing. The green box represents
our separate in-house test dataset, which was gathered from wrist-worn
devices.}

\end{figure}

\hypertarget{development-of-decision-tree-models}{%
\subsection{Development of Decision Tree
Models:}\label{development-of-decision-tree-models}}

For our decision tree models, we sourced 12 predictors from the raw
PHASAR accelerometer data, which encompassed elements like temperature,
time of day, indicators for device placement, day of the week, and
moving average statistics (detailed in Table~\ref{tbl-8}). These moving
average metrics were collated in 10-second increments. To train the
model, we utilized 79.2\% of the PHASAR data, incorporating data from
both hip- and thigh-worn devices (as shown in
Figure~\ref{fig-paper2_flowchart}). A critical aspect of our methodology
was the data partitioning: we made certain that data from individual
participants was exclusively allocated to either the training or test
datasets. This strategy was crucial in ensuring that the model could
effectively generalize to unfamiliar data, rather than overfitting to
specific participant data. During the tuning phase, to boost model
accuracy and avoid overfitting, we opted for a five-fold
cross-validation approach. This process entailed refining several
hyperparameters, such as the tree's depth, its cost-complexity, and the
minimum amount of data points necessary in a node for it to split
further. To effectively explore the hyperparameter space, we employed
Latin hypercube sampling. This method systematically divides the
parameter range into segments, randomly drawing a value from each
segment, resulting in a well-distributed set of parameter combinations.
In our case, we established a 10-level parameter grid, guaranteeing a
comprehensive exploration of the hyperparameter space.

Following this procedure, we introduced three distinct model variations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A full-scope model (\emph{tree\_full}) incorporating every predictor.
\item
  A refined model (\emph{tree\_imp6}) centered on the six most crucial
  predictors, as established by permutation predictor importance
  (Figure~\ref{fig-importance}).
\item
  A model excluding surface skin temperature data
  (\emph{tree\_no\_temp}).
\end{enumerate}

In sum, our methodology generated 50 distinct models for each decision
tree variant. Given our data's distribution - 55.8\% wear time compared
to 44.2\% non-wear time - there was no need to adopt synthetic minority
oversampling methods like SMOTE or other balancing techniques.

\begingroup

\footnotesize

\hypertarget{tbl-8}{}
\begin{longtable}{ll}
\caption{\label{tbl-8}Predictors derived from the raw sensor signals. }\tabularnewline

\toprule
Predictor & Description \\ 
\midrule
Weekday & Day of week ([1:7]) \\ 
time\_day & Time of day (milliseconds) \\ 
Location & Device wear location: 0 = thigh, 1 = hip \\ 
macc\_x & Moving average of the z axis acceleration \\ 
macc\_y & Moving average of the y axis acceleration \\ 
macc\_z & Moving average of the z axis acceleration \\ 
sdacc\_x & Moving average of the standard deviation on the x axis acceleration \\ 
sdacc\_y & Moving average of the standard deviation of the y axis acceleration \\ 
sdacc\_z & Moving average of the standard deviation of the z axis acceleration \\ 
Sdmax & Maximum standard deviation \\ 
Incl & Inclination angle of the device in relation to the direction of the gravitational force \\ 
Temp & Surface skin temperature (degrees Celsius) \\ 
\bottomrule
\end{longtable}

\endgroup

\begin{figure}

{\centering \includegraphics{figures/paper2_vip.pdf}

}

\caption{\label{fig-importance}Permutation importance plot depicting the
significance of predictors in the decision tree. The top six predictors
informed the tree\_imp6 model, while a third model, tree\_no\_temp, was
trained using all predictors except temperature.}

\end{figure}

\newpage

\hypertarget{statistics}{%
\subsection{Statistics}\label{statistics}}

We assessed the classification performance to each ground truth test
dataset, which combined consisted of over 7 million 10-second epochs
from 104 distinct subjects. True positives (TP) represent correctly
identified non-wear time, and true negatives (TN) denote correctly
identified wear time. Both TPs and TNs are vital for the algorithm's
accuracy. These correct classifications are vital for the high accuracy
of our non-wear time algorithm. Misclassifications, where non-wear time
is labeled as wear and vice-versa, resulted in False Negatives (FN) and
False Positives (FP). To determine these classifications, we analyzed
the acceleration data in 10-second intervals, comparing inferred results
with ground truth labels. This comparison allowed us to construct a
confusion matrix. We then computed the overall accuracy, sensitivity,
precision, and F1-score to evaluate the effectiveness of each non-wear
detection method. Notably, a high F1-score, which is the harmonic mean
of precision and sensitivity, indicates superior classification
performance. We further delved into the permutation predictor importance
to discern the factors behind the enhanced performance of our decision
tree models. All our analyses and model developments were conducted
using R (version 4.1.2, Bird Hippie) and RStudio (version 2021.9.1.372,
Ghost Orchid), with Tidymodels for machine learning and the rpart
package serving as the decision tree algorithm engine.

\[accuracy = \frac{TP+TN}{TP+TN+FP+FN}\]
\[sensitivity = \frac{TP}{TP+FN}\] \[precision = \frac{TP}{TP+FP}\]
\[F_1 = 2 \cdot \frac{precision \cdot sensitivity}{precision + sensitivity}\]

The F1-score, which is the harmonic mean of precision and sensitivity,
provides an indicator of the classification performance. A high F1-score
suggests commendable classification prowess.

Additionally, we delved into the permutation predictor importance to
discern what factors contributed to the superior performance of certain
decision tree models.

For all analytical processes and model development, we utilized R
(version 4.1.2, Bird Hippie) and RStudio (version 2021.9.1.372, Ghost
Orchid). The machine learning tasks were primarily facilitated by the
Tidymodels\textsuperscript{\protect\hyperlink{ref-kuhn_tidymodels_2020}{118}}
suite of packages, and we used the
rpart\textsuperscript{\protect\hyperlink{ref-rpart}{119}} package as the
engine for our decision tree algorithms.

\hypertarget{results-1}{%
\section{Results}\label{results-1}}

In our gold standard datasets spanning three wear locations, there were
1,598 non-wear time episodes. Of these, 1,148 episodes (or 71.8\%)
lasted 60 minutes or more, with an average duration of about 13 hours
(794 minutes with a standard deviation of 1,142 minutes). In contrast,
episodes lasting 60 minutes or less made up 28.2\% (450 episodes) with
an average duration of 26.4 minutes (SD = 16.4). Interestingly, the
briefest episodes (less than 60 minutes) made up just 1.3\% of the total
non-wear time across all wear locations (refer to Table~\ref{tbl-9}).
Figure~\ref{fig-paper2_nw_dists} depicts the frequency distribution for
episodes shorter than 60 minutes and those 60 minutes or longer. The
PHASAR dataset showed a bimodal distribution for shorter episodes, with
longer episodes peaking around 10 hours. For the in-house wrist-worn
dataset, shorter episodes displayed a uniform distribution, while longer
episodes were significantly right-skewed.

\begingroup

\footnotesize

\hypertarget{tbl-9}{}
\begin{longtable}{lrrr}
\caption{\label{tbl-9}Overview of non-wear episodes grouped in short and long non-wear
episodes. ¹ Aggregated in minutes. ² Proportion of total non-wear time
by wear location. }\tabularnewline

\toprule
Wear location & Mean¹ & Cumulated¹ & Proportion² \\ 
\midrule
\multicolumn{4}{l}{<60 minutes} \\ 
\midrule
hip & $28$ & $3,202$ & $1.1\%$ \\ 
thigh & $25$ & $3,975$ & $1.4\%$ \\ 
wrist & $27$ & $4,691$ & $1.3\%$ \\ 
\midrule
\multicolumn{4}{l}{≥60 minutes} \\ 
\midrule
hip & $828$ & $279,785$ & $98.9\%$ \\ 
thigh & $776$ & $280,294$ & $98.6\%$ \\ 
wrist & $782$ & $351,179$ & $98.7\%$ \\ 
\bottomrule
\end{longtable}

\endgroup

\begin{figure}

{\centering \includegraphics{figures/paper2_plot_nw_dists.pdf}

}

\caption{\label{fig-paper2_nw_dists}Distribution of the length of the
non-wear episodes across hip, thigh, and wrist data. Distributions are
shown for episodes shorter than 60 min (binwidth = 1 minute) and longer
than 60 min (binwidth = 1 hour).}

\end{figure}

\hypertarget{classification-performance}{%
\subsection{Classification
Performance}\label{classification-performance}}

In assessing classification performance,
Figure~\ref{fig-paper2_preds_ex} visually contrasts the results from
machine-learned models and rule-based algorithms against the ground
truth non-wear time, which is highlighted with a light blue background.
This visualization underscores that while tree-based models tend to be
precise, they can also be unpredictable. On the other hand,
threshold-based methods, such as Syed\_CNN, heu\_alg, and cz\_60, offer
more consistency. Notably, both cz\_60 and heu\_alg algorithms fall
short in identifying shorter non-wear episodes.

Detailing further, Figure~\ref{fig-paper2_performance_all} compiles
performance metrics from all methods evaluated in this study. The CNN
model by Syed et al.~demonstrated consistency across three datasets,
achieving an overall accuracy between 75\% and 80\%. It stood out with a
sensitivity score between 93\% and 96\%. However, its F1 scores, which
hovered between 82\% and 84\%, were hampered by only average precision.
Conversely, the random forests model by Sundararajan et al.~shone with
wrist data, boasting an F1 score of 94\% and accuracy of 93\%. Still,
its performance dwindled with hip and thigh data, marking an overall
accuracy of 56\% and precision of 59\%. This drop suggests a significant
number of false positives.

Among the decision tree models, the variant excluding surface skin
temperature as a predictor fared the poorest for wrist data, achieving a
mere 72\% accuracy. While it secured a high sensitivity score of 98\%,
its subpar precision dragged its F1 score down to 81\%. The other two
decision tree models---one incorporating the six most critical
predictors and the other using all predictors---consistently performed
well across metrics and datasets. Remarkably, both the heu\_alg and
cz\_60 algorithms approached perfection across evaluations.

Further, Figure~\ref{fig-paper2_performance_short} zeroes in on
performance metrics for episodes 60 minutes or shorter. The consecutive
zeros algorithm was unable to detect any non-wear, a result absent from
the figure. Syed et al.'s deep learning model underperformed, detecting
a mere 1--2\% of all non-wear time, leading to F1 scores below 5\%.
Although the heu\_alg algorithm boasted high precision, its lackluster
sensitivity resulted in F1 scores spanning from 12\% to 16\% across wear
locations. The random forest model displayed average results for thigh
and wrist data but faltered with hip data, recording F1 scores of 46\%,
57\%, and 8\%, respectively. Among the trio of decision tree models, the
one leveraging the six pivotal predictors outshone the rest, with F1
scores between 72\% and 79\%. Meanwhile, the decision tree model
encompassing all predictors faced challenges with hip data due to a 23\%
sensitivity score. Excluding the surface skin temperature, another
decision tree model exhibited commendable precision; however, its low
sensitivity culminated in F1 scores ranging from 45\% to 57\%.

\begin{figure}

{\centering \includegraphics{figures/paper2_plot_preds_example.pdf}

}

\caption{\label{fig-paper2_preds_ex}Visual example of the output of
non-wear detection models and algorithms for a random person from the
in-house wrist dataset (14 consecutive days). The grey shade is
ground-truth non-wear time. Syed\_CNN, cz\_60, and tree\_full are
vertically offset for easier interpretation.}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/paper2_performance_all.pdf}

}

\caption{\label{fig-paper2_performance_all}Classification performance
metrics on all non-wear episodes for the seven included methods for
classifying non-wear time. Metrics are shown for the three different
ground-truth dataset including hip-worn, thigh-worn, and wrist-worn raw
accelerometer data.}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/paper2_performance_short.pdf}

}

\caption{\label{fig-paper2_performance_short}Classification performance
for episodes no longer than 60 min in length. Metrics are shown for the
three different gold-standard dataset including hip-worn, thigh-worn,
and wrist-worn raw accelerometer data.}

\end{figure}

\hypertarget{discussion-1}{%
\section{Discussion}\label{discussion-1}}

In our study, we evaluated various methods for classifying non-wear
episodes in accelerometer data, focusing on episodes longer than 60
minutes and those shorter than 60 minutes. Our findings showed that the
simplest methods, specifically cz\_60 and heu\_alg, excelled in
identifying non-wear episodes longer than 60 minutes across all three
sensor wear locations: wrist, hip, and thigh. They were closely followed
in performance by decision tree models that included surface skin
temperature as a predictive variable. On the other hand, the random
forest model demonstrated excellent performance only on the wrist,
delivering mediocre results on the hip and thigh. When we shifted our
focus to short non-wear episodes lasting less than 60 minutes, we found
limitations in the cz\_60 and heu\_alg algorithms due to their built-in
minimum episode durations of 60 and 20 minutes, respectively. As a
result, their performance was poor for these shorter episodes.
Similarly, the deep learning model showed poor results, mainly
attributable to a low sensitivity score that led to many episodes being
misclassified as non-wear time. The random forest model's performance
was also poor on the hip and only mediocre on the thigh and wrist.
Decision tree models, both without temperature and with all predictors,
showed mediocre performance as well. However, a decision tree model
trained on the six most important predictors stood out as the best
performer for short non-wear episodes. Our study also highlighted the
value of incorporating surface skin temperature as a predictor to
enhance the performance of non-wear time classification. Overall, these
results provide valuable insights into the effectiveness of various
methods for classifying non-wear episodes in accelerometer data,
emphasizing the potential of simple algorithms like cz\_60 and heu\_alg,
especially for longer episodes, and the benefit of including surface
skin temperature as a predictive variable.

We discovered that most non-wear episodes in our ground truth datasets
had a duration exceeding 60 minutes, with a noticeable peak around the
10-hour mark. This finding contrasts with previous research that
typically reported shorter episodes as being more
prevalent\textsuperscript{\protect\hyperlink{ref-jaeschke_variability_2018}{95},\protect\hyperlink{ref-aadland_comparison_2018}{120},\protect\hyperlink{ref-hutto_identifying_2013}{121}}.
Our data prominently features children and physically active
adolescents, a demographic known to spend less time in sedentary
activities and to frequently interrupt such
periods\textsuperscript{\protect\hyperlink{ref-cooper_objectively_2015}{122},\protect\hyperlink{ref-kwon_breaks_2012}{123}}.
This likely contributed to both the longer non-wear episodes and
clarified the differentiation between sedentary behavior and non-wear
time in our study. The data favored simple heuristic algorithms for
classifying non-wear time, largely because the limitations imposed by
minimum window lengths had a negligible impact on the proportion of
non-wear time that was incorrectly classified. These algorithms achieved
excellent precision scores, confirming that neither sedentary time nor
sleep was misclassified as non-wear time. This is a significant finding,
given that multiple previous studies have pointed out the complexities
in making this very
distinction\textsuperscript{\protect\hyperlink{ref-barouni_ambulatory_2020}{90},\protect\hyperlink{ref-troiano_physical_2008}{113},\protect\hyperlink{ref-choi_validation_2011}{114},\protect\hyperlink{ref-duncan_wear-time_2018}{124},\protect\hyperlink{ref-doherty_large_2017}{125}}.
Our study suggests that a consecutive zeros algorithm could be deemed
best practice for capturing non-wear episodes lasting over 60 minutes in
children and adolescents. This recommendation is applicable across the
various wear locations that we evaluated, including the hip, thigh, and
wrist. However, it's important to consider that the specific behaviors
of children and adolescents may not make these findings directly
transferable to older adults. Yet, certain standardized procedures like
the syed\_CNN model for mounting and unmounting accelerometers might
have more universal applicability.

Creating a model to classify non-wear time appears to be a relatively
straightforward task, likely because the decision boundary involved is
close to linear. In this context, the use of complex models, as we've
included in our current study, may lead to overfitting. This overfitting
would capture random variations specific to the training dataset,
thereby reducing the model's ability to generalize to new, unseen data.
Consequently, we hypothesize that a well-optimized logistic regression
model could perform just as well as the more intricate methodologies
we've tested. The reason for this is that a logistic regression model
would establish a separating linear hyperplane capable of distinguishing
between wear and non-wear time effectively. Therefore, employing highly
non-linear models for this classification task might be an unnecessary
complication, particularly if the goal is to develop a machine learning
model that can be applied across diverse populations and wear locations.
It is also crucial to enrich the training data with multiple wear
locations and various physical activity profiles to improve
generalizability.

Incorporating surface skin temperature for the classification of
non-wear time has been minimally explored in the realm of machine
learning. One study did indicate that using acceleration data along with
rate-of-change in surface skin temperature could create a robust
decision tree model for detecting non-wear
time\textsuperscript{\protect\hyperlink{ref-vert_detecting_2022}{126}}.
This aligns with previous heuristic studies that have shown improved
predictive performance when temperature data is
included\textsuperscript{\protect\hyperlink{ref-duncan_wear-time_2018}{124},\protect\hyperlink{ref-zhou_classification_2015}{127}}.
Our own findings also corroborate this, as we observed that adding
surface skin temperature as a variable significantly enhances the
performance of the non-wear time model. However, a critical
consideration is the precise detection of the transition between wear
and non-wear periods, especially given the slow temperature step
response time of sensors. Solely relying on temperature data could
introduce classification delays if the sensor's response time is
sluggish. Combining both temperature and acceleration data is therefore
a more effective
approach\textsuperscript{\protect\hyperlink{ref-zhou_classification_2015}{127}}.
During our study, we noted a 20-minute step response in the Axivity
temperature sensor, which could be attributed to the design of the
device's casing. The sensor's response time may also be influenced by
the attachment method used. If more material is placed between the skin
and the device, delays are likely to occur, suggesting that machine
learning models should perhaps consider the type of sensor attachment in
their algorithms. Additionally, different brands of devices have been
found to have varying optimal temperature thresholds, further
complicating the issue. As noted by Duncan et al.~and Zhou et al.,
algorithmic modifications are needed for devices to function optimally
in different
latitudes\textsuperscript{\protect\hyperlink{ref-duncan_wear-time_2018}{124},\protect\hyperlink{ref-zhou_classification_2015}{127}}.
Therefore, the type of device and its attachment method can be critical
variables for improving the accuracy of non-wear time classification
models.

In the study of accelerometry data processing, the ideal scenario is to
employ a single model that performs reliably across different wear
locations and populations. To evaluate the generalizability and
robustness of the methods used in our study, we included a dataset from
wrist-worn devices for external validation. This ensures that the
performance metrics of our decision tree models are not artificially
inflated due to overfitting or lack of variance between the training and
testing data. External validation involves testing a model with
independently sourced datasets to confirm its performance. If a
predictor set has been inaccurately selected due to characteristics
inherent to the training data, such as technical or sampling bias, it is
likely to perform poorly during external
validation\textsuperscript{\protect\hyperlink{ref-steyerberg_prediction_2016}{128}}.
The rationale behind using external validation is strong: while data
from different sources may have fewer similarities, they can nonetheless
capture important domain-relevant information. A model trained to
identify truly informative predictors will maintain its performance even
when exposed to new data. Therefore, the external validation in our
study acts as a verification step, ensuring that our decision tree
models that pass this criterion are not just robust but also likely to
be interpretable within the
domain\textsuperscript{\protect\hyperlink{ref-altman_prognosis_2009}{129}}.
While Syed et al.'s methodology for identifying non-wear time is
innovative and logically coherent, we believe its performance may vary
depending on the age of the population in the dataset. The approach by
Syed et al.~focuses on identifying the specific shape of the
acceleration signal at the start and end of a non-wear episode. In
contrast, methods that simply identify non-wear time based on the
absence of acceleration are less dependent on the characteristics of the
population, since zero movement during non-wear is a universal trait.

Our results support this idea. The Convolutional Neural Network (CNN)
model developed by Syed et al.~showed poor performance across all wear
locations in our study. One possible reason for this could be the age
differences in the populations of the datasets. The original model was
trained on an older population, aged between 40-84 years (mean = 62.74,
SD = 10.25), whereas our study involved datasets of younger individuals
aged 8.1-17.9 years (mean = 12.14, SD = 2.40) for hip and thigh data,
and 14.5-16.4 years (mean = 15.4, SD = 0.37) for wrist data.
Contrastingly, the sunda\_RF model showed acceptable performance in
identifying non-wear episodes shorter than 60 minutes on both the thigh
and wrist data. This suggests that the model by Sundararajan et al.~is
less affected by population characteristics, as anticipated, compared to
the syed\_CNN model. Another point worth noting is that the syed\_CNN
model was originally trained on data with a frequency of 100 Hz, while
we applied it to data with frequencies of 50 Hz and 25 Hz. Although it's
unclear whether this frequency difference impacted the model's
performance, we believe that the 25 Hz data is sufficient for capturing
true movement behavior, given that movement frequencies are generally
below 5 Hz.

While it's standard to evaluate a machine learning model using a test
split from the same dataset used for training, known as internal
validation, this approach has its limitations. For instance, Syed et
al.~and Sundararajan et al.~report high metrics like sensitivity,
specificity, and accuracy for classifying non-wear time, but these
results are derived from cross-validation without an external validation
dataset\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{62},\protect\hyperlink{ref-syed_evaluating_2020}{116}}.
The absence of external validation raises questions about the models'
generalizability. Highly flexible models, without rigorous testing on
independent datasets, risk overfitting or learning dataset-specific
nuances rather than broader, more generalizable characteristics. This
concern is particularly relevant for Syed et al.'s model. Their
methodology could become more robust with training data from a more
varied population and a greater number of participants. Differences in
signal shapes for mounting and unmounting devices may vary with age or
other population characteristics, making a diverse training set
essential for improved generalizability. Given these challenges, future
research should focus on validating models with independent external
datasets prior to publication. While we recognize that accumulating
large and diverse datasets may not always be practically feasible, the
benefits in terms of model reliability and generalizability make it an
important consideration for future work.

The robustness of this study is significantly enhanced by the use of
external validation, which offers strong evidence of methodological
generalizability. However, there are limitations to consider. One major
issue is the absence of a universally accepted gold standard for ground
truth datasets in this research area. This lack of a benchmark makes it
challenging to compare performance metrics across different studies.
Despite this, our approach remains transparent since it relies on raw
accelerometer data, and no part of our data collection or analysis
process is proprietary. It's important to note that our findings are
based on a study population consisting of children and adolescents.
Consequently, the results may not be directly applicable to older age
groups. Additionally, while we chose to develop a decision tree model
for its balance of complexity and interpretability, future research
could explore the efficacy of other machine learning methods like
logistic regression, gradient boosting, or support vector machines.
These alternative algorithms may offer different insights or advantages
that could improve upon our current model.

\hypertarget{conclusions-1}{%
\subsection{Conclusions}\label{conclusions-1}}

In this study, we examine the effectiveness and generalizability of both
existing techniques and our newly-developed decision tree models for
classifying non-wear periods in accelerometer data collected in
free-living conditions. While current heuristic methods offer promising
results, they come with inherent limitations. On the other hand, our
findings suggest that some of the newer, more complex machine learning
methods may be prone to overfitting. The quality and quantity of data
are pivotal factors in training a machine learning model, especially for
a straightforward binary classification problem like this, where the aim
is to make the model generalizable to different datasets. To mitigate
over-optimistic projections about a model's performance on unseen data,
we strongly recommend the use of external validation. Additionally,
given the importance of accurately detecting non-wear time as the
initial step in analyzing accelerometer data, we urge researchers to
carefully choose an appropriate method for this critical task.

\newpage

\hypertarget{paper-iii-improving-sleep-quality-estimation-in-children-and-adolescents-a-comparative-study-of-machine-learning-and-deep-learning-techniques-utilizing-free-living-accelerometer-data-from-thigh-worn-devices-and-eeg-based-sleep-tracking}{%
\chapter{Paper III: Improving Sleep Quality Estimation in Children and
Adolescents: A Comparative Study of Machine Learning and Deep Learning
Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn
Devices and EEG-Based Sleep
Tracking}\label{paper-iii-improving-sleep-quality-estimation-in-children-and-adolescents-a-comparative-study-of-machine-learning-and-deep-learning-techniques-utilizing-free-living-accelerometer-data-from-thigh-worn-devices-and-eeg-based-sleep-tracking}}

This segment of the thesis encompasses the methods, results, and
discussion for Paper III. Polysomnography, the premier method for sleep
evaluation, is not always feasible for extensive research due to its
high costs and impracticality. Wearable accelerometers present an
affordable solution. While wrist and hip-worn devices dominate sleep
studies, the potential of thigh-worn accelerometers remains largely
untapped. This paper delves into the use of machine learning and deep
learning models that leverage data from thigh-worn accelerometers to
gauge sleep and its quality. By comparing these models with an EEG-based
sleep monitor and utilizing data from 585 days and nights of children
aged 4-17 years, we discerned that the XGBoost model, particularly when
applied to 5-minute median filtered data, showcased the most promise.
This model demonstrated minimal biases and a robust correlation with
total sleep time, highlighting its applicability. Nevertheless, our
findings also exposed certain limitations, especially in determining
awake intervals during in-bed periods. Thus, while our results are
encouraging for group-level sleep quality estimation using machine
learning, further refinement is essential for precise individual
assessments due to observed limits of agreement in thigh-worn
accelerometry data.

\hypertarget{methods-2}{%
\section{Methods}\label{methods-2}}

\hypertarget{dataset-and-participants}{%
\subsection{Dataset and Participants}\label{dataset-and-participants}}

The current study uses data from the SCREENS trial, which took place
from June 2019 to March 2021 in the Region of Southern Denmark.
Conducted by Rasmussen and
Pedersen\textsuperscript{\protect\hyperlink{ref-rasmussen_short-term_2020}{93},\protect\hyperlink{ref-pedersen_effects_2022}{130}},
the trial aimed to evaluate the impact of limiting screen media usage
among Danish families. We specifically analyzed data from children
between the ages of 4 and 17, with a mean age of 9.1 years, who were
part of the SCREENS cohort. To gather our primary data, we utilized
accelerometer readings from Axivity AX3 devices attached to the
children's thighs and sleep metrics derived from EEG readings using the
ZM device by General Sleep Corporation.

The Axivity AX3 is a 3-axis accelerometer positioned midway between the
hip and knee on the right anterior thigh. This device records movement
data, and it is unobtrusive, allowing for natural behavior from the
children. On the other hand, the ZM device uses advanced EEG hardware
and signal processing algorithms to gather sleep data. It features three
self-adhesive, disposable sensors placed outside the hairline, ensuring
reliable EEG signal acquisition. Participants were instructed to attach
the device at bedtime and remove it upon leaving bed. To process the
sleep data, the ZM device uses two proprietary algorithms, Z-ALG and
Z-PLUS. The former is known for its accurate sleep detection
capabilities, which make it suitable for in-home monitoring as supported
by Kaplan et
al.\textsuperscript{\protect\hyperlink{ref-kaplan_performance_2014}{97}},
while the latter differentiates between sleep stages and aligns well
with expert evaluations using PSG data, as demonstrated by Wang et
al.\textsuperscript{\protect\hyperlink{ref-wang_evaluation_2015}{96}}.

In this study, we didn't focus on different sleep stages like light
sleep (N1 \& N2), deep sleep (N3), and REM sleep; instead, we
categorized the output of the ZM into ``awake'' and ``asleep.'' This
simplification was made to streamline the data for the machine learning
algorithms and because distinguishing between sleep stages was not
crucial for the sleep quality metrics of interest. As illustrated in
Figure~\ref{fig-paper3_flow}, we only considered recordings that had
complete accelerometer data from the Axivity AX3 and ZM readings lasting
between 7 and 14 hours. Recordings with sensor issues reported by the ZM
were excluded. As a result, our study included a total of 585 nights
from 151 children, with an average of 3.87 nights per child (SD = 1.86).
The mean age of these children was 9.4 years, with a standard deviation
of 2.1. Our study encompassed 696,779 epochs, each lasting 30 seconds,
and about 84\% of the ZM recordings were classified as sleep.

Lastly, the study adhered to ethical guidelines, receiving approval from
the Regional Scientific Committee of Southern Denmark. All data handling
processes were in compliance with the General Data Protection Regulation
(GDPR), ensuring the secure and ethical management of participant
information.

\begin{figure}

{\centering \includegraphics{figures/paper3_flowchart.pdf}

}

\caption{\label{fig-paper3_flow}Flowchart of eligible ZM recording
nights included in the study.}

\end{figure}

\hypertarget{data-preprocessing-and-feature-extraction}{%
\subsection{Data preprocessing and Feature
Extraction}\label{data-preprocessing-and-feature-extraction}}

In this study, we began by processing raw accelerometer data through a
low-pass filtration step, utilizing a 4th order Butterworth filter with
a 5 Hz cut-off frequency to remove high-frequency noise as described by
Skotte and
colleagues\textsuperscript{\protect\hyperlink{ref-skotte_detection_2014}{99}}.
Non-wear data was identified and eliminated using the methods outlined
in Paper
2\textsuperscript{\protect\hyperlink{ref-skovgaard_generalizability_2023}{110}},
and the remaining data was resampled into 30-second epochs to align with
ZM recordings. We then conducted feature extraction, generating 64
features that offered a comprehensive characterization of the data.
These features were derived from both accelerometer and temperature
signals and included temporal elements, which utilized both lag and lead
values to capture dynamic data trends. Additionally, we took inspiration
from Walch et
al.\textsuperscript{\protect\hyperlink{ref-walch_sleep_2019}{131}} to
include sensor-independent features that encapsulate circadian rhythms,
offering unique insights that are not directly discernible from sensor
outputs (see Figure~\ref{fig-paper3_sensor_independent}). We further
enriched the feature set by incorporating signal characteristics such as
vector magnitude, mean crossing rate, skewness, and kurtosis for each of
the x, y, and z dimensions. The ZM recordings and the corresponding
accelerometer data were then merged. Any time overlap between these two
sets of data was categorized as `in-bed' time, while the remaining time
was considered `out-of-bed.' This process yielded a comprehensive
dataset that provided a 24-hour view of each participant's activity and
sleep patterns.

Upon examining the raw ZM predictions, we observed that the device
appeared to overestimate the number of awakenings among the children
studied. Although the ZM software addresses many of these awakenings by
counting only three consecutive awake epochs towards wake time, this
approach renders the raw predictions less suitable as training data for
machine learning algorithms. In fact, many of these awakenings, labeled
by the ZM, would be more aptly described as arousals rather than actual
awakenings. Separately, the ZM device's sleep efficiency rating for our
sample was 83\%, which is below recognized standards. An efficiency of
85\% is considered good, and over 90\% is seen as ideal. This contrasts
with prior research on similar child cohorts that reported a sleep
efficiency of
88.3\%\textsuperscript{\protect\hyperlink{ref-galland_2018}{132}}.
Recommendations from an expert panel by the National Sleep Foundation
emphasize that fewer than 2 awakenings lasting more than 5 minutes each
night qualify as good sleep across all age
groups\textsuperscript{\protect\hyperlink{ref-ohayon_2017}{133}}.
Additionally, it's widely recognized that children typically experience
between five to eight sleep cycles every night, with awakenings most
likely occurring at the conclusion of each
cycle\textsuperscript{\protect\hyperlink{ref-galland_normal_2012}{134}}.
However, definitions of a ``waking bout'' vary across studies. Some
demand at least 5 continuous minutes of wakefulness for it to be counted
as one bout, while others find a 1-minute duration adequate. Of
particular note, many short arousal epochs labeled as awake by the ZM
did not show significant shifts in the accelerometer signal. This
misalignment might distort underlying patterns for machine learning
algorithms. While this might not be outright mislabeling, categorizing
all such epochs as true awakenings could introduce noise, jeopardizing
model accuracy. In light of these observations, we opted to process both
the raw ZM output and versions with 5-minute and 10-minute median
filtering for our model training and evaluation. This approach minimized
noise and offered an awakening count more aligned with typical patterns
in children's sleep (see Table~\ref{tbl-10} for details).

\begin{figure}

{\centering \includegraphics{/home/esbenlykke/projects/thesis/figures/paper3_sensor_independent.pdf}

}

\caption{\label{fig-paper3_sensor_independent}Sensor-independent
features of circadian rhythms across two consecutive nights. A) cosinus
feature, B) linear feature.}

\end{figure}

\begin{figure}

{\centering \includegraphics{/home/esbenlykke/projects/thesis/figures/paper3_zm_raw_vs_filtered.pdf}

}

\caption{\label{fig-paper3_raw_filt}The difference in number of
awakenings between the raw ZM predictions vs.~5-minute, and 10-minute
median filtered predictions for a random night (boy, 9 years). Grey line
is the raw predictions, black line is the median filtered predictions.
A: 5-minute median filter on raw ZM predictions, B: 10-minute median
filter on raw ZM predictions.}

\end{figure}

\hypertarget{algorithms}{%
\subsection{Algorithms}\label{algorithms}}

In our study to assess sleep patterns, we utilized thigh-mounted
accelerometer data and employed two distinct modeling strategies. The
first approach involved a sequential strategy using a series of binary
classifiers, aiming to simplify the task by breaking down the multiclass
problem into more manageable parts. Initially, we predicted `in-bed'
times, which were then subjected to a 5-minute median filter to
eliminate transient blips. This allowed us to identify a single
continuous time interval, termed the Sleep Period Time (SPT), which
represents the total time spent in bed attempting to sleep. The SPT
served as the input for a second set of binary classifiers focused on
predicting `sleep' time, thereby improving their predictive accuracy.

Four machine learning algorithms were applied in this sequential
strategy. Logistic regression acted as a fast and straightforward
baseline model, although its linear nature limited its ability to
capture complex, non-linear patterns. Decision trees, capable of
handling non-linear patterns, were implemented with a maximum tree depth
of 8 to mitigate overfitting and maintain easy interpretability.
Single-layer feed-forward neural networks, while challenging to
interpret, were effective in capturing non-linear relationships. Careful
tuning was required to avoid overfitting. Lastly, XGBoost was used for
its high accuracy and built-in overfitting prevention techniques,
despite its computational intensity and interpretational challenges.

Simultaneously, we also explored a second modeling strategy using a
multiclass algorithm based on a bidirectional Long Short-Term Memory
(biLSTM) neural
network\textsuperscript{\protect\hyperlink{ref-hochreiter_long_1997}{135}}.
This model was designed to predict three distinct sleep states:
`out-of-bed-awake,' `in-bed-awake,' and `in-bed-asleep.' It featured
four layers and 128 hidden units per layer, balancing model complexity
and training efficiency. The bidirectional architecture doubled the
hidden units at each time step, enhancing data interpretation and
reducing the risk of overfitting. The model accepted sequences of
tensors spanning 10 minutes with a step size of one epoch. This approach
is supported by previous research such as studies by Sano et
al.~(2019)\textsuperscript{\protect\hyperlink{ref-sano_multimodal_2019}{136}}{]}
and Chen et
al.~(2021)\textsuperscript{\protect\hyperlink{ref-chen_attention_2021}{137}}{]},
which have demonstrated the efficacy of LSTM models in sleep detection
by capturing complex temporal patterns in accelerometer data.

\hypertarget{model-training}{%
\subsection{Model Training}\label{model-training}}

We trained a total of four pairs of models sequentially to distinguish
between two sets of states: in-bed/out-of-bed and asleep/awake. The
dataset was randomly split into a training and a testing set, each
containing approximately half of the subjects. To ensure the robustness
of the results, we made sure that data from the same night was not
distributed across both sets. To optimize our models, we used a specific
set of hyperparameters for each type of machine learning algorithm. For
the Decision Tree, we tuned the cost complexity, tree depth, and minimum
number of samples required at a leaf node. The decision tree model was
set up using the
\texttt{rpart}\textsuperscript{\protect\hyperlink{ref-rpart}{119}}
engine for classification, with tree depth ranging from 3 to 7. For
Logistic Regression, implemented using the
\texttt{glmnet}\textsuperscript{\protect\hyperlink{ref-friedman_glmnet_2010}{138}}
engine, we considered tuning the penalty and mixture parameters. The
feed-forward neural network was implemented with a single-layer
feed-forward architecture using the
\texttt{nnet}\textsuperscript{\protect\hyperlink{ref-nnet}{139}} engine,
with the maximum number of allowable weights set to 7000 as a form of
regularization. The hyperparameters we tuned for this model were the
number of hidden units, the penalty, and the number of epochs. The range
for the number of hidden units was between 3 and 27. Lastly, the XGBoost
model was configured with the
\texttt{xgboost}\textsuperscript{\protect\hyperlink{ref-xgboost}{140}}
engine. The hyperparameters subjected to tuning included tree depth,
learning rate, loss reduction, minimum number of samples required at a
leaf node, sample size, and number of trees. For this algorithm, the
number of trees was specifically tuned within a range of 200 to 800.
These hyperparameters were optimized using a 10-fold Monte Carlo
cross-validation, carried out on a regular grid comprising different
combinations of these parameters. By providing the range and the
specific hyperparameters considered for each model, we ensured the most
robust and optimal model fitting.

After identifying the best-performing hyperparameters, we proceeded to
fit the models to the full training dataset. This approach made it
possible to use all available data for model parameter estimation, thus
maximizing performance. However, an imbalance issue was noted after the
initial step of our sequential model strategy. This imbalance in the
resulting dataset - the awake in-bed class was underrepresented, making
up only about 15\% of the training data - could induce biases during
model training, as models tend to favor the majority class. To correct
this, we employed the Synthetic Minority Over-sampling Technique (SMOTE)
as outlined by Chawla et
al.\textsuperscript{\protect\hyperlink{ref-chawla_smote_2002}{141}}.
Using the themis R
package\textsuperscript{\protect\hyperlink{ref-themis}{142}}, we
implemented SMOTE to achieve a balanced distribution of training samples
across both classes. The F1 score served as the optimization metric
because it balances both precision and recall, and therefore is more
robust to class imbalance.

In parallel to these sequential models, we also trained a bidirectional
Long Short-Term Memory (biLSTM) model to classify three distinct states:
out-of-bed-awake, in-bed-awake, and in-bed-asleep. The data for this
model was divided into training, validation, and test sets, adhering to
a 50/25/25 split ratio. Again, caution was exercised to avoid having
data from the same night across different sets. For efficient and
adaptive learning, the Adam optimizer was used during the training
process. Given that we were dealing with a multiclass classification
task with mutually exclusive classes, the cross-entropy loss function
was employed. At the output layer, a softmax activation function was
applied to obtain a probability distribution over the classes. We
monitored the model's performance using the F1 score for both the
training and validation sets and employed early stopping with a patience
of 3 epochs, ceasing training if no improvement in the validation loss
was observed over three consecutive epochs.

\hypertarget{model-validation}{%
\subsection{Model Validation}\label{model-validation}}

In our study, we utilized standard evaluation metrics to assess the
performance of each model on an epoch-to-epoch basis. These include
\[accuracy = \frac{TP+TN}{TP+TN+FP+FN}\]
\[sensitivity = \frac{TP}{TP+FN}\] \[specificity = \frac{TN}{TN+FP}\]
\[precision = \frac{TP}{TP+FP}\] \[NPV = \frac{TN}{TN + FN}\]
\[F_1 = 2 \cdot \frac{precision \cdot sensitivity}{precision + sensitivity}\]

where \(NPV\) is negative predictive value, \(F_1\) is the F1 score,
\(TP\) is true positives, \(FP\) is false positives, \(TN\) is true
negatives, and \(FN\) is false negatives.

In our sequential model strategy, we initially focused on models that
carried out binary classification tasks distinguishing between in-bed
and out-of-bed states. We gauged these models' performance through
various metrics, including the F1-score, accuracy, sensitivity,
specificity, and precision. Subsequently, we shifted our focus to models
that could identify the binary state of being asleep or awake, using the
same metrics as well as the negative predictive rate. Due to the class
imbalance, we calculated the F1 score as an unweighted macro-average. We
also scrutinized a multiclass biLSTM classifier using the same metrics,
interpreting its multiclass output as two separate binary
classifications: out-of-bed versus all other states, and in-bed-awake
versus in-bed-asleep. To give a comprehensive view of model performance,
we offered confusion matrices for the entire dataset, covering both
in-bed and out-of-bed data. These matrices report relative counts,
column percentages for accurate predictions of the true class, and row
percentages for correctly classified predictions. Both in-bed/out-of-bed
and awake/asleep classification tasks were treated as binary,
designating `in-bed' and `asleep' as positive labels and `out-of-bed'
and `awake' as negative labels, in line with prior
studies\textsuperscript{\protect\hyperlink{ref-hjorth_measure_2012}{143},\protect\hyperlink{ref-kushida_comparison_2001}{144}}.

To evaluate how well our models performed in generating sleep quality
metrics, we employed Bland-Altman plots and Pearson correlations.
Specifically, the Bland-Altman approach was used to gauge the level of
agreement between two different measurement techniques. Since our
dataset included multiple but uneven observations per subject, we used a
bootstrap procedure to account for extra variability. We initially
calculated the mean difference or bias, and then determined the limits
of agreement (LOA) as the bias ± 1.96 times the standard deviation of
these differences. Given the possibility of non-normal distribution and
skewness in our data, we opted for a bias-corrected and accelerated
(BCa) bootstrap method {[}@diciccio\_bootstrap\_1996{]}. This allowed
for more accurate estimation, taking into account intra-subject
variability. Using 10,000 bootstrap replicates, we confirmed 95\%
confidence intervals for both the bias and LOA, thereby ensuring robust
measurements. Our sleep quality metrics conformed to ZM definitions and
included the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sleep Period Time (SPT) - This refers to the total duration of time in
  bed with the intention to sleep, which is defined as the time from the
  start to the end of the ZM recording.
\item
  Total Sleep Time (TST) - This is the time spent asleep within the SPT.
\item
  Sleep Efficiency (SE) - This is the ratio between TST and SPT,
  representing the proportion of the sleep period that was actually
  spent asleep.
\item
  Latency Until Persistent Sleep (LPS) - This metric represents the time
  it takes to transition from wakefulness to sustained sleep. It is
  calculated as the time from the beginning of the ZM recording until
  the first period when 10 out of 12 minutes are scored as sleep.
\item
  Wake After Sleep Onset (WASO) - This refers to the time spent awake
  after initially falling asleep and before the final awakening. In our
  analysis, a period is counted as `awake' only if it consists of 3 or
  more contiguous 30-second epochs which is also how the ZM summarizes
  WASO.
\end{enumerate}

The technical frameworks used for model development and analyses were R
version
4.3.0\textsuperscript{\protect\hyperlink{ref-rcoreteam_2023}{145}} along
with the
Tidymodels\textsuperscript{\protect\hyperlink{ref-kuhn_tidymodels_2020}{118}}
and
Tidyverse\textsuperscript{\protect\hyperlink{ref-wickham_tidyverse_2019}{146}}
package suites. For the biLSTM model, we used Python version
3.10.6\textsuperscript{\protect\hyperlink{ref-vanrossum_python_2009}{147}}
and
PyTorch\textsuperscript{\protect\hyperlink{ref-paszke_pytorch_2019}{148}}.

\hypertarget{results-2}{%
\section{Results}\label{results-2}}

As indicated in Table~\ref{tbl-10}, the application of 5-minute and
10-minute median filters led to modifications in the sleep quality
metrics derived from ZM predictions. SPT remained consistent between raw
and filtered data sets, with a mean duration of 9.2 ± 2.1 hours, which
aligns with the length of the ZM recording. Interestingly, bothTST and
SE saw increases in the filtered datasets, suggesting that the filters
may be classifying some periods of wakefulness as sleep. Specifically,
the mean TST rose from 7.7 ± 1.9 hours in the raw data to 8.1 ± 2.0
hours with a 5-minute filter and 8.2 ± 2.1 hours with a 10-minute
filter. Similarly, SE increased from an initial mean of 82.6 ± 12.0\% to
86.4 ± 12.7\% and 87.5 ± 12.9\% for the 5-minute and 10-minute filters,
respectively.

Furthermore, the LPS also saw an increase, implying that the filters may
be removing brief awakenings at the onset of sleep, thereby lengthening
the time it takes to achieve persistent sleep. On the other hand, the
WASO metric decreased from a raw average of 39.0 ± 33.6 minutes to 30.6
± 46.8 minutes and 22.3 ± 55.4 minutes in the 5-minute and 10-minute
filtered data, respectively. Notably, the application of these filters
also led to a significant reduction in the average number of awakenings
per night. In the unfiltered data, the mean number of awakenings stood
at 34.46 ± 11.33, which dramatically dropped to 4.43 ± 3.26 and 1.95 ±
2.01 in the 5-minute and 10-minute filtered datasets, respectively.

\begingroup

\footnotesize

\hypertarget{tbl-10}{}
\begin{longtable}{lrrrrrr}
\caption{\label{tbl-10}Overview of characteristics of the ZM sleep quality summaries per night
(585 nights from 151 children). Values are represented as mean (SD).
Hrs: hours, min: minutes. }\tabularnewline

\toprule
 & SPT (hrs) & TST (hrs) & SE (\%) & LPS (min) & WASO (min) & Awakenings (N) \\ 
\midrule
Raw ZM Predictions & 9.2 (2.1) & 7.7 (1.9) & 82.6 (12) & 34.5 (27.9) & 39 (33.6) & 34.5 (11.3) \\ 
5-Min Median & 9.2 (2.1) & 8.1 (2) & 86.4 (12.7) & 36.3 (39.8) & 30.6 (46.8) & 4.4 (3.3) \\ 
10-Min Median & 9.2 (2.1) & 8.2 (2.1) & 87.5 (12.9) & 38 (48.7) & 22.3 (55.4) & 1.9 (2) \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{performance-on-epoch-to-epoch-basis}{%
\subsection{Performance on Epoch-to-Epoch
Basis}\label{performance-on-epoch-to-epoch-basis}}

As delineated in Table~\ref{tbl-11}, the epoch-to-epoch evaluation for
predicting in-bed time shows virtually identical performance across
various model types. The F1 score fluctuates slightly, ranging from
94.4\% in the Decision Tree model to 95.4\% in the XGBoost model.
Likewise, accuracy varies minimally from 95.3\% for the Decision Tree
model to 96.1\% for the XGBoost model. Other metrics such as
Sensitivity, Precision, and Specificity also exhibit uniform performance
across the different models. While the XGBoost model does exhibit the
highest performance with an F1 score of 95.4\% and an accuracy of
96.1\%, it only marginally surpasses the other models in these metrics.

\begingroup

\footnotesize

\hypertarget{tbl-11}{}
\begin{longtable}{lrrrrr}
\caption{\label{tbl-11}Performance metrics of the classification of in-bed/out-of-bed time of
the included models. }\tabularnewline

\toprule
 & F1 Score (\%) & Accuracy (\%) & Sensitivity (\%) & Precision (\%) & Specificity (\%) \\ 
\midrule
Decision Tree & $94.4$ & $95.3$ & $93.1$ & $95.6$ & $96.9$ \\ 
Logistic Regression & $95.0$ & $95.7$ & $95.0$ & $94.9$ & $96.3$ \\ 
Feed-Forward Neural Net & $95.0$ & $95.8$ & $95.1$ & $95.0$ & $96.3$ \\ 
XGBoost & $95.4$ & $96.1$ & $95.8$ & $94.9$ & $96.2$ \\ 
biLSTM & $95.2$ & $95.3$ & $95.3$ & $95.1$ & $95.3$ \\ 
\bottomrule
\end{longtable}

\endgroup

As noted in Table~\ref{tbl-12}, the performance metrics for all types of
sequential models in raw and median-filtered (5 and 10 minute) ZM
predictions for sleep/wake classification are summarized. In the raw ZM
predictions, the F1 scores, calculated as unweighted macro averages,
vary from 65.6\% for the biLSTM model to 76.2\% for the XGBoost model.
While all models demonstrate similar performance, low specificity values
ranging from 62.5\% to 70.9\% indicate challenges in accurately
classifying awake epochs. When a 5-minute median filter is applied,
there is a noticeable improvement in performance metrics, with the
XGBoost model achieving the highest F1 score of 79.2\% and an NPV of
74.0\%. Nonetheless, specificity continues to be low across all models,
registering values between 54.7\% for XGBoost and 74.8\% for Logistic
Regression. Upon application of a 10-minute median filter, the metrics
experience further improvement. The XGBoost model retains its leading
position with an F1 score of 80.9\% and an NPV of 75.9\%. Despite these
improvements, specificity remains a challenge, showing a range from
57.5\% for the Decision Tree model to 76.4\% for Logistic Regression
across all model types.

\begingroup

\footnotesize

\hypertarget{tbl-12}{}
\begin{longtable}{lrrrrr}
\caption{\label{tbl-12}Performance metrics of the sleep/wake classification of the included
models. }\tabularnewline

\toprule
 & F1 Score (\%) & Precision (\%) & NPV (\%) & Sensitivity (\%) & Specificity (\%) \\ 
\midrule
\multicolumn{6}{l}{Raw ZM Predictions} \\ 
\midrule
Decision Tree & $72.9$ & $93.2$ & $48.4$ & $86.3$ & $67.1$ \\ 
Logistic Regression & $71.0$ & $93.7$ & $43.9$ & $82.7$ & $70.9$ \\ 
Neural Network & $71.8$ & $93.8$ & $45.1$ & $83.6$ & $70.8$ \\ 
XGBoost & $76.2$ & $92.8$ & $58.0$ & $91.3$ & $62.8$ \\ 
biLSTM & $65.6$ & $80.6$ & $80.6$ & $62.5$ & $62.5$ \\ 
\midrule
\multicolumn{6}{l}{5-Min Median} \\ 
\midrule
Decision Tree & $75.5$ & $94.2$ & $55.5$ & $93.4$ & $59.0$ \\ 
Logistic Regression & $68.3$ & $95.8$ & $36.0$ & $81.4$ & $74.8$ \\ 
Neural Network & $71.7$ & $95.8$ & $41.6$ & $85.6$ & $73.1$ \\ 
XGBoost & $79.2$ & $93.9$ & $74.0$ & $97.3$ & $54.7$ \\ 
biLSTM & $70.3$ & $84.6$ & $84.6$ & $66.2$ & $66.2$ \\ 
\midrule
\multicolumn{6}{l}{10-Min Median} \\ 
\midrule
Decision Tree & $76.3$ & $94.7$ & $58.1$ & $94.9$ & $57.5$ \\ 
Logistic Regression & $68.0$ & $96.5$ & $34.3$ & $81.9$ & $76.4$ \\ 
Neural Network & $71.0$ & $96.1$ & $39.5$ & $86.5$ & $71.4$ \\ 
XGBoost & $80.9$ & $94.9$ & $75.8$ & $97.7$ & $57.6$ \\ 
biLSTM & $70.9$ & $75.1$ & $75.1$ & $68.5$ & $68.5$ \\ 
\bottomrule
\end{longtable}

\endgroup

Figure~\ref{fig-bin_conf_mat} and Figure~\ref{fig-mul_conf_mat} presents
a comprehensive set of confusion matrices generated from data that
includes both out-of-bed and in-bed times. These matrices offer insights
into the epoch-to-epoch performance of all sequential models when
differentiating between `awake' and `asleep' states, irrespective of
whether the subject is in bed or out of bed. However, it's crucial to
acknowledge that the sequential models, owing to their binary nature,
are not equipped to directly classify the `in-bed-awake' state. In
contrast, the biLSTM model, which does identify the `in-bed-awake' state
as a separate class, seems to be less successful in classifying this
specific state.

\begin{figure}

{\centering \includegraphics{figures/all_binary_conf_mats.pdf}

}

\caption{\label{fig-bin_conf_mat}Confusion matrices for the binary
predictions. The middle of each tile is the normalized count (overall
percentage). The bottom number of each tile is the column percentage and
the right side of each tile is the row percentage. i) decision tree, ii)
logistic regression, iii) feed-forward neural net, iv) XGBoost}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/all_multiclass_conf_mats.pdf}

}

\caption{\label{fig-mul_conf_mat}Confusion matrices for the biLSTM
predictions. The middle of each tile is the normalized count (overall
percentage). The bottom number of each tile is the column percentage and
the right side of each tile is the row percentage.}

\end{figure}

\hypertarget{evaluation-of-sleep-quality-metrics}{%
\subsection{Evaluation of Sleep Quality
Metrics}\label{evaluation-of-sleep-quality-metrics}}

The comparative analysis of the models used for predicting various sleep
quality metrics such as SPT, TST, SE, LPS, and WASO is provided in
Table~\ref{tbl-13}. The complete table, which also includes models
developed from raw ZM predictions and 10-minute median-filtered ZM
predictions, can be found in table 1 of the supplementary materials.
Concerning bias, the Decision Tree model tends to underestimate SPT,
TST, and SE while overestimating LPS and WASO when compared to ZM.
Similar trends are evident in the Logistic Regression model, although
the underestimation in TST and overestimation in LPS are more
pronounced. The Feed-forward Neural Network shows a similar bias pattern
as the Decision Tree and Logistic Regression models but has higher
overestimation in WASO. In contrast, the XGBoost model exhibits the
least bias, particularly in its 5-minute median predictions.

When examining the Limits of Agreement (LOA), the Decision Tree model
displays higher variability in the differences across the sleep quality
metrics and filtering techniques, particularly for LPS and WASO,
suggesting lower agreement with ZM. Other models exhibit comparable LOA
but with some noteworthy exceptions; for instance, the LOA for TST in
the Logistic Regression model is particularly wide when 5-minute median
predictions are considered. In terms of correlation, the Pearson
coefficient indicates that the XGBoost model consistently shows the
highest correlation with ZM across all sleep quality metrics and
filtering methods. Notably, the strongest correlation (0.66) for TST is
observed in the XGBoost model's 5-minute median predictions among all
models and filtering techniques.

\begingroup

\footnotesize

\hypertarget{tbl-13}{}
\begin{longtable}{lrrrr}
\caption{\label{tbl-13}Summary of bias, limits of agreement, and Pearson correlation for
various sleep parameter predictions (SPT, TST, SE, LPS, WASO) using
different machine learning and deep learning models (decision tree,
logistic regression, feed-forward neural network, XGBoost) on raw ZM
predictions, 5-minute and 10-minute median predictions. Each value is
provided with its 95\% confidence interval (CI). }\tabularnewline

\toprule
 & Bias (95\% CI) & lower LOA (95\% CI) & upper LOA (95\% CI) & Pearson, \emph{r} (95\% CI) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - Decision Tree} \\ 
\midrule
SPT (min) & -21.6 (-25.6;-17.6) & -117.5 (-125.6;-110.7) & 74.2 (63.9;85.9) & 0.54 (0.48;0.6) \\ 
TST (min) & -148 (-153.8;-142.4) & -283 (-295.5;-272.6) & -13.1 (-22.8;-1) & 0.3 (0.22;0.37) \\ 
SE (\%) & -22.7 (-23.7;-21.8) & -45.5 (-47.5;-43.8) & 0 (-1.6;1.9) & 0.17 (0.09;0.24) \\ 
LPS (min) & 28.9 (24.5;33.2) & -76 (-87.6;-69.8) & 133.8 (124.6;144.7) & 0.13 (0.05;0.21) \\ 
WASO (min) & 46.1 (43;49.4) & -33.2 (-43.4;-26.2) & 125.4 (117.7;138.8) & 0.29 (0.22;0.37) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - Decision Tree} \\ 
\midrule
SPT (min) & -21.6 (-25.6;-17.6) & -117.5 (-125.6;-110.7) & 74.2 (63.9;85.9) & 0.54 (0.48;0.6) \\ 
TST (min) & -50.5 (-55.2;-46) & -161.4 (-175.8;-151.3) & 60.4 (51.5;71.7) & 0.48 (0.42;0.54) \\ 
SE (\%) & -5.5 (-6.3;-4.7) & -23.9 (-26.4;-22.2) & 12.9 (11.6;14.6) & 0.22 (0.14;0.29) \\ 
LPS (min) & 24.6 (19.7;29.1) & -88.8 (-115;-77.3) & 138 (126.2;156.7) & 0.06 (-0.02;0.14) \\ 
WASO (min) & 9.9 (6.5;14) & -79.4 (-109;-63.1) & 99.2 (80;136.1) & 0.15 (0.07;0.22) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - Decision Tree} \\ 
\midrule
SPT (min) & -21.8 (-25.7;-17.8) & -117.3 (-125.2;-110.4) & 73.7 (63.4;85.4) & 0.54 (0.48;0.6) \\ 
TST (min) & -31.5 (-35.7;-27.4) & -129.9 (-140.9;-121.8) & 67 (58.3;77.7) & 0.56 (0.5;0.61) \\ 
SE (\%) & -2.1 (-2.8;-1.4) & -18 (-19.9;-16.6) & 13.9 (12.6;15.3) & 0.22 (0.14;0.29) \\ 
LPS (min) & 22.8 (17.1;27.6) & -102.7 (-137.1;-83.3) & 148.4 (131.9;173.6) & 0.06 (-0.02;0.14) \\ 
WASO (min) & 9 (5.2;14.3) & -97.4 (-133.5;-72.1) & 115.3 (85.2;163) & 0.07 (-0.02;0.15) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - Logistic Regression} \\ 
\midrule
SPT (min) & -4 (-8.3;0.7) & -113.5 (-122.7;-106.1) & 105.5 (95;118.7) & 0.37 (0.29;0.43) \\ 
TST (min) & -139.2 (-145.7;-132.8) & -291.6 (-306.1;-279.2) & 13.1 (3.8;23.5) & 0.12 (0.04;0.2) \\ 
SE (\%) & -23.1 (-24;-22.1) & -45.6 (-47.4;-44) & -0.6 (-2;1) & 0.18 (0.1;0.26) \\ 
LPS (min) & 47.5 (43.6;51.4) & -46.2 (-57;-38.6) & 141.2 (131;154.5) & 0.1 (0.01;0.18) \\ 
WASO (min) & 48.7 (45.3;52.1) & -34.7 (-46.2;-28) & 132.1 (124.6;147.3) & 0.25 (0.17;0.33) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - Logistic Regression} \\ 
\midrule
SPT (min) & -3.7 (-8;1) & -112.2 (-120.9;-105.2) & 104.8 (94;117.4) & 0.38 (0.3;0.44) \\ 
TST (min) & -139.7 (-146.9;-133) & -305.6 (-323.6;-291.8) & 26.2 (16.1;38.6) & 0.09 (0.01;0.17) \\ 
SE (\%) & -23.2 (-24.3;-22.2) & -48.1 (-50.9;-46.1) & 1.7 (0.1;3.8) & 0.13 (0.05;0.21) \\ 
LPS (min) & 58.1 (53.4;62.6) & -52.3 (-75;-40.1) & 168.6 (155.9;187.7) & 0.05 (-0.03;0.13) \\ 
WASO (min) & 45.4 (41.7;49.7) & -50.7 (-74.4;-38.4) & 141.5 (126.8;173) & 0.19 (0.11;0.27) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - Logistic Regression} \\ 
\midrule
SPT (min) & -4.2 (-8.6;0.5) & -113.4 (-122.4;-106) & 105 (94.2;118) & 0.37 (0.3;0.44) \\ 
TST (min) & -130.9 (-138;-124.2) & -295.1 (-311.8;-281.4) & 33.2 (23.3;45.1) & 0.09 (0.01;0.17) \\ 
SE (\%) & -21.6 (-22.6;-20.6) & -45.7 (-48.2;-43.8) & 2.5 (1;4.3) & 0.13 (0.05;0.21) \\ 
LPS (min) & 60.7 (54.9;65.6) & -64.8 (-100.8;-43.9) & 186.2 (168.1;213.6) & 0.02 (-0.06;0.1) \\ 
WASO (min) & 44.8 (40.8;50) & -66 (-98.3;-45.1) & 155.7 (130.2;197.8) & 0.17 (0.09;0.25) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - Feed-Forward Neural Net} \\ 
\midrule
SPT (min) & -3.9 (-8.1;0.9) & -112.7 (-122;-105.2) & 104.9 (94.1;118.4) & 0.38 (0.3;0.44) \\ 
TST (min) & -154 (-159.9;-148) & -297 (-308.6;-287) & -10.9 (-20;-0.5) & 0.25 (0.17;0.32) \\ 
SE (\%) & -25.6 (-26.5;-24.7) & -48.2 (-50;-46.6) & -3 (-4.5;-1.2) & 0.23 (0.15;0.31) \\ 
LPS (min) & 34.3 (30.2;38.6) & -67.7 (-80.1;-60.5) & 136.4 (126.4;149.3) & 0.11 (0.03;0.19) \\ 
WASO (min) & 58.7 (55.4;62.1) & -23.8 (-33.9;-17.5) & 141.2 (133.9;155.6) & 0.33 (0.26;0.4) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - Feed-Forward Neural Net} \\ 
\midrule
SPT (min) & -3.9 (-8.1;0.9) & -112.7 (-122;-105.2) & 104.9 (94.1;118.4) & 0.38 (0.3;0.44) \\ 
TST (min) & -126.5 (-132.8;-120.3) & -276.8 (-291.3;-264.7) & 23.9 (14.8;33.9) & 0.25 (0.17;0.32) \\ 
SE (\%) & -20.9 (-21.9;-19.9) & -44.3 (-46.3;-42.5) & 2.5 (1.1;4) & 0.21 (0.13;0.29) \\ 
LPS (min) & 35.3 (30.7;39.8) & -75.8 (-102.3;-63.4) & 146.5 (134.4;166.9) & 0.07 (-0.01;0.15) \\ 
WASO (min) & 45 (41.2;49.2) & -51.8 (-76.4;-39.1) & 141.7 (125.8;174.1) & 0.21 (0.14;0.29) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - Feed-Forward Neural Net} \\ 
\midrule
SPT (min) & -4.1 (-8.5;0.6) & -112.6 (-121.7;-105) & 104.5 (93.5;117.6) & 0.38 (0.31;0.45) \\ 
TST (min) & -116.3 (-122.9;-110.3) & -266.2 (-280.4;-254.2) & 33.6 (24.7;43.4) & 0.29 (0.21;0.36) \\ 
SE (\%) & -19.1 (-20.1;-18.1) & -42.9 (-44.8;-41.1) & 4.7 (3.3;6.2) & 0.25 (0.17;0.33) \\ 
LPS (min) & 33.8 (28;38.6) & -91.1 (-127.2;-70.2) & 158.6 (141.2;184.7) & 0.05 (-0.03;0.13) \\ 
WASO (min) & 53.4 (49.2;58.7) & -58.6 (-89.6;-38.6) & 165.4 (140.4;206.7) & 0.22 (0.14;0.3) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - XGboost} \\ 
\midrule
SPT (min) & 0.2 (-3.7;4.5) & -97.4 (-106.2;-90.3) & 97.8 (86.6;111) & 0.56 (0.5;0.61) \\ 
TST (min) & -66 (-70.8;-61.4) & -178.1 (-187.9;-169.6) & 46.1 (38.9;54.5) & 0.47 (0.4;0.53) \\ 
SE (\%) & -11.1 (-11.8;-10.4) & -28.8 (-30.2;-27.5) & 6.5 (5.5;7.7) & 0.37 (0.29;0.44) \\ 
LPS (min) & 34.5 (30.6;38.5) & -62.4 (-75.8;-55.2) & 131.3 (121.1;143.9) & 0.2 (0.12;0.28) \\ 
WASO (min) & 18.4 (15.6;21.2) & -50.2 (-62.7;-43.1) & 86.9 (79.8;104.2) & 0.36 (0.28;0.43) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - XGboost} \\ 
\midrule
SPT (min) & 0.2 (-3.7;4.5) & -97.4 (-106.2;-90.3) & 97.8 (86.6;111) & 0.56 (0.5;0.61) \\ 
TST (min) & -7 (-10.8;-3.3) & -95.5 (-105.2;-88) & 81.4 (72.4;92.5) & 0.66 (0.61;0.7) \\ 
SE (\%) & -1.1 (-1.7;-0.5) & -15.6 (-17;-14.4) & 13.3 (12.2;14.7) & 0.44 (0.38;0.51) \\ 
LPS (min) & 28.5 (23.9;32.6) & -76.4 (-104.2;-63.3) & 133.4 (120.4;154.2) & 0.12 (0.04;0.2) \\ 
WASO (min) & -0.9 (-3.9;3) & -83.4 (-113.1;-66) & 81.7 (62;119.6) & 0.26 (0.18;0.33) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - XGboost} \\ 
\midrule
SPT (min) & 0.2 (-3.8;4.4) & -97.4 (-106.1;-90) & 97.9 (86.7;111.1) & 0.56 (0.5;0.61) \\ 
TST (min) & -4.2 (-7.7;-0.5) & -90.6 (-101.3;-82.9) & 82.3 (72.3;95.3) & 0.67 (0.62;0.71) \\ 
SE (\%) & -0.6 (-1.2;-0.1) & -14.5 (-16;-13.3) & 13.2 (12.1;14.9) & 0.43 (0.36;0.49) \\ 
LPS (min) & 26.4 (21;30.8) & -92.2 (-130;-69.5) & 145 (125.5;173.7) & 0.1 (0.02;0.18) \\ 
WASO (min) & 3.8 (0.3;9.1) & -98.1 (-135.4;-71.9) & 105.7 (74.5;153.4) & 0.2 (0.13;0.28) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - biLSTM} \\ 
\midrule
SPT (min) & -36.7 (-42.6;-30.3) & -141.4 (-153.2;-132) & 68 (54.5;85.5) & 0.5 (0.4;0.58) \\ 
TST (min) & 39 (33.3;44.9) & -60.1 (-72.9;-51.1) & 138 (126;152) & 0.53 (0.44;0.61) \\ 
SE (\%) & 12.6 (11.8;13.3) & 0 (-1.6;1.1) & 25.2 (23.6;27.2) & 0.07 (-0.05;0.18) \\ 
LPS (min) & -17.6 (-24.1;-11.3) & -127.2 (-177.4;-97.4) & 92.1 (63.4;143.8) & 0.05 (-0.06;0.17) \\ 
WASO (min) & -15.9 (-21;-8.9) & -116.1 (-158.9;-95.4) & 84.3 (58.9;138.2) & 0.04 (-0.07;0.16) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - biLSTM} \\ 
\midrule
SPT (min) & -36.1 (-41.7;-30) & -136.1 (-146.3;-126.9) & 64 (51.1;78.6) & 0.54 (0.45;0.62) \\ 
TST (min) & 12.8 (7.4;18.3) & -80.1 (-89.8;-72.3) & 105.8 (94.3;118.8) & 0.63 (0.55;0.69) \\ 
SE (\%) & 8 (7.2;8.8) & -5.1 (-6.8;-3.8) & 21.1 (19.5;23.1) & 0.16 (0.04;0.27) \\ 
LPS (min) & -15.7 (-25.9;-7.5) & -169 (-230.7;-127.9) & 137.6 (101.1;184.9) & 0.09 (-0.02;0.2) \\ 
WASO (min) & -3 (-9.9;7.7) & -144.1 (-197.2;-107.2) & 138.1 (90.8;211.4) & 0.02 (-0.1;0.13) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - biLSTM} \\ 
\midrule
SPT (min) & -83.7 (-90.7;-76.1) & -207.4 (-221.3;-195.2) & 40 (27.7;57.1) & 0.3 (0.19;0.4) \\ 
TST (min) & -42.2 (-49.3;-35.1) & -162 (-176.9;-149.6) & 77.6 (66.3;90.4) & 0.4 (0.29;0.49) \\ 
SE (\%) & 6.4 (5.7;7.2) & -6.5 (-7.8;-5.3) & 19.2 (17.7;21.2) & 0.16 (0.04;0.27) \\ 
LPS (min) & -21.5 (-32.7;-12.8) & -187.2 (-253.4;-138.6) & 144.3 (104.3;192.6) & 0.06 (-0.05;0.18) \\ 
WASO (min) & 26.8 (19.2;38) & -128.2 (-176.3;-90.8) & 181.8 (132.8;250.7) & 0.12 (0.01;0.23) \\ 
\bottomrule
\end{longtable}

\endgroup

The Bland-Altman plot and scatterplot presented in
Figure~\ref{fig-xgb_ba_cor} demonstrate the level of agreement between
the XGBoost model, trained on 5-minute median filtered ZM predictions,
and ZM-derived sleep quality metrics that were also median-smoothed over
5 minutes. For the sleep quality metrics SPT and TST, the bias is
notably close to zero, revealing a minimal average difference with the
ZM. The scatterplot for SPT also suggests a moderate linear correlation
between the model's predictions and the ZM-derived metrics. Similarly,
the bias and LOA for TST align closely with those for SPT, reflecting a
consistent agreement between the XGBoost model and ZM. The TST
scatterplot further indicates a slightly higher correlation, mainly due
to the lack of extreme outliers. In contrast, the remaining sleep
quality metrics, namely SE, LPS, and WASO, show signs of
heteroscedasticity unlike SPT and TST. While a moderate positive linear
correlation exists between the XGBoost model and the ZM-derived SE
metrics, poorer correlations are observed for LPS and WASO.

\begin{figure}

{\centering \includegraphics{figures/median_5_xgboost_ba_cor.pdf}

}

\caption{\label{fig-xgb_ba_cor}Comparison of sleep quality metrics
derived from the XGBoost model trained on the 5-minute smoothed ZM
predictions. The left column displays Bland-Altman plots. Dashed lines
represent the bias (the average difference between the two measurements)
and LOA, with the 95\% confidence intervals represented as the grayed
areas. The right column displays scatter plots of XGBoost-derived vs
ZM-derived sleep quality metrics. The dashed line represents the
identity line, while the full-drawn line represents the best linear fit.
Pearson's correlations are annotated in the upper left corner}

\end{figure}

\hypertarget{discussion-2}{%
\section{Discussion}\label{discussion-2}}

In our quest to find the most effective method for estimating sleep
based on thigh-worn accelerometers, we scrutinized various models
designed to predict both in-bed and sleep times, as well as associated
sleep quality metrics. These models were trained and assessed using both
raw and median-filtered sleep estimates derived from the ZM EEG-based
sleep monitor. Overall, all sequential models exhibited strong
performance in predicting when subjects were in bed. However,
distinguishing between wakefulness and sleep during these in-bed periods
proved to be more challenging. Interestingly, while the multiclass
biLSTM model excelled in terms of F1 score, precision, and NPV, it
lagged behind in deriving sleep quality metrics when compared to the
XGBoost model. The latter outperformed all others across every
evaluation metric, including epoch-to-epoch prediction and various sleep
quality indicators. Nonetheless, it's worth noting that all models
struggled with low specificity values, indicating a common difficulty in
accurately identifying awake epochs during time spent in bed. We also
observed performance improvement in all models when 5-minute and
10-minute median filters were applied. This filtering approach resulted
in increased total sleep time and sleep efficiency metrics while
reducing wake after sleep onset and the number of awakenings. Of all the
models, the XGBoost demonstrated the smallest bias and the highest
correlation with the ZM sleep quality metrics, making it the most robust
choice for this particular application.

While there is limited existing research on the epoch-to-epoch
effectiveness of thigh-worn accelerometers in classifying in-bed time,
Carlson and
colleagues\textsuperscript{\protect\hyperlink{ref-carlson_validity_2021}{149}}
have offered valuable insights. Their study demonstrated that both a
third-party algorithm called ``ProcessingPal'' and a proprietary
algorithm named ``CREA'' were able to achieve high accuracies of 91\%
and 86\%, respectively. Evaluated against self-reported measures in
adolescents and adults, these algorithms yielded impressive F1 scores as
high as 95\% and 96\%. This is consistent with our sequential models,
which also managed to surpass 95\% in both F1 and accuracy scores for
identifying in-bed time, equated in our study with SPT. However, it's
worth noting that all models in our study, with the exception of
XGBoost, tended to underestimate SPT. The biLSTM model displayed the
most significant underestimation, with a bias of -36 minutes. This
aligns with previous research by Winkler et
al.\textsuperscript{\protect\hyperlink{ref-winkler_identifying_2016}{150}},
who reported a similar trend in both young-middle-aged and older adults.
Their algorithm showed a moderate correlation with diary-recorded waking
times but overestimated waking wear time by more than 30 minutes,
resulting in an underestimation of in-bed time. This underestimation was
further validated by Inan-Eroglu et
al.\textsuperscript{\protect\hyperlink{ref-inan-eroglu_comparison_2021}{151}},
who found an underestimation of 9.8 minutes when comparing Winkler et
al.'s algorithm to self-reported measures in middle-aged adults.
Contrastingly, another study reported only a slight underestimation of
in-bed time in middle-aged and older
adults\textsuperscript{\protect\hyperlink{ref-van_der_berg_identifying_2016}{152}}.
They used a unique algorithmic approach that quantified the number and
duration of sedentary periods to ascertain time in bed and active
periods to identify wake times. Lastly, it's essential to clarify that
strong predictive performance in identifying in-bed time doesn't
automatically imply accurate predictions for broader sleep quality
metrics. Capturing awake periods during in-bed time, a critical factor
for assessing other derived sleep quality metrics, isn't effectively
handled by simply predicting in-bed time. This distinction between
actual sleep and time spent in bed while awake is often overlooked but
is vital for a more comprehensive understanding of sleep quality.

To our knowledge, Johansson and
colleagues\textsuperscript{\protect\hyperlink{ref-johansson_development_2023}{153}}
are the only researchers who have gone beyond merely reporting ``waking
time'' and ``in-bed time'' to provide epoch-to-epoch performance metrics
for sleep scoring with thigh-worn accelerometers. Utilizing a
single-night evaluation dataset comprising 71 adult subjects, they
managed a mean sensitivity of 0.84, a specificity of 0.55, and an
accuracy of 0.80. Similarly, our models achieved a high sensitivity of
above 97\%, but struggled, like Johansson et al.'s algorithm, in
detecting in-bed awake epochs. This struggle is manifested in our low
specificity scores, which ranged from 54.7\% to 76.4\%. This challenge
is not solely confined to thigh-worn devices. Conley et
al.'s\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{154}}
meta-analysis reported issues with wrist-worn accelerometers as well,
noting mean values of 0.89 for sensitivity, 0.88 for accuracy, and a low
0.53 for specificity among healthy adults. Patterson and colleagues also
recently summarized various heuristic algorithms, machine learning, and
deep learning models for sleep prediction, finding mean sensitivity and
specificity scores of 93\% and 60\%, respectively. These data
collectively highlight the persistent difficulty in automating the
identification of periods when individuals are awake yet still in bed.
Interestingly, we noted a divergence in our study regarding the
overestimation of LPS and WASO by several of our models, in contrast to
most previous research. This overestimation is evident in the low NPV
scores, suggesting that only a small fraction of the wake predictions
are accurate. This inconsistency might be attributed to the SMOTE we
used to balance the dataset. If the synthetic `wake' samples created by
SMOTE don't accurately represent the actual `wake' data, it could cause
the models to misclassify certain `sleep' epochs as `wake'.
Consequently, this could lead to inflated LPS and WASO estimates, as the
models would incorrectly identify more instances of wakefulness during
sleep.

The application of the SMOTE in our study likely enhanced the
performance of various models by addressing class imbalance issues.
However, the introduction of synthetic ``wake'' samples through this
method posed a challenge as they might not be fully indicative of
genuine wake data. This could explain why some models, including the
biLSTM which was not trained on SMOTE-processed data, overestimated TST
and SE. Contrarily, the XGBoost model, trained on SMOTE-processed data,
managed to navigate these synthetic ``wake'' samples more effectively
and did not overestimate TST as much as other models. Interestingly,
Bland-Altman statistics for the XGBoost model trained on 5-minute
median-filtered ZM predictions indicated a mean difference of -7 minutes
for TST and -1.1\% for SE. The limits of agreement for these metrics
spanned from -95.5 to 81.4 minutes and -15.6\% to 13.3\% respectively.
This suggests that the XGBoost model successfully maintained a balance
between sensitivity and specificity without being overly swayed by the
synthetic ``wake'' samples. The resilience of the XGBoost model to these
synthetic samples could be attributed to its gradient boosting
mechanism, which allows for iterative learning from prior models'
errors. Such an iterative learning process likely rendered XGBoost more
robust against inaccuracies that might be introduced by synthetic data,
ultimately leading to a better overall model performance.

Sleep detection methods are generally used in two distinct scenarios:
night-only recordings and 24-hour recordings. For night recordings, SE
and LPS can be readily derived since SPT can be inferred from the length
of the recording itself, as indicated by studies from Conley et al.~and
Patterson et
al\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{154},\protect\hyperlink{ref-patterson_40_2023}{155}}.
In contrast, when applied to 24-hour recordings, most sleep detection
methods face the challenge of inferring SPT without the aid of sleep
diaries, as presented by several
studies\textsuperscript{\protect\hyperlink{ref-girschik_validation_2012}{32},\protect\hyperlink{ref-doherty_large_2017}{125},\protect\hyperlink{ref-anderson_assessment_2014}{156}}.
This limitation prevents these methods from generating sleep quality
metrics dependent on SPT. To address this issue, we designed models
capable of distinguishing between in-bed awake time and in-bed asleep
time, as well as out-of-bed awake time, over a full 24-hour period. This
innovation allows our models to estimate a comprehensive range of
commonly used sleep quality metrics. In a similar vein, Van Hees et
al.\textsuperscript{\protect\hyperlink{ref-van_hees_estimating_2018}{102}}
proposed an algorithm for determining SPT using wrist-worn devices, an
approach that was subsequently validated by Plekhanova and her
team\textsuperscript{\protect\hyperlink{ref-plekhanova_validation_2023}{157}}.
When combined with other methods, this algorithm enables the estimation
of additional sleep quality metrics based on the identified SPT. Van
Hees et al.~reported favorable results with low mean differences when
compared to self-reported measures and PSG for SPT, a finding later
corroborated by Plekhanova et al.~However, both studies also highlighted
challenges in achieving good agreement on metrics such as LPS and WASO,
revealing low reliability with PSG. These challenges in accurately
detecting wakefulness during in-bed time are similar to the issues we
encountered in our own study.

In evaluating various sleep quality metrics, our study identified that
LPS consistently exhibited the largest mean error in relation to the
actual time allocated to it. This challenge in accurately classifying
the initial periods of SPT was further corroborated by poor Pearson
correlations between LPS obtained from model predictions and the ZM.
Among all models assessed, the XGBoost model emerged as the most
reliable, yet it overestimated LPS by an average of 26.4 minutes for
models trained on unfiltered ZM predictions. This increased to 28.5 and
34.5 minutes when the training data was 5-minute and 10-minute filtered
ZM predictions, respectively. This discrepancy is not unique to our
study; it is on par with the mean error of 23 minutes in sleep latency
reported by Johansson et
al\textsuperscript{\protect\hyperlink{ref-johansson_development_2023}{153}}.
Johansson and colleagues attribute such inconsistencies to sleep state's
multifaceted and complex physiological nature. Specifically, brief
awakenings or transient sleep episodes may not always result in
detectable thigh movements, complicating their identification and
accurate classification. These observations are consistent with findings
on wrist-worn devices by Conley and
colleagues\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{154}},
who reported that correlations between accelerometer data and
polysomnography (PSG) sleep onset latency (equivalent to LPS) varied
greatly across studies. The mean correlation was only 0.2, underscoring
the challenges in leveraging accelerometry alone for estimating LPS.

Moreover, when compared to other models like the Van Hees
algorithm\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{87}},
Oakley
rsc\textsuperscript{\protect\hyperlink{ref-palotti_benchmark_2019}{158}},
and
LSTM-50\textsuperscript{\protect\hyperlink{ref-palotti_benchmark_2019}{158}}
as evaluated in the Patterson et
al.~study\textsuperscript{\protect\hyperlink{ref-patterson_40_2023}{155}},
our XGBoost model displayed narrower LOAs for TST, SE, and WASO.
Interestingly, the LOAs were also narrower when pitted against the
algorithm tailored for thigh-worn devices by Johansson et
al\textsuperscript{\protect\hyperlink{ref-johansson_development_2023}{153}},
albeit not for SPT. Despite these promising facets, it is important to
note that all methods, both from this study and the literature, showcase
wide LOAs. This implies a high level of variability in sleep quality
metrics derived from accelerometry, cautioning against its use as a
stand-alone alternative to EEG-based ZM or PSG for individual-level
sleep assessments. The presence of extreme outliers in our study
appeared to exacerbate the width of LOAs, suggesting that current
methods are better suited for group-level sleep quality metrics. As a
result, there is a pressing need for further refinement to enhance the
reliability and validity of these models for individual sleep
assessments.

In our study, we opted to use the ZM as the reference method for sleep
measurement, as opposed to the generally accepted gold standard, PSG.
While this choice could contribute to the observed discrepancies between
our models and ZM outcomes, we argue that the use of ZM has distinct
advantages. For one, ZM facilitates multiple consecutive nights of
recording in a free-living
environment\textsuperscript{\protect\hyperlink{ref-pedersen_self-administered_2021}{94}},
thereby capturing intra-individual variations in sleep patterns. This is
an aspect often impractical to achieve with PSG. Additionally, the use
of ZM allowed us to incorporate more nights into our study than is
typically possible with PSG-based studies. This is evident when
comparing our data set to the more limited Newcastle dataset, which
consists of only 28
participants\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{87}}.
Despite its benefits, we found that the raw ZM outputs were not ideally
suited for developing machine learning models, primarily due to a low
signal-to-noise ratio, as indicated in Figure ZM Median
(Figure~\ref{fig-paper3_raw_filt}). The ZM device itself employs certain
filtering processes to mitigate this issue when generating sleep quality
metrics. For example, WASO is determined using contiguous epochs of 3
minutes, and sleep only contributes to sleep quality metrics if 10 out
of 12 minutes are categorized as sleep. To enhance the effectiveness of
our machine learning algorithms, we applied median filters to the raw ZM
predictions, which had a notable impact on the derived sleep quality
metrics. The application of these filters led to several changes.
Specifically, the mean WASO dropped from 39 minutes in the raw
predictions to 30.6 minutes when using a 5-minute median filter, and
further decreased to 22.3 minutes with a 10-minute median filter.
Likewise, TST, SE, and LPS all increased upon the application of the
5-minute and 10-minute median filters. These shifts suggest that the
median filters could potentially reclassify brief instances of
wakefulness as sleep, and similarly, eliminate short awakenings. Despite
these alterations, the sleep quality metrics derived from the
median-filtered predictions remained largely consistent with those from
the raw predictions, validating the approach we took in this study.

Our current study offers significant contributions to the field of sleep
estimation methods, particularly in the use of thigh-worn
accelerometers. One of the primary strengths of the research lies in its
ability to distinguish between in-bed awake time and asleep time, as
well as out-of-bed time. This distinction is crucial for extracting
essential sleep quality metrics. Additionally, by evaluating multiple
nights per subject, the study offers valuable insights into
intra-subject sleep variability, another important factor for sleep
assessment.However, there are limitations to our approach. Most notably,
we utilized the ZM as our reference method, which is not considered the
gold standard for sleep measurement. This choice might have impacted the
validity of our findings. For future work, it might be beneficial to
employ PSG as a reference, despite its own set of limitations, to
provide a more accurate comparison. Another limitation is the lack of
external validation for our models, which confines the applicability of
our findings primarily to the children studied.

\hypertarget{conclusions-2}{%
\subsection{Conclusions}\label{conclusions-2}}

In terms of model performance, we tested a variety of machine learning
and deep learning models to predict in-bed and sleep times as well as
corresponding sleep quality metrics. The sequential models performed
particularly well in predicting in-bed time, although they encountered
difficulties in accurately discerning sleep from wake epochs during that
period. Among all the models evaluated, the XGBoost model stood out for
its superior performance in epoch-to-epoch predictions and sleep quality
metrics.The study also brings attention to the existing limitations of
current sleep detection methods. Specifically, there are challenges in
effectively identifying wake periods during in-bed time, and
improvements are needed to enhance the accuracy of individual sleep
assessments. Overall, we believe our work serves as a foundational step
for future research aimed at refining these models. The ultimate goal is
to offer a more precise and accurate evaluation of sleep patterns and
quality through the use of thigh-worn accelerometers.

\hypertarget{overall-discussion}{%
\chapter{Overall Discussion}\label{overall-discussion}}

bla

\hypertarget{references}{%
\chapter{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\leavevmode\vadjust pre{\hypertarget{ref-kraus_physical_2019}{}}%
\CSLLeftMargin{1. }%
\CSLRightInline{Kraus, W. E. \emph{et al.} Physical activity, all-cause
and cardiovascular mortality, and cardiovascular disease. \emph{Med Sci
Sports Exerc} \textbf{51}, 1270--1281 (2019)
doi:\href{https://doi.org/10.1249/MSS.0000000000001939}{10.1249/MSS.0000000000001939}.}

\leavevmode\vadjust pre{\hypertarget{ref-lee_effect_2012}{}}%
\CSLLeftMargin{2. }%
\CSLRightInline{Lee, I.-M. \emph{et al.} Effect of physical inactivity
on major non-communicable diseases worldwide: An analysis of burden of
disease and life expectancy. \emph{Lancet} \textbf{380}, 219--229 (2012)
doi:\href{https://doi.org/10.1016/S0140-6736(12)61031-9}{10.1016/S0140-6736(12)61031-9}.}

\leavevmode\vadjust pre{\hypertarget{ref-wilmot_sedentary_2012}{}}%
\CSLLeftMargin{3. }%
\CSLRightInline{Wilmot, E. G. \emph{et al.} Sedentary time in adults and
the association with diabetes, cardiovascular disease and death:
Systematic review and meta-analysis. \emph{Diabetologia} \textbf{55},
2895--2905 (2012) URL: \url{https://doi.org/10.1007/s00125-012-2677-z}
Accessed 5 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-cappuccio_sleep_2010}{}}%
\CSLLeftMargin{4. }%
\CSLRightInline{Cappuccio, F. P., D'Elia, L., Strazzullo, P. \& Miller,
M. A. Sleep duration and all-cause mortality: A systematic review and
meta-analysis of prospective studies. \emph{Sleep} \textbf{33}, 585--592
(2010)
doi:\href{https://doi.org/10.1093/sleep/33.5.585}{10.1093/sleep/33.5.585}.}

\leavevmode\vadjust pre{\hypertarget{ref-kl_physical_2018}{}}%
\CSLLeftMargin{5. }%
\CSLRightInline{Kl, P. \emph{et al.} The physical activity guidelines
for americans. \emph{{JAMA}} \textbf{320}, (2018) URL:
\url{https://pubmed.ncbi.nlm.nih.gov/30418471/} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-el-zine_fysisk_nodate-1}{}}%
\CSLLeftMargin{6. }%
\CSLRightInline{El-Zine, H. Fysisk aktivitet for voksne (18-64 år).}

\leavevmode\vadjust pre{\hypertarget{ref-el-zine_fysisk_nodate}{}}%
\CSLLeftMargin{7. }%
\CSLRightInline{El-Zine, H. Fysisk aktivitet for børn og unge (5-17
år).}

\leavevmode\vadjust pre{\hypertarget{ref-biddle_physical_2011}{}}%
\CSLLeftMargin{8. }%
\CSLRightInline{Biddle, S. J. H. \& Asare, M. Physical activity and
mental health in children and adolescents: A review of reviews. \emph{Br
J Sports Med} \textbf{45}, 886--895 (2011)
doi:\href{https://doi.org/10.1136/bjsports-2011-090185}{10.1136/bjsports-2011-090185}.}

\leavevmode\vadjust pre{\hypertarget{ref-warburton_health_2017}{}}%
\CSLLeftMargin{9. }%
\CSLRightInline{Warburton, D. E. R. \& Bredin, S. S. D. Health benefits
of physical activity: A systematic review of current systematic reviews.
\emph{Curr Opin Cardiol} \textbf{32}, 541--556 (2017)
doi:\href{https://doi.org/10.1097/HCO.0000000000000437}{10.1097/HCO.0000000000000437}.}

\leavevmode\vadjust pre{\hypertarget{ref-strath_guide_2013}{}}%
\CSLLeftMargin{10. }%
\CSLRightInline{Strath, S. J. \emph{et al.} Guide to the assessment of
physical activity: Clinical and research applications: A scientific
statement from the american heart association. \emph{Circulation}
\textbf{128}, 2259--2279 (2013)
doi:\href{https://doi.org/10.1161/01.cir.0000435708.67487.da}{10.1161/01.cir.0000435708.67487.da}.}

\leavevmode\vadjust pre{\hypertarget{ref-arem_leisure_2015}{}}%
\CSLLeftMargin{11. }%
\CSLRightInline{Arem, H. \emph{et al.} Leisure time physical activity
and mortality: A detailed pooled analysis of the dose-response
relationship. \emph{{JAMA} Intern Med} \textbf{175}, 959--967 (2015)
doi:\href{https://doi.org/10.1001/jamainternmed.2015.0533}{10.1001/jamainternmed.2015.0533}.}

\leavevmode\vadjust pre{\hypertarget{ref-rollo_whole_2020}{}}%
\CSLLeftMargin{12. }%
\CSLRightInline{Rollo, S., Antsygina, O. \& Tremblay, M. S. The whole
day matters: Understanding 24-hour movement guideline adherence and
relationships with health indicators across the lifespan. \emph{Journal
of Sport and Health Science} \textbf{9}, 493--510 (2020) URL:
\url{https://www.sciencedirect.com/science/article/pii/S2095254620300910}
Accessed 5 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-ma_sleep_2017}{}}%
\CSLLeftMargin{13. }%
\CSLRightInline{Ma, G. Sleep, health, and society. \emph{Sleep medicine
clinics} \textbf{12}, (2017) URL:
\url{https://pubmed.ncbi.nlm.nih.gov/28159089/} Accessed 26 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-worley_2018}{}}%
\CSLLeftMargin{14. }%
\CSLRightInline{Worley, S. L. The Extraordinary Importance of Sleep: The
Detrimental Effects of Inadequate Sleep on Health and Public Safety
Drive an Explosion of Sleep Research. \emph{P \& T: A Peer-Reviewed
Journal for Formulary Management} \textbf{43}, 758--763 (2018).}

\leavevmode\vadjust pre{\hypertarget{ref-matricciani_2019}{}}%
\CSLLeftMargin{15. }%
\CSLRightInline{Matricciani, L., Paquet, C., Galland, B., Short, M. \&
Olds, T. Children's sleep and health: A meta-review. \emph{Sleep
Medicine Reviews} \textbf{46}, 136--150 (2019) URL:
\url{https://www.sciencedirect.com/science/article/pii/S1087079219300188}.}

\leavevmode\vadjust pre{\hypertarget{ref-scott_2021}{}}%
\CSLLeftMargin{16. }%
\CSLRightInline{Scott, A. J., Webb, T. L., Martyn-St James, M., Rowse,
G. \& Weich, S. Improving sleep quality leads to better mental health: A
meta-analysis of randomised controlled trials. \emph{Sleep Medicine
Reviews} \textbf{60}, 101556 (2021) URL:
\url{https://www.sciencedirect.com/science/article/pii/S1087079221001416}.}

\leavevmode\vadjust pre{\hypertarget{ref-consensus_conference_panel_recommended_2015}{}}%
\CSLLeftMargin{17. }%
\CSLRightInline{Consensus Conference Panel \emph{et al.} Recommended
amount of sleep for a healthy adult: A joint consensus statement of the
american academy of sleep medicine and sleep research society. \emph{J
Clin Sleep Med} \textbf{11}, 591--592 (2015)
doi:\href{https://doi.org/10.5664/jcsm.4758}{10.5664/jcsm.4758}.}

\leavevmode\vadjust pre{\hypertarget{ref-ji_2020}{}}%
\CSLLeftMargin{18. }%
\CSLRightInline{Ji, A. \emph{et al.} Interactive effect of sleep
duration and sleep quality on risk of stroke: An 8-year follow-up study
in China. \emph{Scientific Reports} \textbf{10}, 8690 (2020) URL:
\url{https://www.nature.com/articles/s41598-020-65611-y}.}

\leavevmode\vadjust pre{\hypertarget{ref-hale_2020}{}}%
\CSLLeftMargin{19. }%
\CSLRightInline{Hale, L., Troxel, W. \& Buysse, D. J. Sleep Health: An
Opportunity for Public Health to Address Health Equity. \emph{Annual
Review of Public Health} \textbf{41}, 81--99 (2020)
doi:\href{https://doi.org/10.1146/annurev-publhealth-040119-094412}{10.1146/annurev-publhealth-040119-094412}.}

\leavevmode\vadjust pre{\hypertarget{ref-shochat_2014}{}}%
\CSLLeftMargin{20. }%
\CSLRightInline{Shochat, T., Cohen-Zion, M. \& Tzischinsky, O.
Functional consequences of inadequate sleep in adolescents: a systematic
review. \emph{Sleep Medicine Reviews} \textbf{18}, 75--87 (2014)
doi:\href{https://doi.org/10.1016/j.smrv.2013.03.005}{10.1016/j.smrv.2013.03.005}.}

\leavevmode\vadjust pre{\hypertarget{ref-kecklund_2016}{}}%
\CSLLeftMargin{21. }%
\CSLRightInline{Kecklund, G. \& Axelsson, J. Health consequences of
shift work and insufficient sleep. \emph{BMJ (Clinical research ed.)}
\textbf{355}, i5210 (2016)
doi:\href{https://doi.org/10.1136/bmj.i5210}{10.1136/bmj.i5210}.}

\leavevmode\vadjust pre{\hypertarget{ref-obrien_2005}{}}%
\CSLLeftMargin{22. }%
\CSLRightInline{O'Brien, E. M. \& Mindell, J. A. Sleep and risk-taking
behavior in adolescents. \emph{Behavioral Sleep Medicine} \textbf{3},
113--133 (2005) URL: \url{https://doi.org/10.1207/s15402010bsm0303_1}.}

\leavevmode\vadjust pre{\hypertarget{ref-bonnet_1985}{}}%
\CSLLeftMargin{23. }%
\CSLRightInline{Bonnet, M. H. Effect of sleep disruption on sleep,
performance, and mood. \emph{Sleep} \textbf{8}, 11--19 (1985) URL:
\url{https://doi.org/10.1093/sleep/8.1.11}.}

\leavevmode\vadjust pre{\hypertarget{ref-connor_2002}{}}%
\CSLLeftMargin{24. }%
\CSLRightInline{Connor, J. \emph{et al.} Driver sleepiness and risk of
serious injury to car occupants: population based case control study.
\emph{BMJ (Clinical research ed.)} \textbf{324}, 1125 (2002)
doi:\href{https://doi.org/10.1136/bmj.324.7346.1125}{10.1136/bmj.324.7346.1125}.}

\leavevmode\vadjust pre{\hypertarget{ref-dewald_2010}{}}%
\CSLLeftMargin{25. }%
\CSLRightInline{Dewald, J. F., Meijer, A. M., Oort, F. J., Kerkhof, G.
A. \& Bögels, S. M. The influence of sleep quality, sleep duration and
sleepiness on school performance in children and adolescents: A
meta-analytic review. \emph{Sleep Medicine Reviews} \textbf{14},
179--189 (2010)
doi:\href{https://doi.org/10.1016/j.smrv.2009.10.004}{10.1016/j.smrv.2009.10.004}.}

\leavevmode\vadjust pre{\hypertarget{ref-roth_1996}{}}%
\CSLLeftMargin{26. }%
\CSLRightInline{Roth, T. \& Roehrs, T. A. Etiologies and sequelae of
excessive daytime sleepiness. \emph{Clinical Therapeutics} \textbf{18},
562--576 (1996) URL:
\url{https://www.sciencedirect.com/science/article/pii/S0149291896802074}.}

\leavevmode\vadjust pre{\hypertarget{ref-wang_2019}{}}%
\CSLLeftMargin{27. }%
\CSLRightInline{Wang, H. \emph{et al.} Genome-wide association analysis
of self-reported daytime sleepiness identifies 42 loci that suggest
biological subtypes. \emph{Nature Communications} \textbf{10}, 3503
(2019)
doi:\href{https://doi.org/10.1038/s41467-019-11456-7}{10.1038/s41467-019-11456-7}.}

\leavevmode\vadjust pre{\hypertarget{ref-aserinsky_1953}{}}%
\CSLLeftMargin{28. }%
\CSLRightInline{Aserinsky, E. \& Kleitman, N. Regularly occurring
periods of eye motility, and concomitant phenomena, during sleep.
\emph{Science (New York, N.Y.)} \textbf{118}, 273--274 (1953)
doi:\href{https://doi.org/10.1126/science.118.3062.273}{10.1126/science.118.3062.273}.}

\leavevmode\vadjust pre{\hypertarget{ref-sadeh_2015}{}}%
\CSLLeftMargin{29. }%
\CSLRightInline{Sadeh, A. Iii. Sleep Assessment Methods.
\emph{Monographs of the Society for Research in Child Development}
\textbf{80}, 33--48 (2015) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/mono.12143}.}

\leavevmode\vadjust pre{\hypertarget{ref-ibuxe1uxf1ez_2018}{}}%
\CSLLeftMargin{30. }%
\CSLRightInline{Ibáñez, V., Silva, J. \& Cauli, O. A survey on sleep
assessment methods. \emph{PeerJ} \textbf{6}, e4849 (2018)
doi:\href{https://doi.org/10.7717/peerj.4849}{10.7717/peerj.4849}.}

\leavevmode\vadjust pre{\hypertarget{ref-roebuck_2014}{}}%
\CSLLeftMargin{31. }%
\CSLRightInline{Roebuck, A. \emph{et al.} A review of signals used in
sleep analysis. \emph{Physiological measurement} \textbf{35}, R1--57
(2014) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4024062/}.}

\leavevmode\vadjust pre{\hypertarget{ref-girschik_validation_2012}{}}%
\CSLLeftMargin{32. }%
\CSLRightInline{Girschik, J., Fritschi, L., Heyworth, J. \& Waters, F.
Validation of self-reported sleep against actigraphy. \emph{J Epidemiol}
\textbf{22}, 462--468 (2012)
doi:\href{https://doi.org/10.2188/jea.je20120012}{10.2188/jea.je20120012}.}

\leavevmode\vadjust pre{\hypertarget{ref-westerterp_2009}{}}%
\CSLLeftMargin{33. }%
\CSLRightInline{Westerterp, K. R. Assessment of physical activity: a
critical appraisal. \emph{European Journal of Applied Physiology}
\textbf{105}, 823--828 (2009)
doi:\href{https://doi.org/10.1007/s00421-009-1000-2}{10.1007/s00421-009-1000-2}.}

\leavevmode\vadjust pre{\hypertarget{ref-lauderdale_2008}{}}%
\CSLLeftMargin{34. }%
\CSLRightInline{Lauderdale, D. S., Knutson, K. L., Yan, L. L., Liu, K.
\& Rathouz, P. J. Sleep duration: How well do self-reports reflect
objective measures? The CARDIA sleep study. \emph{Epidemiology
(Cambridge, Mass.)} \textbf{19}, 838--845 (2008) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2785092/}.}

\leavevmode\vadjust pre{\hypertarget{ref-thurman_2018}{}}%
\CSLLeftMargin{35. }%
\CSLRightInline{Thurman, S. M. \emph{et al.} Individual differences in
compliance and agreement for sleep logs and wrist actigraphy: A
longitudinal study of naturalistic sleep in healthy adults. \emph{PloS
One} \textbf{13}, e0191883 (2018)
doi:\href{https://doi.org/10.1371/journal.pone.0191883}{10.1371/journal.pone.0191883}.}

\leavevmode\vadjust pre{\hypertarget{ref-borbuxe9ly_decades_wrist_2017}{}}%
\CSLLeftMargin{36. }%
\CSLRightInline{Borbély, A. A., Rusterholz, T. \& Achermann, P. Three
decades of continuous wrist-activity recording: analysis of sleep
duration. \emph{Journal of Sleep Research} \textbf{26}, 188--194 (2017)
URL: \url{https://onlinelibrary.wiley.com/doi/abs/10.1111/jsr.12492}.}

\leavevmode\vadjust pre{\hypertarget{ref-cole_automatic_1992}{}}%
\CSLLeftMargin{37. }%
\CSLRightInline{Cole, R. J., Kripke, D. F., Gruen, W., Mullaney, D. J.
\& Gillin, J. C. Automatic sleep/wake identification from wrist
activity. \emph{Sleep} \textbf{15}, 461--469 (1992)
doi:\href{https://doi.org/10.1093/sleep/15.5.461}{10.1093/sleep/15.5.461}.}

\leavevmode\vadjust pre{\hypertarget{ref-sadeh_2011}{}}%
\CSLLeftMargin{38. }%
\CSLRightInline{Sadeh, A. The role and validity of actigraphy in sleep
medicine: An update. \emph{Sleep Medicine Reviews} \textbf{15}, 259--267
(2011) URL:
\url{https://www.sciencedirect.com/science/article/pii/S1087079210001292}.}

\leavevmode\vadjust pre{\hypertarget{ref-jean-louis_2001}{}}%
\CSLLeftMargin{39. }%
\CSLRightInline{Jean-Louis, G., Kripke, D. F., Cole, R. J., Assmus, J.
D. \& Langer, R. D. Sleep detection with an accelerometer actigraph:
comparisons with polysomnography. \emph{Physiology \& Behavior}
\textbf{72}, 21--28 (2001)
doi:\href{https://doi.org/10.1016/s0031-9384(00)00355-3}{10.1016/s0031-9384(00)00355-3}.}

\leavevmode\vadjust pre{\hypertarget{ref-tobin_2021}{}}%
\CSLLeftMargin{40. }%
\CSLRightInline{Tobin, S. Y., Williams, P. G., Baron, K. G., Halliday,
T. M. \& Depner, C. M. Challenges and opportunities for applying
wearable technology to sleep. \emph{Sleep Medicine Clinics} \textbf{16},
607--618 (2021) URL:
\url{https://www.sleep.theclinics.com/article/S1556-407X(21)00054-0/fulltext}.}

\leavevmode\vadjust pre{\hypertarget{ref-hollimon_2022}{}}%
\CSLLeftMargin{41. }%
\CSLRightInline{Hollimon, L. \emph{et al.} Chapter 10 - wearable and
nonwearable sleep-tracking devices. in (ed. Murillo-Rodriguez, E.)
191--214 (Academic Press, 2022). URL:
\url{https://www.sciencedirect.com/science/article/pii/B9780323852357000041}.}

\leavevmode\vadjust pre{\hypertarget{ref-schutte_2021}{}}%
\CSLLeftMargin{42. }%
\CSLRightInline{Schutte, -R. S. \emph{et al.} Evaluating consumer and
clinical sleep technologies: An american academy of sleep medicine
update. \emph{Journal of Clinical Sleep Medicine} \textbf{17},
2275--2282 URL: \url{https://jcsm.aasm.org/doi/10.5664/jcsm.9580}.}

\leavevmode\vadjust pre{\hypertarget{ref-kwon_2021}{}}%
\CSLLeftMargin{43. }%
\CSLRightInline{Kwon, S., Kim, H. \& Yeo, W.-H. Recent advances in
wearable sensors and portable electronics for sleep monitoring.
\emph{iScience} \textbf{24}, 102461 (2021)
doi:\href{https://doi.org/10.1016/j.isci.2021.102461}{10.1016/j.isci.2021.102461}.}

\leavevmode\vadjust pre{\hypertarget{ref-depner_2020}{}}%
\CSLLeftMargin{44. }%
\CSLRightInline{Depner, C. M. \emph{et al.} Wearable technologies for
developing sleep and circadian biomarkers: a summary of workshop
discussions. \emph{Sleep} \textbf{43}, zsz254 (2020)
doi:\href{https://doi.org/10.1093/sleep/zsz254}{10.1093/sleep/zsz254}.}

\leavevmode\vadjust pre{\hypertarget{ref-grandner_2019}{}}%
\CSLLeftMargin{45. }%
\CSLRightInline{Grandner, M. A. \& Rosenberger, M. E. Chapter 12 -
actigraphic sleep tracking and wearables: Historical context, scientific
applications and guidelines, limitations, and considerations for
commercial sleep devices. in (ed. Grandner, M. A.) 147--157 (Academic
Press, 2019). URL:
\url{https://www.sciencedirect.com/science/article/pii/B9780128153734000125}.}

\leavevmode\vadjust pre{\hypertarget{ref-mikkelsen_2019}{}}%
\CSLLeftMargin{46. }%
\CSLRightInline{Mikkelsen, K. B. \emph{et al.} Accurate whole-night
sleep monitoring with dry-contact ear-EEG. \emph{Scientific Reports}
\textbf{9}, 16824 (2019) URL:
\url{https://www.nature.com/articles/s41598-019-53115-3}.}

\leavevmode\vadjust pre{\hypertarget{ref-levendowski_2017}{}}%
\CSLLeftMargin{47. }%
\CSLRightInline{Levendowski, D. J. \emph{et al.} The Accuracy,
Night-to-Night Variability, and Stability of Frontopolar Sleep
Electroencephalography Biomarkers. \emph{Journal of clinical sleep
medicine: JCSM: official publication of the American Academy of Sleep
Medicine} \textbf{13}, 791--803 (2017)
doi:\href{https://doi.org/10.5664/jcsm.6618}{10.5664/jcsm.6618}.}

\leavevmode\vadjust pre{\hypertarget{ref-tobaldini_2013}{}}%
\CSLLeftMargin{48. }%
\CSLRightInline{Tobaldini, E. \emph{et al.} Heart rate variability in
normal and pathological sleep. \emph{Frontiers in Physiology}
\textbf{4}, (2013) URL:
\url{https://www.frontiersin.org/articles/10.3389/fphys.2013.00294}.}

\leavevmode\vadjust pre{\hypertarget{ref-somers_1993}{}}%
\CSLLeftMargin{49. }%
\CSLRightInline{Somers, V. K., Dyken, M. E., Mark, A. L. \& Abboud, F.
M. Sympathetic-nerve activity during sleep in normal subjects. \emph{New
England Journal of Medicine} \textbf{328}, 303--307 (1993) URL:
\url{https://doi.org/10.1056/NEJM199302043280502}.}

\leavevmode\vadjust pre{\hypertarget{ref-radha_sleep_2019}{}}%
\CSLLeftMargin{50. }%
\CSLRightInline{Radha, M. \emph{et al.} Sleep stage classification from
heart-rate variability using long short-term memory neural networks.
\emph{Sci Rep} \textbf{9}, 14149 (2019) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6775145/} Accessed 9
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-kuula_2021}{}}%
\CSLLeftMargin{51. }%
\CSLRightInline{Kuula, L. \& Pesonen, A.-K. Heart Rate Variability and
Firstbeat Method for Detecting Sleep Stages in Healthy Young Adults:
Feasibility Study. \emph{JMIR mHealth and uHealth} \textbf{9}, e24704
(2021) URL: \url{https://mhealth.jmir.org/2021/2/e24704}.}

\leavevmode\vadjust pre{\hypertarget{ref-kinnunen_2020}{}}%
\CSLLeftMargin{52. }%
\CSLRightInline{Kinnunen, H., Rantanen, A., Kenttä, T. \& Koskimäki, H.
Feasible assessment of recovery and cardiovascular health: accuracy of
nocturnal HR and HRV assessed via ring PPG in comparison to medical
grade ECG. \emph{Physiological Measurement} \textbf{41}, 04NT01 (2020)
URL: \url{https://dx.doi.org/10.1088/1361-6579/ab840a}.}

\leavevmode\vadjust pre{\hypertarget{ref-hoogantink_2021}{}}%
\CSLLeftMargin{53. }%
\CSLRightInline{Hoog Antink, C. \emph{et al.} Accuracy of heart rate
variability estimated with reflective wrist-PPG in elderly vascular
patients. \emph{Scientific Reports} \textbf{11}, 8123 (2021) URL:
\url{https://www.nature.com/articles/s41598-021-87489-0}.}

\leavevmode\vadjust pre{\hypertarget{ref-braun_2020}{}}%
\CSLLeftMargin{54. }%
\CSLRightInline{Braun, F. \emph{et al.} Pulse Oximetry at the Wrist
During Sleep: Performance, Challenges and Perspectives. \emph{Annual
International Conference of the IEEE Engineering in Medicine and Biology
Society. IEEE Engineering in Medicine and Biology Society. Annual
International Conference} \textbf{2020}, 5115--5118 (2020)
doi:\href{https://doi.org/10.1109/EMBC44109.2020.9176081}{10.1109/EMBC44109.2020.9176081}.}

\leavevmode\vadjust pre{\hypertarget{ref-preejith_2017}{}}%
\CSLLeftMargin{55. }%
\CSLRightInline{Preejith, S. P., Jeelani, A., Maniyar, P., Joseph, J. \&
Sivaprakasam, M. 2017 IEEE international symposium on medical
measurements and applications (MeMeA). in 171--176 (2017).
doi:\href{https://doi.org/10.1109/MeMeA.2017.7985870}{10.1109/MeMeA.2017.7985870}.}

\leavevmode\vadjust pre{\hypertarget{ref-dehkordi_2011}{}}%
\CSLLeftMargin{56. }%
\CSLRightInline{Dehkordi, P. K., Marzencki, M., Tavakolian, K.,
Kaminska, M. \& Kaminska, B. Validation of respiratory signal derived
from suprasternal notch acceleration for sleep apnea detection.
\emph{Annual International Conference of the IEEE Engineering in
Medicine and Biology Society. IEEE Engineering in Medicine and Biology
Society. Annual International Conference} \textbf{2011}, 3824--3827
(2011)
doi:\href{https://doi.org/10.1109/IEMBS.2011.6090950}{10.1109/IEMBS.2011.6090950}.}

\leavevmode\vadjust pre{\hypertarget{ref-bricout_2019}{}}%
\CSLLeftMargin{57. }%
\CSLRightInline{Bricout, A. \emph{et al.} Adaptive Accelerometry Derived
Respiration: Comparison with Respiratory Inductance Plethysmography
during Sleep. \emph{Annual International Conference of the IEEE
Engineering in Medicine and Biology Society. IEEE Engineering in
Medicine and Biology Society. Annual International Conference}
\textbf{2019}, 6714--6717 (2019)
doi:\href{https://doi.org/10.1109/EMBC.2019.8856561}{10.1109/EMBC.2019.8856561}.}

\leavevmode\vadjust pre{\hypertarget{ref-milici_2018}{}}%
\CSLLeftMargin{58. }%
\CSLRightInline{Milici, S., Lázaro, A., Villarino, R., Girbau, D. \&
Magnarosa, M. Wireless wearable magnetometer-based sensor for sleep
quality monitoring. \emph{IEEE Sensors Journal} \textbf{18}, 2145--2152
(2018)
doi:\href{https://doi.org/10.1109/JSEN.2018.2791400}{10.1109/JSEN.2018.2791400}.}

\leavevmode\vadjust pre{\hypertarget{ref-jarchi_2018}{}}%
\CSLLeftMargin{59. }%
\CSLRightInline{Jarchi, D., Rodgers, S.-J., Tarassenko, L. \& Clifton,
D. A. Accelerometry-based estimation of respiratory rate for
post-intensive care patient monitoring. \emph{IEEE Sensors Journal}
\textbf{18}, (2018) URL:
\url{https://ora.ox.ac.uk/objects/uuid:92aa10da-c801-4f99-be91-a2a8e34ebaea}.}

\leavevmode\vadjust pre{\hypertarget{ref-price_2012}{}}%
\CSLLeftMargin{60. }%
\CSLRightInline{Price, L., Khazova, M. \& O'Hagan, J. Performance
assessment of commercial circadian personal exposure devices.
\emph{Lighting Research \& Technology} \textbf{44}, 17--26 (2012) URL:
\url{https://doi.org/10.1177/1477153511433171}.}

\leavevmode\vadjust pre{\hypertarget{ref-chase_2022}{}}%
\CSLLeftMargin{61. }%
\CSLRightInline{Chase, J. D., Busa, M. A., Staudenmayer, J. W. \&
Sirard, J. R. Sleep Measurement Using Wrist-Worn Accelerometer Data
Compared with Polysomnography. \emph{Sensors (Basel, Switzerland)}
\textbf{22}, 5041 (2022)
doi:\href{https://doi.org/10.3390/s22135041}{10.3390/s22135041}.}

\leavevmode\vadjust pre{\hypertarget{ref-sundararajan_sleep_2021}{}}%
\CSLLeftMargin{62. }%
\CSLRightInline{Sundararajan, K. \emph{et al.} Sleep classification from
wrist-worn accelerometer data using random forests. \emph{Sci Rep}
\textbf{11}, 24 (2021) URL:
\url{https://www.nature.com/articles/s41598-020-79217-x} Accessed 13
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-jortberg_2018}{}}%
\CSLLeftMargin{63. }%
\CSLRightInline{Jortberg, E. \emph{et al.} A novel adhesive biosensor
system for detecting respiration, cardiac, and limb movement signals
during sleep: validation with polysomnography. \emph{Nature and Science
of Sleep} \textbf{10}, 397--408 (2018)
doi:\href{https://doi.org/10.2147/NSS.S179588}{10.2147/NSS.S179588}.}

\leavevmode\vadjust pre{\hypertarget{ref-athavale_2017}{}}%
\CSLLeftMargin{64. }%
\CSLRightInline{Athavale, Y. \emph{et al.} Advanced signal analysis for
the detection of periodic limb movements from bilateral ankle
actigraphy. \emph{Journal of Sleep Research} \textbf{26}, 14--20 (2017)
URL: \url{https://onlinelibrary.wiley.com/doi/abs/10.1111/jsr.12438}.}

\leavevmode\vadjust pre{\hypertarget{ref-razjouyan_2017}{}}%
\CSLLeftMargin{65. }%
\CSLRightInline{Razjouyan, J. \emph{et al.} Improving Sleep Quality
Assessment Using Wearable Sensors by Including Information From
Postural/Sleep Position Changes and Body Acceleration: A Comparison of
Chest-Worn Sensors, Wrist Actigraphy, and Polysomnography. \emph{Journal
of clinical sleep medicine: JCSM: official publication of the American
Academy of Sleep Medicine} \textbf{13}, 1301--1310 (2017)
doi:\href{https://doi.org/10.5664/jcsm.6802}{10.5664/jcsm.6802}.}

\leavevmode\vadjust pre{\hypertarget{ref-dezambotti_2019}{}}%
\CSLLeftMargin{66. }%
\CSLRightInline{Zambotti, M. de, Cellini, N., Goldstone, A., Colrain, I.
M. \& Baker, F. C. Wearable Sleep Technology in Clinical and Research
Settings. \emph{Medicine and Science in Sports and Exercise}
\textbf{51}, 1538--1557 (2019)
doi:\href{https://doi.org/10.1249/MSS.0000000000001947}{10.1249/MSS.0000000000001947}.}

\leavevmode\vadjust pre{\hypertarget{ref-imtiaz_2021}{}}%
\CSLLeftMargin{67. }%
\CSLRightInline{Imtiaz, S. A. A Systematic Review of Sensing
Technologies for Wearable Sleep Staging. \emph{Sensors} \textbf{21},
1562 (2021) URL: \url{https://www.mdpi.com/1424-8220/21/5/1562}.}

\leavevmode\vadjust pre{\hypertarget{ref-paruthi_consensus_2016}{}}%
\CSLLeftMargin{68. }%
\CSLRightInline{Paruthi, S. \emph{et al.} Consensus statement of the
american academy of sleep medicine on the recommended amount of sleep
for healthy children: Methodology and discussion. \emph{J Clin Sleep
Med} \textbf{12}, 1549--1561 (2016)
doi:\href{https://doi.org/10.5664/jcsm.6288}{10.5664/jcsm.6288}.}

\leavevmode\vadjust pre{\hypertarget{ref-tremblay_sedentary_2017}{}}%
\CSLLeftMargin{69. }%
\CSLRightInline{Tremblay, M. S. \emph{et al.} Sedentary behavior
research network ({SBRN}) -- terminology consensus project process and
outcome. \emph{International Journal of Behavioral Nutrition and
Physical Activity} \textbf{14}, 75 (2017) URL:
\url{https://doi.org/10.1186/s12966-017-0525-8} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-liguori_evolving_2023}{}}%
\CSLLeftMargin{70. }%
\CSLRightInline{Liguori, C. \emph{et al.} The evolving role of
quantitative actigraphy in clinical sleep medicine. \emph{Sleep Medicine
Reviews} \textbf{68}, 101762 (2023) URL:
\url{https://www.sciencedirect.com/science/article/pii/S1087079223000187}
Accessed 26 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-hastie01statisticallearning}{}}%
\CSLLeftMargin{71. }%
\CSLRightInline{Hastie, T., Tibshirani, R. \& Friedman, J. \emph{The
elements of statistical learning}. (Springer New York Inc., 2001).}

\leavevmode\vadjust pre{\hypertarget{ref-rosenberger_24-hour_2019}{}}%
\CSLLeftMargin{72. }%
\CSLRightInline{Rosenberger, M. E. \emph{et al.} The 24-hour activity
cycle: A new paradigm for physical activity. \emph{Med Sci Sports Exerc}
\textbf{51}, 454--464 (2019)
doi:\href{https://doi.org/10.1249/MSS.0000000000001811}{10.1249/MSS.0000000000001811}.}

\leavevmode\vadjust pre{\hypertarget{ref-welk_reliability_2004}{}}%
\CSLLeftMargin{73. }%
\CSLRightInline{Welk, G. J., Schaben, J. A. \& Morrow, J. R.
\href{https://www.ncbi.nlm.nih.gov/pubmed/15354049}{Reliability of
accelerometry-based activity monitors: A generalizability study}.
\emph{Med Sci Sports Exerc} \textbf{36}, 1637--1645 (2004).}

\leavevmode\vadjust pre{\hypertarget{ref-migueles_comparability_2019}{}}%
\CSLLeftMargin{74. }%
\CSLRightInline{Migueles, J. H. \emph{et al.} Comparability of
accelerometer signal aggregation metrics across placements and dominant
wrist cut points for the assessment of physical activity in adults.
\emph{Sci Rep} \textbf{9}, 18235 (2019) URL:
\url{https://www.nature.com/articles/s41598-019-54267-y} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-fiorillo_automated_2019}{}}%
\CSLLeftMargin{75. }%
\CSLRightInline{Fiorillo, L. \emph{et al.} Automated sleep scoring: A
review of the latest approaches. \emph{Sleep Med Rev} \textbf{48},
101204 (2019)
doi:\href{https://doi.org/10.1016/j.smrv.2019.07.007}{10.1016/j.smrv.2019.07.007}.}

\leavevmode\vadjust pre{\hypertarget{ref-van_der_ploeg_modern_2014}{}}%
\CSLLeftMargin{76. }%
\CSLRightInline{Ploeg, T. van der, Austin, P. C. \& Steyerberg, E. W.
Modern modelling techniques are data hungry: A simulation study for
predicting dichotomous endpoints. \emph{{BMC} Med Res Methodol}
\textbf{14}, 137 (2014)
doi:\href{https://doi.org/10.1186/1471-2288-14-137}{10.1186/1471-2288-14-137}.}

\leavevmode\vadjust pre{\hypertarget{ref-chaput_systematic_2017}{}}%
\CSLLeftMargin{77. }%
\CSLRightInline{Chaput, J.-P. \emph{et al.} Systematic review of the
relationships between sleep duration and health indicators in the early
years (0-4~years). \emph{{BMC} Public Health} \textbf{17}, 855 (2017)
doi:\href{https://doi.org/10.1186/s12889-017-4850-2}{10.1186/s12889-017-4850-2}.}

\leavevmode\vadjust pre{\hypertarget{ref-chaput_systematic_2016}{}}%
\CSLLeftMargin{78. }%
\CSLRightInline{Chaput, J.-P. \emph{et al.} Systematic review of the
relationships between sleep duration and health indicators in
school-aged children and youth. \emph{Appl Physiol Nutr Metab}
\textbf{41}, S266--282 (2016)
doi:\href{https://doi.org/10.1139/apnm-2015-0627}{10.1139/apnm-2015-0627}.}

\leavevmode\vadjust pre{\hypertarget{ref-st-onge_sleep_2016}{}}%
\CSLLeftMargin{79. }%
\CSLRightInline{St-Onge, M.-P. \emph{et al.} Sleep duration and quality:
Impact on lifestyle behaviors and cardiometabolic health: A scientific
statement from the american heart association. \emph{Circulation}
\textbf{134}, e367--e386 (2016)
doi:\href{https://doi.org/10.1161/CIR.0000000000000444}{10.1161/CIR.0000000000000444}.}

\leavevmode\vadjust pre{\hypertarget{ref-gruber_position_2014}{}}%
\CSLLeftMargin{80. }%
\CSLRightInline{Gruber, R. \emph{et al.}
\href{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4197518}{Position
statement on pediatric sleep for psychiatrists}. \emph{J Can Acad Child
Adolesc Psychiatry} \textbf{23}, 174--195 (2014).}

\leavevmode\vadjust pre{\hypertarget{ref-haghayegh_application_2020}{}}%
\CSLLeftMargin{81. }%
\CSLRightInline{Haghayegh, S., Khoshnevis, S., Smolensky, M. H. \&
Diller, K. R. Application of deep learning to improve sleep scoring of
wrist actigraphy. \emph{Sleep Med} \textbf{74}, 235--241 (2020)
doi:\href{https://doi.org/10.1016/j.sleep.2020.05.008}{10.1016/j.sleep.2020.05.008}.}

\leavevmode\vadjust pre{\hypertarget{ref-vaughn_technical_2008}{}}%
\CSLLeftMargin{82. }%
\CSLRightInline{Vaughn, B. V. \& Giallanza, P. Technical review of
polysomnography. \emph{Chest} \textbf{134}, 1310--1319 (2008)
doi:\href{https://doi.org/10.1378/chest.08-0812}{10.1378/chest.08-0812}.}

\leavevmode\vadjust pre{\hypertarget{ref-van_de_water_objective_2011}{}}%
\CSLLeftMargin{83. }%
\CSLRightInline{Van De Water, A. T. M., Holmes, A. \& Hurley, D. A.
Objective measurements of sleep for non-laboratory settings as
alternatives to polysomnography -- a systematic review. \emph{Journal of
Sleep Research} \textbf{20}, 183--200 (2011) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2869.2009.00814.x}
Accessed 21 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-younes_staging_2016}{}}%
\CSLLeftMargin{84. }%
\CSLRightInline{Younes, M., Raneri, J. \& Hanly, P. Staging sleep in
polysomnograms: Analysis of inter-scorer variability. \emph{J Clin Sleep
Med} \textbf{12}, 885--894 (2016)
doi:\href{https://doi.org/10.5664/jcsm.5894}{10.5664/jcsm.5894}.}

\leavevmode\vadjust pre{\hypertarget{ref-dafna_sleep-wake_2015}{}}%
\CSLLeftMargin{85. }%
\CSLRightInline{Dafna, E., Tarasiuk, A. \& Zigel, Y. Sleep-wake
evaluation from whole-night non-contact audio recordings of breathing
sounds. \emph{{PLOS} {ONE}} \textbf{10}, e0117382 (2015) URL:
\url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0117382}
Accessed 5 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-montazeri_ghahjaverestan_sleepwakefulness_2020}{}}%
\CSLLeftMargin{86. }%
\CSLRightInline{Montazeri Ghahjaverestan, N. \emph{et al.}
Sleep/wakefulness detection using tracheal sounds and movements.
\emph{Nat Sci Sleep} \textbf{12}, 1009--1021 (2020)
doi:\href{https://doi.org/10.2147/NSS.S276107}{10.2147/NSS.S276107}.}

\leavevmode\vadjust pre{\hypertarget{ref-hees_novel_2015}{}}%
\CSLLeftMargin{87. }%
\CSLRightInline{Hees, V. T. van \emph{et al.} A novel, open access
method to assess sleep duration using a wrist-worn accelerometer.
\emph{{PLOS} {ONE}} \textbf{10}, e0142533 (2015) URL:
\url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142533}
Accessed 13 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-madsen_actigraphy_2013}{}}%
\CSLLeftMargin{88. }%
\CSLRightInline{Madsen, M. T., Rosenberg, J. \& Gögenur, I. Actigraphy
for measurement of sleep and sleep-wake rhythms in relation to surgery.
\emph{J Clin Sleep Med} \textbf{9}, 387--394 (2013)
doi:\href{https://doi.org/10.5664/jcsm.2598}{10.5664/jcsm.2598}.}

\leavevmode\vadjust pre{\hypertarget{ref-schwab_actigraphy_2018}{}}%
\CSLLeftMargin{89. }%
\CSLRightInline{Schwab, K. E. \emph{et al.} Actigraphy to evaluate sleep
in the intensive care unit. A systematic review. \emph{Ann Am Thorac
Soc} \textbf{15}, 1075--1082 (2018)
doi:\href{https://doi.org/10.1513/AnnalsATS.201801-004OC}{10.1513/AnnalsATS.201801-004OC}.}

\leavevmode\vadjust pre{\hypertarget{ref-barouni_ambulatory_2020}{}}%
\CSLLeftMargin{90. }%
\CSLRightInline{Barouni, A. \emph{et al.} Ambulatory sleep scoring using
accelerometers-distinguishing between nonwear and sleep/wake states.
\emph{{PeerJ}} \textbf{8}, e8284 (2020)
doi:\href{https://doi.org/10.7717/peerj.8284}{10.7717/peerj.8284}.}

\leavevmode\vadjust pre{\hypertarget{ref-skovgaard_manual_2021}{}}%
\CSLLeftMargin{91. }%
\CSLRightInline{Skovgaard, E. L., Pedersen, J., Møller, N. C., Grøntved,
A. \& Brønd, J. C. Manual annotation of time in bed using free-living
recordings of accelerometry data. \emph{Sensors (Basel)} \textbf{21},
8442 (2021)
doi:\href{https://doi.org/10.3390/s21248442}{10.3390/s21248442}.}

\leavevmode\vadjust pre{\hypertarget{ref-rasmussen_feasibility_2021}{}}%
\CSLLeftMargin{92. }%
\CSLRightInline{Rasmussen, M. G. B. \emph{et al.} Feasibility of two
screen media reduction interventions: Results from the {SCREENS} pilot
trial. \emph{{PLOS} {ONE}} \textbf{16}, e0259657 (2021) URL:
\url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0259657}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-rasmussen_short-term_2020}{}}%
\CSLLeftMargin{93. }%
\CSLRightInline{Rasmussen, M. G. B. \emph{et al.} Short-term efficacy of
reducing screen media use on physical activity, sleep, and physiological
stress in families with children aged 4--14: Study protocol for the
{SCREENS} randomized controlled trial. \emph{{BMC} Public Health}
\textbf{20}, 380 (2020) URL:
\url{https://doi.org/10.1186/s12889-020-8458-6} Accessed 12 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-pedersen_self-administered_2021}{}}%
\CSLLeftMargin{94. }%
\CSLRightInline{Pedersen, J., Rasmussen, M. G. B., Olesen, L. G.,
Kristensen, P. L. \& Grøntved, A. Self-administered
electroencephalography-based sleep assessment: Compliance and perceived
feasibility in children and adults. \emph{Sleep Science and Practice}
\textbf{5}, 8 (2021) URL:
\url{https://doi.org/10.1186/s41606-021-00059-1} Accessed 22 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-jaeschke_variability_2018}{}}%
\CSLLeftMargin{95. }%
\CSLRightInline{Jaeschke, L., Steinbrecher, A., Jeran, S., Konigorski,
S. \& Pischon, T. Variability and reliability study of overall physical
activity and activity intensity levels using 24~h-accelerometry-assessed
data. \emph{{BMC} Public Health} \textbf{18}, 530 (2018) URL:
\url{https://doi.org/10.1186/s12889-018-5415-8} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-wang_evaluation_2015}{}}%
\CSLLeftMargin{96. }%
\CSLRightInline{Wang, Y., Loparo, K. A., Kelly, M. R. \& Kaplan, R. F.
Evaluation of an automated single-channel sleep staging algorithm.
\emph{Nat Sci Sleep} \textbf{7}, 101--111 (2015) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4583116/} Accessed 13
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-kaplan_performance_2014}{}}%
\CSLLeftMargin{97. }%
\CSLRightInline{Kaplan, R. F., Wang, Y., Loparo, K. A., Kelly, M. R. \&
Bootzin, R. R. Performance evaluation of an automated single-channel
sleep--wake detection algorithm. \emph{Nat Sci Sleep} \textbf{6},
113--122 (2014) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4206400/} Accessed 13
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-audacity}{}}%
\CSLLeftMargin{98. }%
\CSLRightInline{Audacity Team. Audacity\textregistered{} software is
copyright © 1999--2021 audacity team. (2021).}

\leavevmode\vadjust pre{\hypertarget{ref-skotte_detection_2014}{}}%
\CSLLeftMargin{99. }%
\CSLRightInline{Skotte, J., Korshøj, M., Kristiansen, J., Hanisch, C. \&
Holtermann, A. Detection of physical activity types using triaxial
accelerometers. \emph{Journal of Physical Activity and Health}
\textbf{11}, 76--84 (2014) URL:
\url{https://journals.humankinetics.com/view/journals/jpah/11/1/article-p76.xml}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-koo_guideline_2016}{}}%
\CSLLeftMargin{100. }%
\CSLRightInline{Koo, T. K. \& Li, M. Y. A guideline of selecting and
reporting intraclass correlation coefficients for reliability research.
\emph{J Chiropr Med} \textbf{15}, 155--163 (2016)
doi:\href{https://doi.org/10.1016/j.jcm.2016.02.012}{10.1016/j.jcm.2016.02.012}.}

\leavevmode\vadjust pre{\hypertarget{ref-bland_measuring_1999}{}}%
\CSLLeftMargin{101. }%
\CSLRightInline{Bland, J. M. \& Altman, D. G. Measuring agreement in
method comparison studies. \emph{Stat Methods Med Res} \textbf{8},
135--160 (1999) URL: \url{https://doi.org/10.1177/096228029900800204}
Accessed 9 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-van_hees_estimating_2018}{}}%
\CSLLeftMargin{102. }%
\CSLRightInline{Hees, V. T. van \emph{et al.} Estimating sleep
parameters using an accelerometer without sleep diary. \emph{Sci Rep}
\textbf{8}, 12975 (2018)
doi:\href{https://doi.org/10.1038/s41598-018-31266-z}{10.1038/s41598-018-31266-z}.}

\leavevmode\vadjust pre{\hypertarget{ref-aili_reliability_2017}{}}%
\CSLLeftMargin{103. }%
\CSLRightInline{Aili, K., Åström-Paulsson, S., Stoetzer, U.,
Svartengren, M. \& Hillert, L. Reliability of actigraphy and subjective
sleep measurements in adults: The design of sleep assessments. \emph{J
Clin Sleep Med} \textbf{13}, 39--47 (2017)
doi:\href{https://doi.org/10.5664/jcsm.6384}{10.5664/jcsm.6384}.}

\leavevmode\vadjust pre{\hypertarget{ref-label_studio}{}}%
\CSLLeftMargin{104. }%
\CSLRightInline{Open Source Data Labeling. URL:
\url{https://labelstud.io/}.}

\leavevmode\vadjust pre{\hypertarget{ref-visplore}{}}%
\CSLLeftMargin{105. }%
\CSLRightInline{Visplore {\textendash} software for visual time series
analysis. URL: \url{https://visplore.com/home-11-2022/}.}

\leavevmode\vadjust pre{\hypertarget{ref-yavuz-kodat_2019}{}}%
\CSLLeftMargin{106. }%
\CSLRightInline{Yavuz-Kodat, E. \emph{et al.} Validity of Actigraphy
Compared to Polysomnography for Sleep Assessment in Children With Autism
Spectrum Disorder. \emph{Frontiers in Psychiatry} \textbf{10}, 551
(2019)
doi:\href{https://doi.org/10.3389/fpsyt.2019.00551}{10.3389/fpsyt.2019.00551}.}

\leavevmode\vadjust pre{\hypertarget{ref-littner_2003}{}}%
\CSLLeftMargin{107. }%
\CSLRightInline{Littner, M. \emph{et al.} Practice parameters for the
role of actigraphy in the study of sleep and circadian rhythms: an
update for 2002. \emph{Sleep} \textbf{26}, 337--341 (2003)
doi:\href{https://doi.org/10.1093/sleep/26.3.337}{10.1093/sleep/26.3.337}.}

\leavevmode\vadjust pre{\hypertarget{ref-lockley_1999}{}}%
\CSLLeftMargin{108. }%
\CSLRightInline{Lockley, S. W., Skene, D. J. \& Arendt, J. Comparison
between subjective and actigraphic measurement of sleep and sleep
rhythms. \emph{Journal of Sleep Research} \textbf{8}, 175--183 (1999)
URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2869.1999.00155.x}.}

\leavevmode\vadjust pre{\hypertarget{ref-aasm}{}}%
\CSLLeftMargin{109. }%
\CSLRightInline{AASM scoring manual - american academy of sleep
medicine. URL:
\url{https://aasm.org/clinical-resources/scoring-manual/}.}

\leavevmode\vadjust pre{\hypertarget{ref-skovgaard_generalizability_2023}{}}%
\CSLLeftMargin{110. }%
\CSLRightInline{Skovgaard, E. L. \emph{et al.} Generalizability and
performance of methods to detect non-wear with free-living accelerometer
recordings. \emph{Sci Rep} \textbf{13}, 2496 (2023) URL:
\url{https://www.nature.com/articles/s41598-023-29666-x} Accessed 26
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-pedersen_protocol_2018}{}}%
\CSLLeftMargin{111. }%
\CSLRightInline{Pedersen, N. H. \emph{et al.} Protocol for evaluating
the impact of a national school policy on physical activity levels in
danish children and adolescents: The PHASAR study - a natural
experiment. \emph{BMC Public Health} \textbf{18}, 1245 (2018) URL:
\url{https://doi.org/10.1186/s12889-018-6144-8}.}

\leavevmode\vadjust pre{\hypertarget{ref-hecht_methodology_2009}{}}%
\CSLLeftMargin{112. }%
\CSLRightInline{Hecht, A., Ma, S., Porszasz, J., Casaburi, R. \& COPD
Clinical Research Network. Methodology for using long-term accelerometry
monitoring to describe daily activity patterns in {COPD}. \emph{{COPD}}
\textbf{6}, 121--129 (2009)
doi:\href{https://doi.org/10.1080/15412550902755044}{10.1080/15412550902755044}.}

\leavevmode\vadjust pre{\hypertarget{ref-troiano_physical_2008}{}}%
\CSLLeftMargin{113. }%
\CSLRightInline{Troiano, R. P. \emph{et al.} Physical activity in the
united states measured by accelerometer. \emph{Med Sci Sports Exerc}
\textbf{40}, 181--188 (2008)
doi:\href{https://doi.org/10.1249/mss.0b013e31815a51b3}{10.1249/mss.0b013e31815a51b3}.}

\leavevmode\vadjust pre{\hypertarget{ref-choi_validation_2011}{}}%
\CSLLeftMargin{114. }%
\CSLRightInline{Choi, L., Liu, Z., Matthews, C. E. \& Buchowski, M. S.
Validation of accelerometer wear and nonwear time classification
algorithm. \emph{Med Sci Sports Exerc} \textbf{43}, 357--364 (2011)
doi:\href{https://doi.org/10.1249/MSS.0b013e3181ed61a3}{10.1249/MSS.0b013e3181ed61a3}.}

\leavevmode\vadjust pre{\hypertarget{ref-van_hees_estimation_2011}{}}%
\CSLLeftMargin{115. }%
\CSLRightInline{Hees, V. T. van \emph{et al.} Estimation of daily energy
expenditure in pregnant and non-pregnant women using a wrist-worn
tri-axial accelerometer. \emph{{PLoS} One} \textbf{6}, e22922 (2011)
doi:\href{https://doi.org/10.1371/journal.pone.0022922}{10.1371/journal.pone.0022922}.}

\leavevmode\vadjust pre{\hypertarget{ref-syed_evaluating_2020}{}}%
\CSLLeftMargin{116. }%
\CSLRightInline{Syed, S., Morseth, B., Hopstock, L. A. \& Horsch, A.
Evaluating the performance of raw and epoch non-wear algorithms using
multiple accelerometers and electrocardiogram recordings. \emph{Sci Rep}
\textbf{10}, 5866 (2020) URL:
\url{https://www.nature.com/articles/s41598-020-62821-2} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-syed_novel_2021}{}}%
\CSLLeftMargin{117. }%
\CSLRightInline{Syed, S., Morseth, B., Hopstock, L. A. \& Horsch, A. A
novel algorithm to detect non-wear time from raw accelerometer data
using deep convolutional neural networks. \emph{Sci Rep} \textbf{11},
8832 (2021) URL:
\url{https://www.nature.com/articles/s41598-021-87757-z} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-kuhn_tidymodels_2020}{}}%
\CSLLeftMargin{118. }%
\CSLRightInline{Kuhn, M. \& Wickham, H. \emph{Tidymodels: A collection
of packages for modeling and machine learning using tidyverse
principles.} (2020). URL: \url{https://www.tidymodels.org}.}

\leavevmode\vadjust pre{\hypertarget{ref-rpart}{}}%
\CSLLeftMargin{119. }%
\CSLRightInline{Therneau, T. \& Atkinson, B. \emph{Rpart: Recursive
partitioning and regression trees}. (2022). URL:
\url{https://CRAN.R-project.org/package=rpart}.}

\leavevmode\vadjust pre{\hypertarget{ref-aadland_comparison_2018}{}}%
\CSLLeftMargin{120. }%
\CSLRightInline{Aadland, E., Andersen, L. B., Anderssen, S. A. \&
Resaland, G. K. A comparison of 10 accelerometer non-wear time criteria
and logbooks in children. \emph{{BMC} Public Health} \textbf{18}, 323
(2018) URL: \url{https://doi.org/10.1186/s12889-018-5212-4} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-hutto_identifying_2013}{}}%
\CSLLeftMargin{121. }%
\CSLRightInline{Hutto, B. \emph{et al.} Identifying accelerometer
nonwear and wear time in older adults. \emph{International Journal of
Behavioral Nutrition and Physical Activity} \textbf{10}, 120 (2013) URL:
\url{https://doi.org/10.1186/1479-5868-10-120} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-cooper_objectively_2015}{}}%
\CSLLeftMargin{122. }%
\CSLRightInline{Cooper, A. R. \emph{et al.} Objectively measured
physical activity and sedentary time in youth: The international
children's accelerometry database ({ICAD}). \emph{International Journal
of Behavioral Nutrition and Physical Activity} \textbf{12}, 113 (2015)
URL: \url{https://doi.org/10.1186/s12966-015-0274-5} Accessed 5 August
2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-kwon_breaks_2012}{}}%
\CSLLeftMargin{123. }%
\CSLRightInline{Kwon, S., Burns, T. L., Levy, S. M. \& Janz, K. F.
Breaks in sedentary time during childhood and adolescence: Iowa bone
development study. \emph{Med Sci Sports Exerc} \textbf{44}, 1075--1080
(2012) URL: \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3623750/}
Accessed 5 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-duncan_wear-time_2018}{}}%
\CSLLeftMargin{124. }%
\CSLRightInline{Duncan, S. \emph{et al.} Wear-time compliance with a
dual-accelerometer system for capturing 24-h behavioural profiles in
children and adults. \emph{Int J Environ Res Public Health} \textbf{15},
1296 (2018)
doi:\href{https://doi.org/10.3390/ijerph15071296}{10.3390/ijerph15071296}.}

\leavevmode\vadjust pre{\hypertarget{ref-doherty_large_2017}{}}%
\CSLLeftMargin{125. }%
\CSLRightInline{Doherty, A. \emph{et al.} Large scale population
assessment of physical activity using wrist worn accelerometers: The
{UK} biobank study. \emph{{PLOS} {ONE}} \textbf{12}, e0169649 (2017)
URL:
\url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169649}
Accessed 12 July 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-vert_detecting_2022}{}}%
\CSLLeftMargin{126. }%
\CSLRightInline{Vert, A. \emph{et al.} Detecting accelerometer non-wear
periods using change in acceleration combined with rate-of-change in
temperature. \emph{{BMC} Medical Research Methodology} \textbf{22}, 147
(2022) URL: \url{https://doi.org/10.1186/s12874-022-01633-6} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-zhou_classification_2015}{}}%
\CSLLeftMargin{127. }%
\CSLRightInline{Zhou, S.-M. \emph{et al.} Classification of
accelerometer wear and non-wear events in seconds for monitoring
free-living physical activity. \emph{{BMJ} Open} \textbf{5}, e007447
(2015) URL: \url{https://bmjopen.bmj.com/content/5/5/e007447} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-steyerberg_prediction_2016}{}}%
\CSLLeftMargin{128. }%
\CSLRightInline{Steyerberg, E. W. \& Harrell, F. E. Prediction models
need appropriate internal, internal-external, and external validation.
\emph{J Clin Epidemiol} \textbf{69}, 245--247 (2016)
doi:\href{https://doi.org/10.1016/j.jclinepi.2015.04.005}{10.1016/j.jclinepi.2015.04.005}.}

\leavevmode\vadjust pre{\hypertarget{ref-altman_prognosis_2009}{}}%
\CSLLeftMargin{129. }%
\CSLRightInline{Altman, D. G., Vergouwe, Y., Royston, P. \& Moons, K. G.
M. Prognosis and prognostic research: Validating a prognostic model.
\emph{{BMJ}} \textbf{338}, b605 (2009) URL:
\url{https://www.bmj.com/content/338/bmj.b605} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-pedersen_effects_2022}{}}%
\CSLLeftMargin{130. }%
\CSLRightInline{Pedersen, J. \emph{et al.} Effects of Limiting
Recreational Screen Media Use on Physical Activity and Sleep in Families
With Children: A Cluster Randomized Clinical Trial. \emph{JAMA
pediatrics} \textbf{176}, 741--749 (2022)
doi:\href{https://doi.org/10.1001/jamapediatrics.2022.1519}{10.1001/jamapediatrics.2022.1519}.}

\leavevmode\vadjust pre{\hypertarget{ref-walch_sleep_2019}{}}%
\CSLLeftMargin{131. }%
\CSLRightInline{Walch, O., Huang, Y., Forger, D. \& Goldstein, C. Sleep
stage prediction with raw acceleration and photoplethysmography heart
rate data derived from a consumer wearable device. \emph{Sleep}
\textbf{42}, zsz180 (2019) URL:
\url{https://doi.org/10.1093/sleep/zsz180} Accessed 13 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-galland_2018}{}}%
\CSLLeftMargin{132. }%
\CSLRightInline{Galland, B. C. \emph{et al.} Establishing normal values
for pediatric nighttime sleep measured by actigraphy: a systematic
review and meta-analysis. \emph{Sleep} \textbf{41}, (2018)
doi:\href{https://doi.org/10.1093/sleep/zsy017}{10.1093/sleep/zsy017}.}

\leavevmode\vadjust pre{\hypertarget{ref-ohayon_2017}{}}%
\CSLLeftMargin{133. }%
\CSLRightInline{Ohayon, M. \emph{et al.} National Sleep Foundation's
sleep quality recommendations: first report. \emph{Sleep Health}
\textbf{3}, 6--19 (2017)
doi:\href{https://doi.org/10.1016/j.sleh.2016.11.006}{10.1016/j.sleh.2016.11.006}.}

\leavevmode\vadjust pre{\hypertarget{ref-galland_normal_2012}{}}%
\CSLLeftMargin{134. }%
\CSLRightInline{Galland, B. C., Taylor, B. J., Elder, D. E. \& Herbison,
P. Normal sleep patterns in infants and children: A systematic review of
observational studies. \emph{Sleep Med Rev} \textbf{16}, 213--222 (2012)
doi:\href{https://doi.org/10.1016/j.smrv.2011.06.001}{10.1016/j.smrv.2011.06.001}.}

\leavevmode\vadjust pre{\hypertarget{ref-hochreiter_long_1997}{}}%
\CSLLeftMargin{135. }%
\CSLRightInline{Hochreiter, S. \& Schmidhuber, J. Long short-term
memory. \emph{Neural Computation} \textbf{9}, 1735--1780 (1997) URL:
\url{https://doi.org/10.1162/neco.1997.9.8.1735} Accessed 12 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-sano_multimodal_2019}{}}%
\CSLLeftMargin{136. }%
\CSLRightInline{Sano, A., Chen, W., Lopez-Martinez, D., Taylor, S. \&
Picard, R. W. Multimodal ambulatory sleep detection using {LSTM}
recurrent neural networks. \emph{{IEEE} J Biomed Health Inform}
\textbf{23}, 1607--1617 (2019)
doi:\href{https://doi.org/10.1109/JBHI.2018.2867619}{10.1109/JBHI.2018.2867619}.}

\leavevmode\vadjust pre{\hypertarget{ref-chen_attention_2021}{}}%
\CSLLeftMargin{137. }%
\CSLRightInline{Chen, Z., Wu, M., Cui, W., Liu, C. \& Li, X. An
attention based {CNN}-{LSTM} approach for sleep-wake detection with
heterogeneous sensors. \emph{{IEEE} J Biomed Health Inform} \textbf{25},
3270--3277 (2021)
doi:\href{https://doi.org/10.1109/JBHI.2020.3006145}{10.1109/JBHI.2020.3006145}.}

\leavevmode\vadjust pre{\hypertarget{ref-friedman_glmnet_2010}{}}%
\CSLLeftMargin{138. }%
\CSLRightInline{Friedman, J., Hastie, T. \& Tibshirani, R.
Regularization Paths for Generalized Linear Models via Coordinate
Descent. \emph{Journal of Statistical Software} \textbf{33}, 1--22
(2010).}

\leavevmode\vadjust pre{\hypertarget{ref-nnet}{}}%
\CSLLeftMargin{139. }%
\CSLRightInline{Venables, W. N. \& Ripley, B. D. \emph{Modern applied
statistics with s}. (Springer, 2002). URL:
\url{https://www.stats.ox.ac.uk/pub/MASS4/}.}

\leavevmode\vadjust pre{\hypertarget{ref-xgboost}{}}%
\CSLLeftMargin{140. }%
\CSLRightInline{Chen, T. \emph{et al.} \emph{Xgboost: Extreme gradient
boosting}. (2023). URL:
\url{https://CRAN.R-project.org/package=xgboost}.}

\leavevmode\vadjust pre{\hypertarget{ref-chawla_smote_2002}{}}%
\CSLLeftMargin{141. }%
\CSLRightInline{Chawla, N. V., Bowyer, K. W., Hall, L. O. \& Kegelmeyer,
W. P. {SMOTE}: Synthetic minority over-sampling technique. \emph{Journal
of Artificial Intelligence Research} \textbf{16}, 321--357 (2002) URL:
\url{https://www.jair.org/index.php/jair/article/view/10302} Accessed 22
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-themis}{}}%
\CSLLeftMargin{142. }%
\CSLRightInline{Hvitfeldt, E. \emph{Themis: Extra recipes steps for
dealing with unbalanced data}. (2023). URL:
\url{https://CRAN.R-project.org/package=themis}.}

\leavevmode\vadjust pre{\hypertarget{ref-hjorth_measure_2012}{}}%
\CSLLeftMargin{143. }%
\CSLRightInline{Hjorth, M. F. \emph{et al.} Measure of sleep and
physical activity by a single accelerometer: Can a waist-worn actigraph
adequately measure sleep in children? \emph{Sleep and Biological
Rhythms} \textbf{10}, 328--335 (2012) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1479-8425.2012.00578.x}
Accessed 20 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-kushida_comparison_2001}{}}%
\CSLLeftMargin{144. }%
\CSLRightInline{Kushida, C. A. \emph{et al.} Comparison of actigraphic,
polysomnographic, and subjective assessment of sleep parameters in
sleep-disordered patients. \emph{Sleep Med} \textbf{2}, 389--396 (2001)
doi:\href{https://doi.org/10.1016/s1389-9457(00)00098-8}{10.1016/s1389-9457(00)00098-8}.}

\leavevmode\vadjust pre{\hypertarget{ref-rcoreteam_2023}{}}%
\CSLLeftMargin{145. }%
\CSLRightInline{R Core Team. \emph{R: A language and environment for
statistical computing}. (R Foundation for Statistical Computing, 2023).
URL: \url{https://www.R-project.org/}.}

\leavevmode\vadjust pre{\hypertarget{ref-wickham_tidyverse_2019}{}}%
\CSLLeftMargin{146. }%
\CSLRightInline{Wickham, H. \emph{et al.} Welcome to the tidyverse.
\emph{Journal of Open Source Software} \textbf{4}, 1686 (2019)
doi:\href{https://doi.org/10.21105/joss.01686}{10.21105/joss.01686}.}

\leavevmode\vadjust pre{\hypertarget{ref-vanrossum_python_2009}{}}%
\CSLLeftMargin{147. }%
\CSLRightInline{Van Rossum, G. \& Drake, F. L. \emph{Python 3 reference
manual}. (CreateSpace, 2009).}

\leavevmode\vadjust pre{\hypertarget{ref-paszke_pytorch_2019}{}}%
\CSLLeftMargin{148. }%
\CSLRightInline{Paszke, A. \emph{et al.} PyTorch: An imperative style,
high-performance deep learning library. in 80248035 (Curran Associates,
Inc., 2019). URL:
\url{http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}.}

\leavevmode\vadjust pre{\hypertarget{ref-carlson_validity_2021}{}}%
\CSLLeftMargin{149. }%
\CSLRightInline{Carlson, J. A. \emph{et al.} Validity of two awake
wear-time classification algorithms for {activPAL} in youth, adults, and
older adults. \emph{Journal for the Measurement of Physical Behaviour}
\textbf{4}, 151--162 (2021) URL:
\url{https://journals.humankinetics.com/view/journals/jmpb/4/2/article-p151.xml}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-winkler_identifying_2016}{}}%
\CSLLeftMargin{150. }%
\CSLRightInline{Winkler, E. A. H. \emph{et al.} Identifying adults'
valid waking wear time by automated estimation in {activPAL} data
collected with a 24 h wear protocol. \emph{Physiol. Meas.} \textbf{37},
1653 (2016) URL: \url{https://dx.doi.org/10.1088/0967-3334/37/10/1653}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-inan-eroglu_comparison_2021}{}}%
\CSLLeftMargin{151. }%
\CSLRightInline{Inan-Eroglu, E. \emph{et al.} Comparison of a thigh-worn
accelerometer algorithm with diary estimates of time in bed and time
asleep: The 1970 british cohort study. \emph{Journal for the Measurement
of Physical Behaviour} \textbf{4}, 60--67 (2021) URL:
\url{https://journals.humankinetics.com/view/journals/jmpb/4/1/article-p60.xml}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-van_der_berg_identifying_2016}{}}%
\CSLLeftMargin{152. }%
\CSLRightInline{Berg, J. D. van der \emph{et al.} Identifying waking
time in 24-h accelerometry data in adults using an automated algorithm.
\emph{Journal of Sports Sciences} \textbf{34}, 1867--1873 (2016) URL:
\url{https://doi.org/10.1080/02640414.2016.1140908} Accessed 12 June
2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-johansson_development_2023}{}}%
\CSLLeftMargin{153. }%
\CSLRightInline{Johansson, P. J. \emph{et al.} Development and
performance of a sleep estimation algorithm using a single accelerometer
placed on the thigh: An evaluation against polysomnography.
\emph{Journal of Sleep Research} \textbf{32}, e13725 (2023) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/jsr.13725} Accessed
9 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-conley_agreement_2019}{}}%
\CSLLeftMargin{154. }%
\CSLRightInline{Conley, S. \emph{et al.} Agreement between actigraphic
and polysomnographic measures of sleep in adults with and without
chronic conditions: A systematic review and meta-analysis. \emph{Sleep
Medicine Reviews} \textbf{46}, 151--160 (2019) URL:
\url{https://www.sciencedirect.com/science/article/pii/S108707921930019X}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-patterson_40_2023}{}}%
\CSLLeftMargin{155. }%
\CSLRightInline{Patterson, M. R. \emph{et al.} 40 years of actigraphy in
sleep medicine and current state of the art algorithms. \emph{npj Digit.
Med.} \textbf{6}, 1--7 (2023) URL:
\url{https://www.nature.com/articles/s41746-023-00802-1} Accessed 9 June
2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-anderson_assessment_2014}{}}%
\CSLLeftMargin{156. }%
\CSLRightInline{Anderson, K. N. \emph{et al.} Assessment of sleep and
circadian rhythm disorders in the very old: The newcastle 85+ cohort
study. \emph{Age and Ageing} \textbf{43}, 57--63 (2014) URL:
\url{https://doi.org/10.1093/ageing/aft153} Accessed 12 July 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-plekhanova_validation_2023}{}}%
\CSLLeftMargin{157. }%
\CSLRightInline{Plekhanova, T. \emph{et al.} Validation of an automated
sleep detection algorithm using data from multiple accelerometer brands.
\emph{J Sleep Res} \textbf{32}, e13760 (2023)
doi:\href{https://doi.org/10.1111/jsr.13760}{10.1111/jsr.13760}.}

\leavevmode\vadjust pre{\hypertarget{ref-palotti_benchmark_2019}{}}%
\CSLLeftMargin{158. }%
\CSLRightInline{Palotti, J. \emph{et al.} Benchmark on a large cohort
for sleep-wake classification with machine learning techniques.
\emph{npj Digit. Med.} \textbf{2}, 1--9 (2019) URL:
\url{https://www.nature.com/articles/s41746-019-0126-9} Accessed 12 June
2023, 2023:2023.}

\end{CSLReferences}

\hypertarget{list-of-appendices}{%
\chapter{List of Appendices}\label{list-of-appendices}}

\begin{itemize}
\item
  \textbf{Appendix I}: Manual Annotation of Time in Bed Using
  Free-Living Recordings of Accelerometry Data
\item
  \textbf{Appendix II}: Generalizability and performance of methods to
  detect non‑wear with free‑living accelerometer recordings
\item
  \textbf{Appendix III}: Improving Sleep Quality Estimation in Children
  and Adolescents: A Comparative Study of Machine Learning and Deep
  Learning Techniques Utilizing Free-Living Accelerometer Data from
  Thigh-Worn Devices and EEG-Based Sleep Tracking
\item
  \textbf{Appendix IV}: Supplementary Material for Paper III
\end{itemize}

\newpage

\begin{center}

\textbf{\textsf{\Huge Appendix I}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix I}

\vspace{1cm}

\textsf{\Huge Manual Annotation of Time in Bed Using Free-Living Accelerometry Data}

\vspace{5cm}

This paper was published in \textbf{Sensors} and is used here under the terms and conditions of the Creative Commons Attribution (CC BY) license (\href{https://creativecommons.org/licenses/by/4.0/}{https://creativecommons.org/licenses/by/4.0/})

\vspace{1cm}

DOI: \href{https://doi.org/10.3390/s21248442}{https://doi.org/10.3390/s21248442}

\end{center}

\includepdf[pages=-]{my_papers/paper1.pdf}

\begin{center}

\textbf{\textsf{\Huge Appendix II}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix II}

\vspace{1cm}

\textsf{\Huge Generalizability and Performance of Methods to Detect Non-Wear With Free-Living Accelerometer Recordings}

\vspace{5cm}

This paper was published in \textbf{Scientific Reports} and is used here under the terms and conditions of the Creative Commons Attribution (CC BY) license (\href{https://creativecommons.org/licenses/by/4.0/}{https://creativecommons.org/licenses/by/4.0/})

\vspace{1cm}

DOI: \href{https://doi.org/10.1038/s41598-023-29666-x}{https://doi.org/10.1038/s41598-023-29666-x}

\end{center}

\includepdf[pages=-]{my_papers/paper2.pdf}

\begin{center}

\textbf{\textsf{\Huge Appendix III}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix III}

\vspace{1cm}

\textsf{\Huge Improving Sleep Quality Estimation in Children and Adolescents: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking}

\vspace{5cm}

This manuscript is under preparation for submission to \textbf{SLEEP}, the official journal of the Sleep Research Society (SRS).

\vspace{1cm}

DOI: \href{https://doi.org/10.1038/s41598-023-29666-x}{https://doi.org/10.1038/s41598-023-29666-x}

\end{center}

\includepdf[pages=-]{my_papers/paper3.pdf}

\begin{center}

\textbf{\textsf{\Huge Appendix IV}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix IV}

\vspace{1cm}

\textsf{\Huge Supplementary Material for Paper III}

\end{center}

\includepdf[pages=-]{paper3_supp.pdf}


\backmatter

\end{document}
