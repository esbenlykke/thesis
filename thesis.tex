% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  10pt,
]{scrbook}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[]{EB Garamond}
  \setsansfont[]{Montserrat}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=20mm,paperwidth=17cm,paperheight=24cm]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{caption}
\usepackage{longtable}
% Page setup and typography
 \usepackage[margin=20mm, paperwidth=17cm, paperheight=24cm]{geometry}
 \pagestyle{plain}
 \usepackage{sectsty}
 \usepackage{color}
 \definecolor{color1}{RGB}{80, 80, 80}
 \allsectionsfont{\sffamily \color{color1}}
 \usepackage{multicol}

 \let\originaltextbf\textbf
 \renewcommand{\textbf}[1]{\textcolor{color1}{\originaltextbf{#1}}}

 \let\originalbfseries\bfseries
 \renewcommand{\bfseries}{\originalbfseries\color{color1}}

 % Landscape handling
 \usepackage{lscape}
 \newcommand{\blandscape}{\begin{landscape}}
 \newcommand{\elandscape}{\end{landscape}}

 % Captions and listings
 \usepackage[font=small,labelfont=bf]{caption}
 \captionsetup{font=footnotesize}

 % Other utilities
 \usepackage{pdfpages}
 \usepackage{hyperref}
 \usepackage{afterpage}
 \usepackage[nottoc,numbib]{tocbibind}
 \newcommand{\aftertocpagenum}{
   \cleardoublepage
   \pagenumbering{arabic}
 }

 % Continuous numbering for figures/tables
 \usepackage{chngcntr}
 \counterwithout{figure}{chapter}
 \counterwithout{table}{chapter}
\makeatletter
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  colorlinks=true,
  linkcolor={DarkSlateBlue},
  filecolor={Maroon},
  citecolor={DarkSlateBlue},
  urlcolor={DarkRed},
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{}

\begin{document}
  \frontmatter
  
  
\pagenumbering{roman}

\includepdf[pages=-]{titlepage.pdf}

\newpage

\textcolor{color1}{\textsf{\textbf{\Large{Supervisor}}}}

\vspace*{\baselineskip}

Associate Professor Jan Christian Brønd, PhD

Research Unit for Exercise Epedimiology, Centre of Research in Childhood Health, Department of Sports Science and Clinical Biomechanics, University of Southern Denmark, Denmark

\vspace{2cm}

\textcolor{color1}{\textsf{\textbf{\Large{Assessment Committee}}}}

\vspace*{\baselineskip}

\textcolor{color1}{\textbf{Chair}}

Professor WSR Jasper Schiperijn, PhD

Research Unit of Active Living, Danish centre for motivation and behaviour science, Playground Research, Department of Sports Science and Clinical Biomechanics, University of Southern Denmark, 5230 Odense, Denmark

\bigskip

\textcolor{color1}{\textbf{Opponents}}

\begin{multicols}{2}

Associate Professor Samuel Emil Schmidt, PhD

Department of Health Science and Technology, \newline Aalborg University, Denmark

\columnbreak

Associate Professor Alex Rowlands, PhD

Biomedical Research Centre, \newline University of Leicester, United Kingdom

\end{multicols}

\vspace{2cm}

\textcolor{color1}{\textsf{\textbf{\Large{Funding}}}}

\vspace*{\baselineskip}

The research presented in this thesis was generously funded by TrygFonden, under grant numbers ID 130081 and 115606, and by the European Research Council, under grant number 716657. Additional support was provided by a one-year scholarship from the Faculty of Health Sciences, University of Southern Denmark.

\newpage

%----------------------------------------------
  %   Preface
%----------------------------------------------
  
\textcolor{color1}{\textsf{\textbf{\Large{Preface}}}}

\vspace*{\baselineskip}

The present thesis delves into the objective measurements of physical behavior and sleep, a subject that has captivated me since my Master's program. This work represents a fulfilling journey marked by exploration, discovery, struggles, and both personal and professional growth.

The thesis is based on data from several different studies and is the product of collaboration with numerous internal and external co-authors. It employs machine learning and advanced statistical methods on accelerometer data to bring new insights into the field of sleep and physical behavior.

This thesis comprises three distinct papers, each focusing on improving and validating methods for leveraging accelerometer data in the study of human behaviors—particularly sleep and physical activity. Each paper applies innovative methods, such as machine learning techniques, to enhance the utility, reliability, and accuracy of free-living accelerometer data in large-scale studies. Two of these papers have already been published in peer-reviewed journals, and the third is under preparation. These works are integral to this thesis and are included as appendices.

My research journey began during my Master's program, where I was introduced to the capabilities of accelerometer data. This early exposure culminated in the publication of my Master's thesis and solidified my desire to pursue a career in research. Embarking on my PhD, I faced a series of challenges. Initially, my limited experience with programming and machine learning posed a steep learning curve. However, persistent effort enabled me to acquire the necessary skills for data analysis. A significant hurdle arose during the data collection phase of my main paper. I attempted to collect overnight polysomnography data, along with readings from multiple accelerometers and wrist photoplethysmography, from 55 children in their homes. Regrettably, the sensitive nature of EEG electrodes did not mix well with children, resulting in data that was largely unsuitable for model development. Fortunately, I could turn to the SCREENS trial for alternative data, allowing me to complete the third paper.

The PhD experience has fundamentally shaped my approach to work and life, instilling in me qualities like discipline, precision, and a keen attention to detail. This journey has been as much about professional development as it has been a personal voyage of self-discovery and growth.

As I stand on the threshold of new beginnings, I am filled with excitement about the future possibilities. This thesis reflects the lessons and experiences gathered along the way and serves as a stepping stone for further exploration in this rapidly evolving field.

Enjoy reading.

\newpage

%----------------------------------------------
  %   Acknowledgement
%----------------------------------------------
  
\textcolor{color1}{\textsf{\textbf{\Large{Acknowledgment}}}}

\vspace*{\baselineskip}

As I reflect on the transformative journey that my PhD has been, I find myself indebted to numerous individuals whose support, guidance, and inspiration have been instrumental in shaping both my professional and personal growth.
First and foremost, I extend my deepest gratitude to my Main Supervisor, Jan Christian Brønd. Your unwavering guidance and patience have not only nurtured my development as a researcher but also as a lecturer. Our collaborative dialogues, whether they took place in the office or during examinations, have been a cornerstone in my academic development.
To my co-supervisors, Anders Grøntved and Niels Christian Møller, your expert insights and unique perspectives have enriched my work immeasurably. My gratitude also extends to my colleague Jesper Schmidt-Persson, whose contributions have consistently elevated the quality of my research.
Being part of an internationally recognized and experienced research group has been an enriching experience. It afforded me the privilege to work alongside some of the most brilliant minds in my field. This collective experience has not only broadened my understanding but also contributed significantly to our shared goal of advancing knowledge in our discipline.
At the core of this journey has been the unceasing support of my family. To my wife, who has been the bedrock of our family, your constant support and curiosity about my work have been my emotional mainstay. The joy and love I've received from our four children have been ceaseless fountains of inspiration and motivation.
This PhD journey has taught me more than just academic rigor; it has molded my approach to work and life in ways that are ineffably valuable. The discipline and precision inherent in research have permeated my daily life, influencing my problem-solving and decision-making processes. This endeavor has been much more than an academic pursuit; it has been a voyage of self-discovery.
Whether it was solving a complex analytical problem, having my work accepted for publication, or receiving positive feedback, such milestones have fueled my motivation and are poignant reminders of the impact and importance of my work.
In conclusion, I want to express my heartfelt gratitude to everyone who has supported me through this transformative period of my life—supervisors, colleagues, friends, and family. Your faith in my abilities and continuous encouragement have been the backbone of this journey, and I hope that the work presented in this thesis is a testament to that.

I am incredibly grateful for all the support and wisdom I have been fortunate to receive, and it is my earnest hope that this thesis stands as a tribute to each of you. Thank you.

\newpage

\textcolor{color1}{\textsf{\textbf{\Large{Included Papers}}}}

\vspace{2cm}

\begin{center}

Paper I

\textsf{Manual Annotation of Time in Bed Using Free-Living Recordings of Accelerometry Data}

published in \href{https://doi.org/10.3390/s21248442}{Sensors}

\vspace{2cm}
Paper II

\textsf{Generalizability and Performance of Methods to Detect Non–Wear with Free–Living Accelerometer Recordings}

published in \href{https://doi.org/10.1038/s41598-023-29666-x}{Scientific Reports}

\vspace{2cm}
Paper III 

\textsf{Improving Sleep Quality Estimation: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free–Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking}

In preparation for \href{https://academic.oup.com/sleep}{SLEEP}

\end{center}\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables
\mainmatter
\aftertocpagenum

\hypertarget{english-summary}{%
\chapter{English Summary}\label{english-summary}}

\textbf{Introduction:} Sleep is an important element in promoting
health, and the quantification of sleep has been improved with modern
technology. Polysomnography, considered the gold standard, provides
in-depth insight into sleep but is costly. In contrast, accelerometry is
a cheaper and less invasive method, especially for longer home-based
recordings. Machine learning is a tool that has the potential to
automate and facilitate the estimation of sleep from accelerometer data.
However, there are three challenges: producing reliable training data,
ensuring data integrity through accurate removal of non-wear, and
effectively using data to estimate sleep. Firstly, it is necessary to
have sufficient and accurate annotations in the data for effective
machine learning, emphasizing the importance of methods for manual
annotations based on accelerometer data. Secondly, it is essential to
detect and remove periods when the device is not worn to perform
accurate analyses. Identifying periods of non-wear is challenging, as
traditional methods like logbooks can be prone to bias. Existing
algorithms removes bias, but their accuracy is still debated. Finally,
once data is correctly collected and processed, it is crucial to apply
it effectively. Current methods for estimating sleep using
accelerometers are based on data from wrist-worn and hip-worn devices,
while data from thigh-worn accelerometers remains largely untapped for
sleep estimation.

\textbf{Aims:} This thesis has the following objectives. Firstly, we
will assess the accuracy of manual annotation of bedtime in raw
accelerometer data compared to EEG-based bedtime and sleep diaries.
Secondly, we will assess heuristic algorithms and machine learning
models for detecting non-wear. Finally, we will develop machine learning
models for sleep classification and the estimation of sleep quality
metrics using data from thigh-worn accelerometers and compare them with
EEG-based sleep recordings. Overall, this thesis aims to understand the
potential and challenges of using machine learning to estimate sleep via
accelerometry.

\textbf{Methods:} The data for the papers included in this thesis are
sourced from the SCREENS pilot trial (paper I), the PHASAR study, and an
internal validation study (paper II), as well as the SCREENS trial
(paper III). Accelerometer data, sleep recordings, and diaries of
bedtimes are used from the SCREENS experiments, while PHASAR and the
internal validation study provide accelerometer data. All accelerometer
data were collected using Axivity AX3 triaxial accelerometers, and sleep
was recorded using the EEG-based Zmachine® Insight+ system.

For paper I, accelerometer data from the hip and thigh of 14 children
and 19 adults were used. Using Audacity, an open-source audio editing
program, three raters annotated each accelerometer recording by marking
the times when the person went to bed and when they got out of bed. Two
rounds of annotations were performed to test reliability. The manual
annotations were evaluated against both sleep log and EG-based sleep
recordings. Concordance and agreement was evaluated using the intraclass
correlation coefficient and Bland-Altman analyses.

Paper II used accelerometer data from sensors placed on the wrist,
thigh, and hip. In data from 64 PHASAR participants and 42 participants
in an internal validation study, periods of non-wear were manually
annotated in the same way as described in paper I. Three variants of
decision trees were trained on 79.2\% data from the hip and thigh and
were evaluated against a selection of heuristic algorithms and recently
developed machine learning models. The remaining data were used for
testing purposes for all included algorithms and models. Decision tree
hyperparameters were optimized through five-fold cross-validation.
External validation was performed on wrist data from all 42 participants
from the internal validation study. All included algorithms and models
were evaluated using metrics derived from confusion matrices.

For paper III, accelerometry and EEG-based sleep recordings from
children aged 4-17 years were used. The predicted sleep stage classes
from the EEG-based sleep recording were reduced to ``awake'' and
``sleep'', as information about sleep stages is not relevant for
generating the sleep quality metrics of interest for this thesis. Data
preprocessing included a low-pass Butterworth filter, removal of periods
non-wear using the method described paper II, and a set of 64 predictors
were constructed. Sleep recordings were median filtered in 5 and
10-minute windows before models were trained to better capture true
awakenings. Two model strategies were used, a sequential approach with
four types of binary classification models, and the other strategy used
a multi-class model. Data for the four pairs of sequential models were
divided into training and test sets, and hyperparameter optimization was
performed using ten-fold Monte Carlo cross-validation. An imbalance in
training data was addressed using the synthetic minority oversampling
technique. Data for training the multi-class model was split in a ratio
of 50/25/25 for training, validation, and testing. For both strategies,
the F1 score was used as an optimization target. To evaluate the
performance of all models, metrics derived from confusion matrices were
used, and to understand the effectiveness of our models in estimating
sleep quality measures, Bland-Altman plots and Pearson correlations were
used. The following sleep quality measures were evaluated: sleep period
time, total sleep time, sleep efficiency, latency until persistent
sleep, and wake after sleep onset.

\textbf{Results:} In paper 1, we compared manual annotations of three
expert raters of in-bed timestamps with EEG-based and sleep diary in-bed
timestamps. The results indicated excellent inter- and intra-rater
agreement. Furthermore, the Bland--Altman limits of agreement were
approximately ±30 min, showcasing only a minimal mean bias of manual
annotation compared to EEG-based and sleep diary in-bed timestamps.

In paper 2, our focus was on non-wear detection. For non-wear periods
longer than 60 minutes, the established consecutive zeros algorithms
were the most effective, registering F1-scores above 0.96. However, for
durations shorter than 60 minutes, decision trees stood out, achieving
F1-scores of over 0.74 across all sensor locations. Notably, the newly
developed deep learning and random forests models couldn't match these
performances.

Paper 3 examined sleep classification and the estimation of sleep
quality metrics using thigh-worn accelerometers. Here, the XGBoost model
excelled, especially when analyzing 5-minute filtered data. The model
demonstrated only small discrepancies in several sleep quality metrics:
sleep period time (0.2 minutes), total sleep time (-7.0 minutes), sleep
efficiency (-1.1\%), and wake after sleep onset (-0.9 minutes).
Additionally, this model exhibited a moderate correlation of 0.66 with
total sleep time. It's worth noting that the limits of agreement in our
findings mirrored those in previous studies on hip and wrist devices.
Specifically, total sleep time exhibited LoAs of (95\%CI): -95.5 (-105.2
to -88) minutes to 81.4 (72.4 to 92.5) minutes.

\textbf{Conclusions:} Overall, the findings of this thesis underscore
the reliability and precision of emerging technological methods in sleep
and non-wear detection research. Paper 1 validated the credibility of
manual annotation techniques, reinforcing their alignment with
traditional benchmarks. Paper 2 emphasized the nuances of non-wear
detection, revealing clear strengths in certain algorithms for specific
durations and highlighting areas where newer models need enhancement.
Paper 3 highlights the XGBoost model for sleep assessment with
thigh-worn accelerometers, situating it as a valid alternative compared
to methods employed on thigh and wrist accelerometer data.
However,challenges remain in identifying in-bed awake periods and in
assessing sleep quality metrics on an individual-basis, consistent with
previous findings from wrist and hip-worn devices.

\hypertarget{dansk-resume}{%
\chapter{Dansk Resume}\label{dansk-resume}}

\textbf{Introduktion:} Søvn er et vigtigt element i sundhedsfremme og
kvantificeringen af søvn er blevet forbedret med moderne teknologi.
Polysomnografi betragtes som guldstandarden, og giver en dybdegående
indsigt i søvn, men er omkostningsfuld. Omvendt er accelerometri en
billigere og mindre invasiv metode, især til længere optagelser i
hjemmet. Maskinlæring er et værktøj, der har potentialet til at
automatisere og lette arbejdet med at estimere søvn fra
accelerometridata. Dog er der tre udfordringer: at producere pålidelig
træningsdata, sikre integriteten af data og effektivt bruge data til at
estimere søvn. For det første er det nødvendigt at have tilstrækkeligt
med nøjagtige annotationer i data for effektiv maskinlæring, hvilket
understreger vigtigheden af metoder til manuelle annotationer baseret på
accelerometridata. For det andet, for at udføre korrekte analyser, er
det essentielt at detektere og fjerne perioder, hvor sensoren ikke er
båret. Det kan være udfordrende at identificere perioder, hvor sensorene
ikke bæres, da traditionelle metoder som logbøger kan være
fejlbehæftede. Eksisterende algoritmer kan forbedre denne detektering,
men deres nøjagtighed er stadig genstand for debat. Endelig, når data er
blevet korrekt indsamlet og bearbejdet, er det afgørende at anvende det
effektivt. Nuværende metoder til at estimere søvn ved brug accelerometre
er baseret på data fra håndleds- og hoftebårne sensorer, mens data fra
accelerometre, der bæres på låret, stort set er uudnyttede i forhold til
at estimere søvn.

\textbf{Formål:} Denne afhandling har følgende formål. For det første
vurderes præcisionen af manuel annotation af sengetider i
accelerometridata sammenlignet med EEG-baserede sengetider og
søvndagbøger. For det andet undersøges eksisternede og nye algoritmer og
maskinlæringsmodeller til at detektere perioder, hvor accelerometeret
ikke er båret. Endeligt udvikles maskinelæringsmodeller til
søvnklassifikation og estimering af søvnkvalitetsmål ved brug af data
fra accelerometre, der bæres på låret og sammenligner med EEG-baserede
søvnoptagelser. Samlet set søger denne afhandling at forstå potentialet
og udfordringerne ved at anvende maskinlæring til at estimere søvn via
accelerometri.

\textbf{Metoder:} Data til artiklerne i denne afhandling stammer fra
SCREENS piloteksperimentet (artikel I), PHASAR-studiet og en intern
valideringsundersøgelse (artikel II) samt SCREENS-eksperimentet (artikel
III). Fra SCREENS-eksperiemterne gøres brug af accelerometerdata,
søvnoptagelser og dagbøger over sengetider, mens PHASAR og det interne
valideringsstudie leverer accelerometerdata. Al accelerometerdata blev
indsamlet ved hjælp af Axivity AX3 triaksiale accelerometre, og søvnen
blev registreret ved hjælp af det EEG-baserede Zmachine®
Insight+-system.

Til artikel I benyttedes accelerometerdata fra hofte og lår fra 14 børn
og 19 voksne. Ved hjælp af Audacity, et open-source
lydredigeringsprogram, annoterede tre bedømmere hver
accelerometeroptagelserne ved at markere tidspunkter for, hvornår
personen gik i sengen, og hvornår de stod ud af sengen. Der blev udført
to runder med annotationer for at teste pålideligheden. `Ground truth'
baseredes på EEG-søvnoptagelserne. Overensstemmelse blev målt ved hjælp
af intraklassekorrelationskoefficienten og Bland-Altman-analyser.

Artikel II anvendte accelerometerdata fra sensorer placeret på
håndleddet, låret og hoften. I data fra 64 PHASAR-deltagere og 42
deltagere i den interne valideringsundersøgelse annoteredes manuelt
perioder hvor sensorerne ikke blev båret på samme måde som metoden
beskrevet i artikel I. Tre varianter af decision trees blev trænet på
79,2\% data fra hofte og lår og det resterende data blev brugt til test.
Hyperparametre blev optimeret gennem en fem-foldig krydsvalidering.
Ekstern validering blev udført på håndledsdata fra alle 42 deltagere fra
den interne valideringsundersøgelse. Alle inkluderede algoritmer og
modeller blev evalueret ved hjælp af mål afledt af confusion matricer.

Til artikel III benyttedes accelerometri og EEG-baserede søvnoptagelser
fra børn i alderen 4-17 år. Prædiktionsklasserne fra søvnoptagelsen blev
reduceret til ``vågen'' og ``sove'', da information om søvnstadier ikke
er relevant for generere søvnkvalitetsmål af interesse for denne
afhandling. Dataforarbejdningen omfattede et lowpass Butterworth-filter,
fjernelse af perioder, hvor sensorerne ikke blev båret via metode fra
artikel II og et sæt på 64 prædiktorer blev konstrueret.
Søvnoptagelserne blev medianfiltreret i 5 og 10 minutters vinduer inden
modellerne blev trænet, for at fange sande opvågninger bedre. To
model-strategier blev anvendt, en sekventiel tilgang med fire typer af
binære klassifikationsmodeller og den anden strategi anvendte en
multiklasse model. Data til de fire par sekventielle modeller blev delt
op i trænings- og testsæt og hyperparameteroptimering blev udført ved
hjælp af ti-fold Monte Carlo krydsvalidering. En ubalance i træningsdata
blev løst ved hjælp af synthetic minority oversampling technique. Data
til træning af multiklasse-modellen blev opdelt i et forhold på 50/25/25
for træning, validering og test. For begge strategier blev F1 score
anvendt som optimeringsmål. For at vurdere præstationen på alle modeller
blev der anvendt mål afledt af confusion matricer og for at forstå
effektiviteten af vores modeller til at estimere søvnkvalitetsmål blev
Bland-Altman-plots og Pearson-korrelationer anvendt. Følgende
søvnkvalitetsmål blev evalueret: tid i sengen, total sovetid,
søvneffektivitet, tid til første søvn og vågentid efter første søvn.

\textbf{Resultater:} I den første artikel sammenlignes manuelle
annotationer med ZM og søvndagbøger. Resultaterne viste fremragende
enighed både mellem bedømmere og inden for samme bedømmer. Derudover var
Bland-Altman limits of agreement cirka ±30 minutter samtidig med en
minimal gennemsnitsbias.

I artikel II undersøges detekteringen af perioder, hvor accelerometrene
ikke bliver båret. For perioder af denne type længere end 60 minutter
var de etablerede algoritmer, som på forskellig vis detekterer perioder
uden acceleration, de mest effektive og opnåede F1-score over 0,96.
Decision trees viste sig at præstere bedst på perioder kortere end 60
minutter og opnåede en F1-score på over 0,74 på tværs af alle
sensorplaceringer. De nyligt udviklede deep learning- og random
forest-modeller kunne ikke matche disse resultater.

Den tredje og sidste artikel beskæftiger sig med søvnklassifikation og
søvnkvalitetsmål ved hjælp af accelerometre, der var båret på låret. Her
udmærkede XGBoost-modellen sig, især når den analyserede data filtreret
i 5 minutter. Modellen viste små afvigelser i flere søvnkvalitetsmål:
tid i sengen (0,2 minutter), total sovetid (-7,0 minutter),
søvneffektivitet (-1,1\%) og vågen efter først søvn (-0,9 minutter).
Derudover viste denne model en moderat korrelation på 0,66 med total
søvntid. Det er værd at bemærke, at limits of agreements i vores
resultater var sammenlignelige med tidligere studier på hofte- og
håndledssensorer. Specifikt viste total søvntid limits of agreements på
-95,5 minutter til 81,4 minutter.

\textbf{Konklusion:} Samlet set undersøger denne afhandling
pålideligheden og præcisionen af metoder inden for bearbejdning af
accelerometerdata og søvndetektering. Artikel I understreger at manuel
annotatering stemmer overens med EEG-baserede og selvrapporterede
sengetider. Artikel II fremhævede nuancerne ved detektering af perioder,
hvor sensorerne ikke bæres og viste at visse metoder præsterer bedst for
specifikke varigheder af perioderne. Artikel III fremhæver
XGBoost-modellen som bedst til at klassificere søvn på data fra
accelerometre på låret og viser sammenligelige resultater i forhold til
metoder, der anvender maskinlæringsmodeller på data fra hofter og
håndled. Dog er der stadig udfordringer med at identificere perioder,
hvor man er vågen i sengen. Derudover understreger limits of agreements
udfordringer i forhold til at vurdere individuelle søvnkvalitetsmål,
hvilket er i tråd med tidligere fund fra sensorer, der bæres på
håndleddet og hoften.

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\hypertarget{why-track-sleep-in-health-research}{%
\section{Why Track Sleep in Health
Research}\label{why-track-sleep-in-health-research}}

Physical behaviors throughout a day encompass a range of activities,
including sleep, physical activity, and sedentary behavior. A plethora
of research over the past decade has strongly emphasized the health
benefits of optimal sleep, high pysical activity levels, especially
moderate-to-vigorous physical
activity\textsuperscript{\protect\hyperlink{ref-kraus_physical_2019}{1},\protect\hyperlink{ref-lee_effect_2012}{2}},
minimal sedentary
periods\textsuperscript{\protect\hyperlink{ref-wilmot_sedentary_2012}{3}},
and adequate sleep across all age
groups\textsuperscript{\protect\hyperlink{ref-cappuccio_sleep_2010}{4},\protect\hyperlink{ref-jennum_suxf8vn_sundhed_2015}{5}}.
These findings have informed public health
guidelines,\textsuperscript{\protect\hyperlink{ref-kl_physical_2018}{6}--\protect\hyperlink{ref-el-zine_fysisk_nodate}{8}}
as well as recommendations on sleep
duration\textsuperscript{\protect\hyperlink{ref-hirshkowitz_2015}{9}}.
The integration of sleep tracking in health research is increasingly
crucial for a comprehensive understanding of individual well-being.
Sleep and physical activity are instrumental in influencing a broad
spectrum of health aspects, ranging from mental
health\textsuperscript{\protect\hyperlink{ref-biddle_physical_2011}{10}}
to physical
fitness\textsuperscript{\protect\hyperlink{ref-warburton_health_2017}{11}},
and even extending to disease
prevention\textsuperscript{\protect\hyperlink{ref-strath_guide_2013}{12},\protect\hyperlink{ref-arem_leisure_2015}{13}}.
With advancements in wearable technology and tracking systems, we now
have tools that enable in-depth investigations into the complex
interplay between sleep, physical activity, and general
health\textsuperscript{\protect\hyperlink{ref-rollo_whole_2020}{14}}.
Given the established significance of sleep and physical activity in
health, underscored by extensive research and public health guidelines,
integrating sleep tracking into broader health research becomes
essential. Modern wearable technologies now grant us the ability to
deeply investigate the relationship between sleep, physical activity,
and overall health. Thus, a thorough study of sleep is crucial for a
holistic grasp of a healthy life.

We spend approximately one-third of our lives asleep, yet much about
this state of consciousness remains elusive, including its biological
function and what defines its
quality\textsuperscript{\protect\hyperlink{ref-ma_sleep_2017}{15}}.
However, what is clear is the essential role of adequate sleep in
maintaining both physical and psychological well-being, consolidating
memories, and regulating
emotions\textsuperscript{\protect\hyperlink{ref-worley_2018}{16}--\protect\hyperlink{ref-scott_2021}{18}}.
On the flip side, insufficient sleep has been linked to a range of
negative health outcomes such as weight gain, obesity, heart disease,
stroke, impaired immune function, and even an elevated risk of
death\textsuperscript{\protect\hyperlink{ref-consensus_conference_panel_recommended_2015}{19}--\protect\hyperlink{ref-hale_2020}{21}}.
The impact of sleep deprivation is felt not just in the long term but
also immediately. Short-term consequences include reduced alertness,
heightened stress levels, diminished concentration, delayed reaction
times, and a propensity for risk-taking
behavior\textsuperscript{\protect\hyperlink{ref-shochat_2014}{22}--\protect\hyperlink{ref-bonnet_1985}{25}}.
When poor sleep becomes a chronic issue, it can severely affect one's
quality of life. For example, daytime sleepiness increases the risk of
accidents in occupational settings and while driving, as well as
negatively impacts academic and work performance, with broader social
and economic repercussions like school dropouts or job
loss\textsuperscript{\protect\hyperlink{ref-connor_2002}{26}--\protect\hyperlink{ref-roth_1996}{28}}.
The concern over daytime sleepiness becomes particularly acute given
that it is widespread, affecting around 10-20\% of
society\textsuperscript{\protect\hyperlink{ref-wang_2019}{29}}. Various
factors contribute to this, ranging from lifestyle choices like
irregular bedtime and shift work to medical conditions that affect the
central nervous system and certain
medications\textsuperscript{\protect\hyperlink{ref-roth_1996}{28}}.

\hypertarget{determinants-of-sleep-in-relation-to-health}{%
\section{Determinants of Sleep in Relation to
Health}\label{determinants-of-sleep-in-relation-to-health}}

Sleep is complex, defined by its structure, length, quality, and when it
occurs during a day. Growing research indicates that disrupted sleep can
harm health, elevating the risk of issues like obesity and
diabetes\textsuperscript{\protect\hyperlink{ref-reutrakul_2018}{30}},
heart-related
diseases\textsuperscript{\protect\hyperlink{ref-cappuccio_sleep_2010}{4}},
and mental health
challenges\textsuperscript{\protect\hyperlink{ref-jouxe3o_2018}{31}}.

Human sleep consists of two primary phases: non-REM (Rapid Eye Movement)
and REM sleep. Typically, healthy adults begin their sleep in the
non-REM phase, which is further broken down into three stages. As
individuals transition from one stage to the next, their sleep
deepens\textsuperscript{\protect\hyperlink{ref-roebuck_2014}{32}}. The
most regenerative sleep stage, slow-wave sleep or deep sleep, takes
place during the third stage of non-REM sleep and usually occurs early
at night. On the other hand, REM sleep is marked by heightened brain
activity, and its durations extend as the night
progresses\textsuperscript{\protect\hyperlink{ref-roebuck_2014}{32}}.
Throughout the night, these sleep stages cycle, usually rotating four to
six times in intervals of roughly 90-120
minutes\textsuperscript{\protect\hyperlink{ref-roebuck_2014}{32}}.
Research into disrupted sleep, such as sleep interrupted by alarms, has
shown that hindering slow-wave sleep, even without altering total sleep
time, can lead to decreased insulin sensitivity, diminished glucose
tolerance, elevated sympathetic activity, and higher morning cortisol
levels\textsuperscript{\protect\hyperlink{ref-stamatakis_2010}{33},\protect\hyperlink{ref-herzog_2013}{34}}.

Epidemiological and experimental studies have convincingly shown a link
between sleep duration and health effects. Cross-sectional studies
indicate a ``U''-shaped relationship, where both shorter sleep durations
(typically less than 6 hours) and longer durations (typically more than
8 hours) correlate with heightened risks of obesity, mental health
disorders, coronary heart disease, stroke, and
diabetes\textsuperscript{\protect\hyperlink{ref-cappuccio_sleep_2010}{4},\protect\hyperlink{ref-reutrakul_2018}{30},\protect\hyperlink{ref-jouxe3o_2018}{31},\protect\hyperlink{ref-cappuccio_2011}{35},\protect\hyperlink{ref-cappuccio_2008}{36}}.
In controlled experiments, depriving healthy adults of sleep negatively
impacted their endocrine functions and triggered adverse metabolic and
inflammatory
reactions\textsuperscript{\protect\hyperlink{ref-banks_2007}{37},\protect\hyperlink{ref-vancauter_2008}{38}}.
Besides total sleep time (TST), sleep quality is primarily determined by
factors like sleep onset latency also referred to as latency until
persistent sleep (SOL or LPS; the time needed to fall asleep), wake
after sleep onset (WASO; the awake duration after initially falling
asleep), sleep efficiency (SE; a comparison of total sleep time to total
time spent in bed), and the number of times one wakes up during the
night\textsuperscript{\protect\hyperlink{ref-buysse_2014}{39}}. Studies
have indicated that subpar sleep quality is linked to a higher risk of
chronic illnesses in adults, including obesity, diabetes, and
cardiovascular
disease\textsuperscript{\protect\hyperlink{ref-basnet_2016}{40}}.

\hypertarget{the-gold-standard-for-measuring-sleep}{%
\section{The Gold Standard for Measuring
Sleep}\label{the-gold-standard-for-measuring-sleep}}

The challenge of studying sleep has become significantly more manageable
due to advancements in technology and our understanding of neuroscience.
It wasn't until the 1950s that sleep study became scientifically
feasible, thanks to the pioneering work of Nathaniel Kleitman and Eugene
Aserinsky\textsuperscript{\protect\hyperlink{ref-aserinsky_1953}{41}},
who demonstrated the brain's active involvement in sleep. Utilizing
electroencephalography (EEG), Kleitman and Aserinsky were able to
measure brain activity and identified that it synchronizes over multiple
regions, predominantly within specific frequency bands. This
groundbreaking discovery enabled them to define distinct ``sleep
stages'' that the brain cycles through, fundamentally transforming the
way sleep is measured and understood. A visual example of these sleep
stage cycles can be seen in Figure~\ref{fig-hypno}. Therefore, measuring
sleep, given its complexities, not only is critical but also possible
thanks to these technological and scientific milestones.

In a relaxed wakeful state, the EEG predominantly displays alpha
activity within the frequency band of 8-10 Hz and amplitudes usually
ranging from 10-50 μV. As an individual begins to fall asleep, they
enter the non-rapid eye movement (NREM) sleep stage 1 (N1). During this
drowsy phase, the brain's EEG activity transitions to the theta range
frequencies of 4-6 Hz. Simultaneously, muscle relaxation is evident,
respiratory rates decelerate, and there's a drop in both distal body
temperature and heart rate. This initial stage is followed by NREM sleep
stage 2 (N2), where the EEG spectra frequencies are further reduced.
This stage introduces sleep spindles---periodic high-frequency waves
oscillating between 12-14 Hz lasting for 0.5-1.5 seconds---and
K-complexes, which are characteristic reactive EEG elements of N2 sleep.

Progressing deeper into sleep, one enters NREM sleep stage 3 (N3), often
termed ``deep sleep''. Here, the EEG mainly exhibits high-amplitude
oscillations within the delta band of 1-4 Hz. Following these NREM
stages, the sleep cycle culminates in REM sleep. Interestingly, the EEG
patterns during REM sleep closely resemble the alpha activity seen in
wakeful states. This stage is marked by evident rhythmic eye movements,
while the respiration and heart rate display enhanced amplitudes and
variability. The brain stem suppresses most voluntary body movements at
this time, making it a period of relative physical inactivity. Dreaming
tends to be more frequent during REM sleep. A single REM episode can
span a few minutes and tends to extend in duration during the latter
part of the night. On average, an entire sleep cycle, from N1 to REM,
spans 90-110 minutes and is typically repeated multiple times throughout
the night.

\begin{figure}

{\centering \includegraphics{figures/hypnogram.pdf}

}

\caption{\label{fig-hypno}Sample hypnogram showing the sleep stage
cycles of an eight-hour polysomnography recording. The sleep stages
(REM, NREM 1-3) and arousals are shown.}

\end{figure}

Polysomnography (PSG) is a gold-standard technique in sleep research,
allowing simultaneous assessment of various physiological signals
influenced during
sleep\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{42}}. PSG
gathers electrophysiological data from the brain using a 6-channel EEG,
specifically from locations F3, F4, C3, C4, O1, and O2, contrasted
against the contralateral mastoids (M1, M2). In addition, it uses
electrooculography (EOG) to assess eye movements, electromyography (EMG)
to track chin muscle tone and occasional arm and leg movements, and
electrocardiography (ECG) to monitor heart rate. The study is augmented
by methods to assess respiratory airflow, respiratory effort indicators,
as well as peripheral pulse oximetry
(PPG)\textsuperscript{\protect\hyperlink{ref-ibuxe1uxf1ez_2018}{43}}.
For enhanced data interpretation, an infrared-equipped video camera
captures the sleeping subject. Typically, PSG is carried out overnight
in a specialized clinical sleep laboratory, assisting in diagnosing
various sleep disorders. This technique provides detailed insights into
an individual's sleep architecture, revealing sleep and wake durations
as well as aiding in the classification of sleep
stages\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{42}}. Sleep,
as per standard PSG scoring, is classified into four distinct stages:
three stages of non-REM (NREM) sleep and one stage of rapid-eye-movement
(REM) sleep\textsuperscript{\protect\hyperlink{ref-roebuck_2014}{32}}.
Such detailed data enables accurate clinical research and the diagnosis
of various sleep disorders, such as sleep apnea and periodic movements
during sleep\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{42}}.
While PSG offers an unparalleled depth of sleep data, essential for
diagnosing an array of sleep disorders, it comes with its own set of
limitations. The procedure can be costly, often restricted to one or two
nights in a specialized setting under a technician's supervision. This
controlled environment may not truly mirror free-living sleep
conditions\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{42}}.
Moreover, PSG necessitates specialized personnel to oversee, score, and
interpret the data, making it less feasible for expansive or free-living
studies\textsuperscript{\protect\hyperlink{ref-girschik_validation_2012}{44}}
and also introducing inter and intra-rater differences in scoring the
PSG data\textsuperscript{\protect\hyperlink{ref-levendowski_2017}{45}}.
Hence, while invaluable, PSG is predominantly reserved for individuals
presenting sleep-related complaints and for the conclusive diagnosis of
sleep disorders.

\hypertarget{the-zmachine-insight}{%
\section{The Zmachine® Insight+}\label{the-zmachine-insight}}

Automated EEG data scoring presents a cost-effective alternative that
mitigates the subjectivity tied to manual scoring by
technicians\textsuperscript{\protect\hyperlink{ref-redline_2013}{46}}.
While there has been an uptick in technological advancements recently,
substantial progress is still needed to create objective, dependable,
and valid methods to determine sleep
metrics\textsuperscript{\protect\hyperlink{ref-berthomier_2013}{47}}.
From the relatively few studies on automated scoring algorithms, some
have shown encouraging outcomes. For instance, Malhotra et
al.\textsuperscript{\protect\hyperlink{ref-malhotra_2013}{48}} explored
an automated system, comparing its PSG data scoring with visual
evaluations done by PSG professionals. They found that their
computer-based method yielded outcomes comparable to those of seasoned
technologists. Yet, this algorithm relies on several physiological data
channels, including EEG, chin EMG, and electrooculography. In the past
decade, single-channel EEG-based sleep staging algorithms have started
to gain attention among researchers who have proposed a variety of
potential scoring methods that are compared against traditional visual
scoring\textsuperscript{\protect\hyperlink{ref-koley_2012}{49}--\protect\hyperlink{ref-zhu_2014}{51}}.

The Zmachine® Insight+ (ZM) emerges as an important asset in sleep
studies. With positive validation against
PSG\textsuperscript{\protect\hyperlink{ref-kaplan_performance_2014}{52},\protect\hyperlink{ref-wang_evaluation_2015}{53}},
the ZM delivers data on par with this gold standard, but without the
hefty expenses or the demand for specialized oversight typical of PSG.
Notably, the ZM's
user-friendliness\textsuperscript{\protect\hyperlink{ref-pedersen_self-administered_2021}{54}}
allows for multi-night evaluations in real-world settings, capturing
genuine sleep pattern fluctuations. This offers an edge over one-night
PSG studies, making it an ideal primary data source for machine learning
analyses. This is because it offers several nights of data without
inconsistencies from different raters. However, despite its advantages,
the ZM, much like the PSG, still has considerable costs and demands on
participants. This underscores the importance of more convenient and
cost-effective options like accelerometers.

\hypertarget{sleep-questionnaires-and-diaries}{%
\section{Sleep Questionnaires and
Diaries}\label{sleep-questionnaires-and-diaries}}

Sleep has often been assessed using a sleep questionnaire in
larger-scale studies. These are cost-effective and quick, making them
suitable for first-line diagnosis. They quantify a patient's subjective
perception of their sleep quality. While these questionnaires are
inherently subjective, they've been validated as accurate in numerous
studies\textsuperscript{\protect\hyperlink{ref-silva_2011}{55}--\protect\hyperlink{ref-pataka_2014}{59}}.
Typically, medical professionals are not needed to administer these
questionnaires; they can be self-completed, even at home. For example,
several apps exist that instantly provides a report after questionnaire
completion, assisting those with potential sleep issues to seek
specialist care. It's vital to understand that not all questionnaires
measure the same aspect of sleep. While some assess sleep quality,
others like the FOSQ-10 evaluate
sleepiness\textsuperscript{\protect\hyperlink{ref-chasens_2009}{60}}
whereas instruments like the Pittsburgh Sleep Quality Index offers
insights into an individual's overall satisfaction with their sleep over
a defined time-frame, often a
month\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{42}}. In
population studies, self-report sleep assessments are common but flawed.
They can overestimate sleep duration and miss subtle sleep quality
details. Their design, summarizing sleep data over weeks, risks recall
biases, especially when remembering older sleep
patterns\textsuperscript{\protect\hyperlink{ref-sadeh_2015}{42}}.
Factors like weight, ethnicity, and regular sleep duration can influence
these self-reports'
accuracy\textsuperscript{\protect\hyperlink{ref-lauderdale_2008}{61}}.

Stepping away from these broad self-reports, sleep diaries stand out as
a more detailed and structured tool. Often framed as the ``gold
standard'' in subjective sleep assessment, they dive deep into various
sleep parameters, like total sleep duration, efficiency, onset latency,
and wake periods post sleep onset. Their strength lies in offering a
day-by-day account, making it easier to spot disturbances, ascertain
precise sleep timings, and decipher the rhythm of daily sleep-wake
patterns over an extended
duration\textsuperscript{\protect\hyperlink{ref-ibuxe1uxf1ez_2018}{43}}.
However, like all tools, they aren't perfect. Their accuracy hinges on
participants' memory retention and commitment to regular, detailed diary
entries. From the researchers' standpoint, sifting through these
extensive diaries can be time-intensive and, for participants, the
process can sometimes be seen as taxing, potentially affecting their
consistency in logging
entries\textsuperscript{\protect\hyperlink{ref-thurman_2018}{62}}.

\hypertarget{accelerometry-for-assessing-sleep}{%
\section{Accelerometry for Assessing
Sleep}\label{accelerometry-for-assessing-sleep}}

To address the limitations of EEG-based systems and sleep diaries,
accelerometers have emerged as a valuable alternative. Generally, an
accelerometer is an electronic device that measures both static and
dynamic acceleration forces. Static forces, arising from gravitational
pull, let devices determine orientation, like a smartphone's landscape
or portrait mode. Dynamic forces, resulting from movement or vibrations,
are utilized in activities such as step-counting in fitness trackers or
detecting collisions in vehicle airbag systems. Through technologies
like piezoelectric and MEMS (microelectromechanical systems),
accelerometers measure acceleration across various axes, serving diverse
applications from aerospace to consumer electronics. Essentially, they
are crucial sensors relaying motion or position changes to electronic
systems.

While sleep researchers refer to these as ``actigraphy devices'', those
in physical activity studies call them ``accelerometers.'' Both terms
denote devices employing accelerometer sensors to detect motion. For
physical activity measurement and physical activity type distinction,
devices are often placed on the hip or
thigh\textsuperscript{\protect\hyperlink{ref-migueles_accelerometer_2017}{63}--\protect\hyperlink{ref-arvidsson_re-examination_2019}{67}},
mainly detecting vertical acceleration associated with walking or
running. This stemmed from early studies using uni-axial accelerometers
that sensed movement in one direction. Devices for sleep, however, are
usually wrist-worn. Omnidirectional accelerometers can sense movement in
multiple directions, giving a composite signal, whereas triaxial
accelerometers, with three orthogonal units, measure acceleration in
three planes\textsuperscript{\protect\hyperlink{ref-chen_2005}{68}}.
These tools offer objective insights into sleep patterns in free-living
settings over consecutive
nights\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{69}}.
Their affordability and non-intrusive nature make them more appealing
than PSG systems for population studies. However, many studies focus
exclusively on sleep or activity, leading participants to wear the
device either during the day for activity or at night for sleep. This
can result in inaccuracies, like not wearing the device immediately upon
waking or removing it before
sleep\textsuperscript{\protect\hyperlink{ref-meredith-jones_2016}{70}}.
To improve consistency, guidelines recommend 24-hour device
wear\textsuperscript{\protect\hyperlink{ref-tudor-locke_2012}{71}}.

Over the last 30 years, several research studies have highlighted the
dependability and accuracy of actigraphy as an alternative to PSG for
determining nocturnal sleep-wake
patterns\textsuperscript{\protect\hyperlink{ref-sadeh_activity-based_1994}{72}--\protect\hyperlink{ref-granovsky_actigraphy-based_2018}{79}}.
The findings from these investigations indicate a consistent
epoch-by-epoch concordance of 80 to 95\% between accelerometer-based
sleep-wake scoring methods and the conventional PSG-based scoring. Due
to this high degree of accuracy, the inclusion of actigraphy devices has
become a standard in sleep medicine protocols for diagnosing various
sleep disorders\textsuperscript{\protect\hyperlink{ref-smith_2018}{80}}.

Actigraphy employs algorithms to distinguish sleep from wake states,
using movement as an indicator of wakefulness. Though these algorithms
vary depending on factors like device brand and placement, they share a
common principle: they categorize each epoch based on surrounding
activity levels. Early actigraphy devices, due to technical constraints,
converted raw acceleration data into activity counts for
storage\textsuperscript{\protect\hyperlink{ref-neishabouri_2022}{81}}.
The first of such algorithms emerged in 1982, validated against
PSG\textsuperscript{\protect\hyperlink{ref-webster_activity-based_1982}{82}}.
Its successor, the Cole-Kripke algorithm, became widely accepted by
1992\textsuperscript{\protect\hyperlink{ref-cole_automatic_1992}{73}}.
These algorithms typically analyzed activity count-based features around
a specific time frame and utilized linear or logistic regression for
binary sleep-wake
predictions\textsuperscript{\protect\hyperlink{ref-sazonov_activity-based_2004}{78}}.
In response to technological evolution and research demands,
manufacturers began offering raw acceleration data from actigraphy
devices. This shift allowed the creation of sleep algorithms rooted
directly in raw acceleration rather than aggregated activity counts. A
notable development in this area was by van Hees et al.~(2015), who
utilized raw data to calculate the forearm's angle, subsequently
establishing a sleep-wake classification method based on the angle's
variations over
time\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{83}} and
more presently an algorithm developed for data collected from thigh-worn
devices that relies on a constantly changing variable called `sleep
index' that is affected by
movement\textsuperscript{\protect\hyperlink{ref-johansson_development_2023}{84}}.
The widespread use of accelerometer devices has produced a wealth of
data. However, traditional interpretation methods might not tap into the
full potential of this data. This makes a shift towards machine learning
methods increasingly crucial, as they offer advanced tools for analyzing
these vast datasets.

\hypertarget{machine-learning-and-its-use-with-accelerometry}{%
\section{Machine Learning and Its Use With
Accelerometry}\label{machine-learning-and-its-use-with-accelerometry}}

Machine learning, a subfield of artificial intelligence, focuses on the
development of algorithms that enable computers to learn from and make
predictions or decisions based on
data\textsuperscript{\protect\hyperlink{ref-hastie01statisticallearning}{85}}.
Rather than being explicitly programmed to perform a task, these
algorithms use statistical techniques to learn patterns from
data\textsuperscript{\protect\hyperlink{ref-bishop_2006}{86}}. This
capability to learn from experience allows machines to improve their
performance over time, adapting to new information without human
intervention. At the heart of machine learning is the concept of
training. Given a set of data known as the training dataset, an
algorithm iteratively makes predictions and adjusts itself based on any
errors it makes. Over time, the algorithm becomes more adept at its
task, be it recognizing images, understanding spoken language,
forecasting sales, or detecting sleep in accelerometry data. Deep
learning, an advanced branch of machine learning, utilizes neural
networks with multiple layers---hence the term ``deep''---to discern
complex patterns within datasets. Notably, architectures such as
convolutional neural networks (CNNs) and recurrent neural networks
(RNNs) stand out in deep learning. CNNs excel at identifying spatial
hierarchies and localized patterns in data, while RNNs capture temporal
or sequential dependencies. These capabilities enable deep learning
models to analyze a vast array of data types with precision and
nuance\textsuperscript{\protect\hyperlink{ref-Goodfellow-et-al-2016}{87}}.

There are various types of machine learning and deep learning, including
supervised learning, unsupervised learning, and reinforcement learning.
In supervised learning, the training data includes both the input and
the desired output. The model is ``supervised'' as it learns from this
data until it can accurately predict outcomes for new, unseen data.
Unsupervised learning, on the other hand, involves training the model on
data without labeled responses, with the goal of discovering hidden
patterns in the data. Reinforcement learning is a paradigm where the
model learns by interacting with an environment and receiving feedback
in the form of rewards or
penalties\textsuperscript{\protect\hyperlink{ref-sutton_1998}{88}}. In
this thesis, the focus will be on supervised learning for all tasks
regarding detection of behaviors in accelerometry data.

There exists a plethora of algorithms tailored for various supervised
learning tasks ranging from simple linear regressions to complex deep
learning models. While each algorithm has its unique strengths, their
collective objective is to extract patterns from data, facilitating
accurate predictions and insights. Linear Regression is a foundational
algorithm, aimed at predicting a continuous outcome variable based on
one or more predictor variables. The relationship between the variables
is considered
linear\textsuperscript{\protect\hyperlink{ref-kutner_2005}{89}}. Support
Vector Machines are supervised models designed for classification and
regression. By finding the optimal hyperplane, Support Vector Machines
are adept at dividing datasets into distinct
classes\textsuperscript{\protect\hyperlink{ref-cortes_1995}{90}}.
K-Means Clustering, an unsupervised algorithm, aims to segment data into
clusters based on
similarity\textsuperscript{\protect\hyperlink{ref-macqueen_1967}{91}}.
Although there exists an almost endless number of learning algorithms,
in this thesis, all developed models are based on the following
algorithms:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Logistic Regression}: Contrary to its name, logistic
  regression is used for binary classification rather than regression.
  It predicts the probability of an instance belonging to a particular
  category. The outcome is transformed using the logistic function,
  ensuring it lies between 0 and 1, making it interpretable as a
  probability\textsuperscript{\protect\hyperlink{ref-McCullagh_1989}{92}}.
\item
  \textbf{Decision Trees}: Decision trees offer a graphical
  representation of possible outcomes to a decision, making them easily
  interpretable. By segmenting the dataset based on feature values, they
  can handle both categorical and numerical data. They are employed in
  diverse areas, including medical diagnosis and credit risk
  analysis\textsuperscript{\protect\hyperlink{ref-quinlan_1986}{93}}.
\item
  \textbf{Multilayer Perceptron}: Often termed a single-layer,
  feed-forward neural network, multilayer perceptrons consist of at
  least three layers: an input layer, a hidden layer, and an output
  layer. They can model complex relationships by adjusting weights
  between nodes during training. Activation functions, like the sigmoid
  or ReLU, introduce non-linearity into the
  model\textsuperscript{\protect\hyperlink{ref-Goodfellow-et-al-2016}{87}}.
\item
  \textbf{XGBoost}: An optimized gradient boosting machine learning
  library, XGBoost is renowned for its performance and speed. It works
  by sequentially adding weak learners (typically decision trees) and
  correcting errors from previous stages, resulting in a strong
  prediction model. The algorithm has been a dominant force in various
  Kaggle competitions and is favored for structured or tabular
  data\textsuperscript{\protect\hyperlink{ref-Chen_xgboost_2016}{94}}
\item
  \textbf{Bidirectional LSTM (Long Short-Term Memory)}: LSTM networks, a
  type of Recurrent Neural Network (RNN), are designed to remember
  patterns over long sequences and are particularly effective for
  time-series and NLP tasks. The bidirectional variant processes the
  sequence data from both past-to-future and future-to-past directions,
  enhancing the context information available to the
  network\textsuperscript{\protect\hyperlink{ref-graves_2005}{95}}.
\end{enumerate}

Machine learning and its advanced subset, deep learning, have
revolutionized numerous sectors, from healthcare and finance to
entertainment and technology. At the core of these advancements lies
data, often termed as the new ``oil'' (a term coined by Clive Humby,
2006) of the digital era. The efficacy and accuracy of machine learning
models are inherently tied to the volume, variety, and quality of the
data they are trained on. The rationale behind this reliance on data is
twofold. Firstly, machine learning algorithms, by design, identify
patterns and relationships within data. The richer and more diverse the
dataset, the better these algorithms can generalize and make accurate
predictions on new, unseen data. Sparse or limited data can lead to
overfitting, where the model becomes overly specialized to the training
data and performs poorly in real-world applications. Secondly,
especially deep learning models, which often employ multi-layered neural
networks, have a vast number of parameters. To train these parameters
effectively and avoid overfitting, a substantial volume of data is
necessary. It's akin to fitting pixels in an image together---the more
pixels (or data) you have, the clearer the overall picture (or pattern)
becomes. It's worth noting, however, that the sheer volume isn't the
only concern. The quality, relevance, and diversity of data play equally
crucial roles. High-quality datasets that encompass a broad spectrum of
scenarios and edge cases ensure that machine learning and deep learning
models are robust, versatile, and reliable in diverse applications.

The availability of large datasets from wearable devices have set the
stage for the incorporation of machine learning techniques into research
using accelerometry. These algorithms have the capability to analyze
vast and complex data sets, delivering insights that were previously
difficult or impossible to discern. Whether it's recognizing subtle
patterns indicative of sleep apnea for timely
intervention\textsuperscript{\protect\hyperlink{ref-cappuccio_sleep_2010}{4}},
or evaluating the effectiveness of antidepressant medications in
patients with sleep
disturbances\textsuperscript{\protect\hyperlink{ref-paruthi_consensus_2016}{96}},
machine learning adds a layer of precision and depth to data analysis.
Machine learning and deep learning methodologies have been effectively
applied to sleep
research\textsuperscript{\protect\hyperlink{ref-tilmanne_2009}{75},\protect\hyperlink{ref-granovsky_actigraphy-based_2018}{79},\protect\hyperlink{ref-palotti_benchmark_2019}{97},\protect\hyperlink{ref-sundararajan_sleep_2021}{98}}
to identify and categorize sleep and sleep stages. For instance,
Tilmanne et
al.\textsuperscript{\protect\hyperlink{ref-tilmanne_2009}{75}} explored
the application of Multilayer Perceptrons and Decision Trees in
sleep-wake scoring algorithms. They found these techniques to surpass
the accuracy of algorithms by Sazonov and
Sadeh\textsuperscript{\protect\hyperlink{ref-sadeh_activity-based_1994}{72},\protect\hyperlink{ref-sazonov_activity-based_2004}{78}}.
In another study, Granovsky et
al.\textsuperscript{\protect\hyperlink{ref-granovsky_actigraphy-based_2018}{79}}
utilized a Convolutional Neural Networks to classify sleep-wake patterns
utilizing actigraphy data from 35 patients with chronic cluster
headaches with strong precision and recall scores. While the results
from Granovsky et al.~are encouraging, their assessment diverges from
other related studies, as it wasn't benchmarked against PSG, making it
less detailed. Moreover, deep learning models showed enhanced precision
over traditional models in the MESA sleep
dataset\textsuperscript{\protect\hyperlink{ref-palotti_benchmark_2019}{97},\protect\hyperlink{ref-lutsey_objectively_2015}{99}}
and the algorithm developed by van Hees et al.~in
2015\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{83}} has
since been improved in accuracy with a random forest model that
outperformed both its predecessor and established algorithms like
Cole-Kripke and
Sadeh\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{98}}.
Despite these advancements, several challenges persist in the trajectory
of creating machine learning models tailored for sleep detection which
will be outlined in the following sections.

\hypertarget{importance-of-accurate-data-annotation}{%
\section{Importance of Accurate Data
Annotation}\label{importance-of-accurate-data-annotation}}

The complexity of a machine learning model is closely tied to the number
of parameters it must learn. As the number of features a model considers
increases, there's a proportional demand for more data. For instance, in
predicting housing prices where a model evaluates variables such as
location, number of bedrooms, and the neighborhood, a diverse dataset is
important to understand the influence of each
variable\textsuperscript{\protect\hyperlink{ref-hastie01statisticallearning}{85}}.
While basic algorithms can often produce satisfactory outcomes with
relatively limited data, more intricate algorithms, especially those
within the deep learning spectrum, have a heightened data requirement.
One of the standout attributes of deep learning, in contrast to
traditional machine learning, is its ability to draw insights directly
from raw data without the need for manual feature engineering. This
capability necessitates a richer and more diverse dataset for optimal
model
performance\textsuperscript{\protect\hyperlink{ref-Goodfellow-et-al-2016}{87}}.
Data volume also depends on the task's complexity and the acceptable
error margins for the application. A weather prediction model might
tolerate a 20\% error, but medical diagnostics require near-perfect
accuracy. Lastly, the unpredictability or diversity of input can
significantly influence data needs. Take, for instance, an online
virtual assistant. Given that users can pose a myriad of queries in
various styles and with occasional grammatical errors, the underlying
model must be trained on a broad dataset to handle this range of
unpredictability\textsuperscript{\protect\hyperlink{ref-Goodfellow-et-al-2016}{87}}.

The complexities and nuances associated with data requirements in
machine learning underscore the importance of not only having the right
volume and diversity of data but also ensuring its quality and
precision\textsuperscript{\protect\hyperlink{ref-Goodfellow-et-al-2016}{87}}.
One of the pivotal aspects ensuring this precision, particularly in
supervised learning scenarios, is data labeling. It means marking data
with specific tags, guiding models to learn and predict. These labels,
which are typically manually added by experts, help the models identify
patterns. They can indicate things like categories, feelings, or any
task-specific information. The better the annotation, the better the
model performs, so thorough annotations is essential. Yet, the manual
annotation process, especially by experts, can be complex. Simple
visualization might not always offer a comprehensive understanding,
potentially leading to inaccurate labels. With the vast data volumes at
play, this procedure is not just lengthy but could also be error-prone,
especially for lengthy annotation tasks. Inherent limitations in the
precision of manual labeling mean that any missteps can profoundly skew
results.

In the context of machine learning models tailored for sleep detection
in multi-day accelerometry recordings, accurately annotating bedtimes
and wake-up moments is essential. While one might consider sourcing
annotations from sleep diaries or EEG recordings, many studies have not
integrated these within their study design, leading to an information
gap which can be circumvented via manually annotating targets of
importance. Moreover, many current methods aimed at detecting sleep
don't effectively capture the `in-bed' time also termed the sleep period
time. An exception is the HDCZA algorithm by Van Hees et
al.\textsuperscript{\protect\hyperlink{ref-van_hees_estimating_2018}{100}}.
The question then becomes whether manual annotations of `in-bed' times
in accelerometry data can serve as a reliable alternative to sleep
diaries or EEG recordings. If they can, this would offer a means to
enrich a vast amount of existing data that currently lacks associated
sleep logs or other `in-bed' time indicators, making it more suitable
for machine learning tasks. However, as of now, there's no research
showcasing the effectiveness and precision of such manual annotations.

\hypertarget{integrity-of-accelerometry-data}{%
\section{Integrity of Accelerometry
Data}\label{integrity-of-accelerometry-data}}

Data integrity is a cornerstone of any credible research or analytic
endeavor. This is especially true for the world of accelerometry, where
data accuracy and completeness are important for understanding human
motion and behavior. In the context of accelerometry, devices are
commonly mounted using tape, elastic belts, or other secure mechanisms.
However, as mundane as this step might sound, its significance cannot be
overstated. Proper mounting ensures consistent data capture, while
flawed or insecure attachments can introduce erroneous readings.
Moreover, there's the potential of a device being unintentionally
flipped or reattached to an incorrect wearsite after a non-wear period,
further complicating the data quality. These seemingly minor missteps
can lead to substantial data inaccuracies, casting doubts on the ensuing
analyses and findings.

As outlined in previous sections, accelerometry-based activity monitors
have proven their worth by providing objective data on movement
intensity in a cost-effective manner while minimizing participant
burden\textsuperscript{\protect\hyperlink{ref-dowd_systematic_2018}{101}--\protect\hyperlink{ref-migueles_comparability_2019}{104}}.
However, challenges emerge when considering non-wear time, the intervals
during which devices aren't worn due to activities like swimming,
sleeping, certain sports, or sensor malfunctioning or other unforeseen
incidences. This non-wear time introduces what can be equated to
`missing data' in the dataset. Such missing data could be overlooked or
replaced using statistical imputations like zero-inflated Poisson and
Log-normal
distributions\textsuperscript{\protect\hyperlink{ref-lee_missing_2018}{105}}.
Yet, this process is not without its pitfalls, as imputation might
infuse biases rooted in data assumptions. The importance of an accurate
classification of non-wear time thus gains paramount significance,
ensuring the data quality remains pristine, especially in free-living
scenarios.

To circumvent this classification challenge, some research methods
require subjects to maintain a log diary of all non-wear periods, an
approach that is susceptible to errors and can be taxing on
participants\textsuperscript{\protect\hyperlink{ref-ainsworth_recommendations_2012}{106}}.
Seeking better accuracy, the scientific community turned to both
rule-based methods and more advanced algorithms. A notable early method
designed for ActiGraph counts data would identify non-wear time when
consecutive zero counts surpassed a certain
duration\textsuperscript{\protect\hyperlink{ref-hecht_methodology_2009}{107}--\protect\hyperlink{ref-troiano_how_2020}{109}}.
But even a minor tweak in this duration threshold could sway the results
by a notable
10\%\textsuperscript{\protect\hyperlink{ref-aadland_comparison_2018}{110}}.
The field also grappled with proprietary algorithms that not only lacked
transparency but also were affected by factors like age and obesity.
These variables subsequently hindered the comparability across multiple
studies\textsuperscript{\protect\hyperlink{ref-toftager_accelerometer_2013}{111}}.

But technology, being ever-evolving, introduced accelerometers capable
of storing raw acceleration data. This leap promised enhanced
granularity of data and a more precise non-wear period classification.
Algorithms soon popped up aiming to decode non-wear time from this raw
data, with some even harnessing skin temperature measurements for better
results\textsuperscript{\protect\hyperlink{ref-duncan_wear-time_2018}{112}--\protect\hyperlink{ref-zhou_classification_2015}{114}}.
These heuristic approaches are generalizable across various populations,
device brands, and wear-sites. In this setting, the term
``generalizability'' refers to how a model performs when applied to
unfamiliar datasets. High generalizability would suggest versatility
across varied settings and populations, whereas low generalizability
points to the contrary. The limitation of the heuristic duration-based
algorithms is that they may erroneously classify true non-wear as
inactivity due to their time-specific intervals, missing shorter
non-wear episodes. Furthermore, the volume and quality of the data
collected do not directly correspond to better performance. Contrary to
machine learning models that improves with increasing amounts of data.

With the progress in technology, machine learning methods such as random
forests\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{98}}
and deep
learning\textsuperscript{\protect\hyperlink{ref-syed_novel_2021}{115}}
entered the scene, aimed at classifying non-wear using raw accelerometer
data. However, these models must balance between variance and bias.
While high bias results in underfitting, high variance leads to
overfitting, where a model performs exceptionally on training data but
poorly with new data. These advanced machine learning models, even with
their robust performance on test data, are wrapped in uncertainty when
it comes to unseen, external data. External validation is a crucial
aspect, especially considering the universal aim of non-wear detection
methods. But often, this step is overlooked either due to limited
out-of-distribution data or the intent to harness all data for training.
Some studies have tried blending surface skin temperature with raw
acceleration data for non-wear
classification\textsuperscript{\protect\hyperlink{ref-zhou_classification_2015}{114}},
yet the broader implications of this combination using machine learning
are still unexplored. Despite these strides in technology and
methodology, the perfect classification of non-wear time in raw
accelerometer data remains elusive. The heart of the matter boils down
to pinpointing the optimal algorithm or model capable of best
classifying non-wear time on out-of-distribution data.

\hypertarget{limitations-of-current-ml-models-to-detect-sleep}{%
\section{Limitations of Current ML Models to Detect
Sleep}\label{limitations-of-current-ml-models-to-detect-sleep}}

Although machine learning and deep learning have been applied to
accelerometer data with the goal of predicting sleep for over a decade,
the field is still in its infancy. Primarily, most methods have been
tailored to integrate with data sourced from wrist- and hip-worn
devices\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{69}}.
The use of machine learning and deep learning on data collected via
devices mounted to the thigh remains unexplored despite the potential
advantages of this sensor location in estimating physical activity
behaviors\textsuperscript{\protect\hyperlink{ref-bruxf8nd_2020}{66}}.
Only a few studies have leveraged this sensor-location for heuristic
algorithms\textsuperscript{\protect\hyperlink{ref-winkler_identifying_2016}{119}}.
One must wonder how this skewed focus impacts the adaptability and
performance of these models in diverse real-world scenarios. For
example, specific sleep-related behaviors or positions might be better
captured by thigh-mounted devices compared to their wrist or hip
counterparts. Not leveraging this potential data source might lead to
overlooked nuances in sleep detection.

A significant hurdle in assessing sleep using accelerometer data is the
extraction of the sleep period time window without supplementary data
from sleep logs or
diaries\textsuperscript{\protect\hyperlink{ref-doherty_large_2017}{120}--\protect\hyperlink{ref-anderson_assessment_2014}{122}}.
This dependence on subjective sleep logs can introduce biases, and it
inherently assumes participants consistently record accurate and precise
timings. In reality, this can be a substantial point of failure,
especially in long-term studies or with certain demographics who might
be less consistent with logging such as children who often rely on their
parents reporting accurate bed times on their behalf. Typical approaches
that rely on traditional accelerometers often necessitate participants
to diligently log their bedtime, sleep initiation, and wake-up
moments\textsuperscript{\protect\hyperlink{ref-girschik_validation_2012}{44},\protect\hyperlink{ref-littner_2003}{77},\protect\hyperlink{ref-lockley_1999}{123}}.
This reliance is burdensome and can lead to incomplete or inaccurate
datasets, compromising the integrity and reliability of any derived
insights. Moreover, the data foundation used to develop these algorithms
often consists of single-night PSG-recordings, like the random forests
model by Sundarajan et
al.\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{98}}.
While this may provide a snapshot of a participant's sleep behavior, it
doesn't capture the night-to-night variability. Capturing
intra-individual variances in sleep across multiple nights could lead to
more robust and generalized models. Unfortunately, multiple nights of
PSG recording can be impractical due to the intrusive nature of PSG, its
cost, and the inconvenience for participants. Thus, alternative systems
like the ZM could offer significant advantages, serving as a more
feasible and less intrusive alternative to traditional PSG.

\hypertarget{thesis-aim-and-objectives}{%
\section{Thesis Aim and Objectives}\label{thesis-aim-and-objectives}}

The rapidly growing field of wearable technology provides unprecedented
opportunities to collect accurate and objective data on human behavior,
particularly in the realm of free-living accelerometer recordings. This
thesis situates itself within this developing domain, with the ambition
of harnessing the potential of wearable accelerometer technology for
sleep estimation. At its core, the objective is to innovate methods and
models for the analysis and interpretation of sleep. Building on the
challenges delineated in earlier sections, this thesis endeavors to
advance the field through a series of papers, as detailed below.

The objectives of paper I is to present a method for manually annotating
individual bedtime and wake-up times using raw, unprocessed
accelerometry data. Furthermore, to validate the accuracy of these
annotations by comparing them with findings from a single-channel
EEG-based sleep staging system and a conventional sleep diary, and
lastly, to assess both inter-rater and intra-rater reliability of the
manual annotations.

Paper II lays down two primary objectives. Firstly, it seeks to evaluate
decision tree models utilizing data from both thigh and hip-worn
accelerometers to detect non-wear time in accelerometry data, also
including the role of surface skin temperature. Secondly, it draws a
comparison between machine-learned models and heuristic algorithms
across accelerometer datasets sourced from devices worn on both the hip,
thigh, and wrist.

In Paper III, the primary objective was to assess the performance of a
selection of machine learning and deep learning models in estimating
in-bed and sleep time, benchmarking all included methods against an
EEG-based sleep tracking monitor. Beyond this, the secondary objective
was to evaluate the ability of the developed models to quantify
essential sleep quality metrics, once again validated against an
EEG-based sleep tracking device.

\hypertarget{paper-i-manual-annotation-of-time-in-bed-using-free-living-recordings-of-accelerometry-data}{%
\chapter{Paper I: Manual Annotation of Time in Bed Using Free-Living
Recordings of Accelerometry
Data}\label{paper-i-manual-annotation-of-time-in-bed-using-free-living-recordings-of-accelerometry-data}}

This segment of the thesis encompasses the methods and results for Paper
I. The study underscores the importance of effective machine learning
algorithms for sleep/wake cycles, which ideally necessitate correct data
annotations over a span of 7-10 days. Although sleep diaries or EEG
recordings can annotate `time in bed', many researches exclusively rely
on accelerometry. This emphasizes the imperative for valid annotation
techniques. Our objective is to introduce a manual annotation method,
assess its precision, and determine its consistency. Some of the details
presented here were previously mentioned in the published version of
Paper
I\textsuperscript{\protect\hyperlink{ref-skovgaard_manual_2021}{124}}.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{study-population}{%
\subsection{Study Population}\label{study-population}}

The data for this study was sourced from the SCREENS pilot trial
(www.clinicaltrials.gov, NCT03788525), a two-arm parallel-group
cluster-randomized trial with two intervention groups, conducted between
October 2018 and March
2019\textsuperscript{\protect\hyperlink{ref-rasmussen_short-term_2020}{113},\protect\hyperlink{ref-rasmussen_feasibility_2021}{125}}.
There was no control group in this trial.

Families from the Middelfart municipality in Denmark were approached for
participation if they had a child aged between 6 to 10 years living with
them, out of a total of 1686 families. To qualify, the parent's screen
media usage had to exceed the median of 2.7 hours per day, based on
survey responses from 394 respondents. Additionally, all children in the
household needed to be older than 3.9 years to ensure that sleep
measurements weren't disrupted by the nocturnal awakenings typical of
infants or toddlers. For a comprehensive list of inclusion and exclusion
criteria, refer to Pedersen et
al.\textsuperscript{\protect\hyperlink{ref-pedersen_self-administered_2021}{54}}.

The present study ultimately included data from 14 children and 19
adults. These participants weren't advised to alter their sleep or
bedtime routines for the interventions. While the study focused on
nightly sleep time as recorded by the EEG-based sleep staging system,
any napping behavior of the participants was deemed irrelevant.

All data collection procedures were reported to the local data
protection department, SDU RIO (ID: 10.391), in compliance with the
Danish Data Protection Agency's regulations.

\hypertarget{accelerometry-recordings}{%
\subsection{Accelerometry Recordings}\label{accelerometry-recordings}}

Both adults and children participated in 24-hour accelerometry
recordings using two triaxial accelerometers, Axivity AX3 (Axivity Ltd.,
Newcastle upon Tyne, UK). The Axivity AX3 is a compact device, measuring
23 mm × 32.5 mm × 7.6 mm and weighing just 11 g. It was set with a
sensitivity of ±8 g and a sampling frequency of 50 Hz. Participants wore
the accelerometers at two specific anatomical locations. The first was
positioned on the right hip, secured in a pocket attached to a belt
around the waist, ensuring the USB connector faced outward from the
body's right side. The second accelerometer was placed midway between
the hip and knee on the right thigh, housed in a pocket on a belt, with
the USB connector also facing away from the body. For both the baseline
and follow-up, the devices were worn for a duration of one week (seven
consecutive days). This duration aligns with the recommended number of
days to reliably assess habitual physical
activity\textsuperscript{\protect\hyperlink{ref-jaeschke_variability_2018}{126}}.

\hypertarget{eeg-based-and-self-report-sleep-recordings}{%
\subsection{EEG-based and Self-Report Sleep
Recordings}\label{eeg-based-and-self-report-sleep-recordings}}

Both adults and children were assessed for their sleep patterns using
the ZM model DT-200 (General Sleep Corporation, Cleveland, OH, USA),
Firmware version 5.1.0. This assessment was concurrent with the
accelerometer recordings. At the baseline, the sleep assessment using
the ZM spanned 3--4 nights, while during the follow-up, it was conducted
over 3 nights.

The ZM device operates by measuring sleep through a single-channel EEG,
specifically from the differential mastoid (A1--A2) EEG location,
evaluated on a 30-second epoch basis. Designed for use in everyday
settings, the ZM provides an objective measurement of various sleep
parameters, including sleep duration, sleep stage classification, and
latency to different sleep stages. The ZM's algorithm has been
benchmarked against PSG in laboratory settings for both adults with and
without chronic sleep
issues\textsuperscript{\protect\hyperlink{ref-kaplan_performance_2014}{52},\protect\hyperlink{ref-wang_evaluation_2015}{53}}.
Our findings indicate that the ZM is effectively applicable to both
children and adults for multi-day measurements in real-world
settings\textsuperscript{\protect\hyperlink{ref-pedersen_self-administered_2021}{54}}.
Notably, the device showcased a high accuracy in distinguishing between
sleep and wakefulness, with sensitivity, specificity, positive
predictive value, and negative predictive values being 95.5\%, 92.5\%,
98\%, and 84.2\%,
respectively\textsuperscript{\protect\hyperlink{ref-kaplan_performance_2014}{52}}.

For the assessment, three electrodes (Ambu A/S, Ballerup, Denmark, type:
N-00-S/25) are positioned on the mastoids (for signal) and the nape (as
ground). About half an hour before their intended sleep time,
participants' skin areas are cleaned with alcohol swabs, after which the
electrodes are affixed. An EEG cable connects these electrodes to the ZM
device. A preliminary sensor check ensures all electrodes are correctly
mounted; any issues are promptly addressed by replacing the problematic
electrodes. Additionally, participants, or parents on behalf of their
children, recorded their sleep and wake times daily in a dedicated
diary.

\hypertarget{annotation-software}{%
\subsection{Annotation Software}\label{annotation-software}}

Audacity®️ is a distinguished free audio editing
software\textsuperscript{\protect\hyperlink{ref-audacity}{127}}. The
genesis of Audacity can be traced back to the fall of 1999, when it
emerged as an innovative project led by Dominic Mazzoni and Roger
Dannenberg at Carnegie Mellon University. By May 2000, it was unveiled
to the world as an open-source audio editor. Since its inception,
Audacity has undergone significant evolution. The software, developed
collaboratively by the community, now boasts of hundreds of unique
features, offers complete support for professional-grade 24-bit and
32-bit audio, has a comprehensive manual available in multiple
languages, and has witnessed distribution in the millions. Today, a
dedicated team of volunteers from various corners of the globe continues
to maintain and enhance Audacity. It is disseminated under the GNU
General Public License, granting everyone the freedom to utilize the
software for personal, educational, or commercial endeavors.

Audacity is not limited to audio processing; it can also serve as a tool
for accelerometer data analysis. This software provides researchers with
the means to precisely inspect high-resolution raw accelerometer data in
great detail. Users can quickly zoom in to explore deeper into specific
segments of the recording, like certain patterns around bedtime, or zoom
out for a broader perspective, such as data spanning a week.
Furthermore, Audacity's sophisticated labeling function is pivotal for
annotating the accelerometry data. Any labels created can be saved in a
separate file and subsequently incorporated into the training phase of
machine learning algorithms. The depth of manual inspection for
high-resolution accelerometer data that Audacity provides is, to our
knowledge, matched by only a few other software
options\textsuperscript{\protect\hyperlink{ref-visplore}{128},\protect\hyperlink{ref-label_studio}{129}}.

Within the Audacity interface, there's the possibility of amalgamating
over 100 channels of data. This aids in the merging of distinct signal
features derived from acceleration. The integration of multiple signal
features is intriguing as it might enhance the visual comprehension and
classification of inherent behaviors. Nevertheless, an excessive
conglomeration of signal features might obscure the precise
identification of targeted behaviors. For our study, we incorporated a
total of seven distinct signal features. The criteria for classifying
``lying'' in the first feature are explicit: if the inclination of the
hip accelerometer surpasses 65 degrees and the thigh accelerometer
simultaneously identifies as ``sitting'' based on Skotte et al.'s
activity type classification
algorithm\textsuperscript{\protect\hyperlink{ref-skotte_detection_2014}{65}}.
The other signal features, barring ``time'', are directly procured from
Skotte et al.'s algorithm. These features, delineated in
Table~\ref{tbl-man_signal_features}, concern the longitudinal axis of
the body. Data derived from accelerometry undergoes processing using a
window length of two seconds (60 samples) and has a 50\% overlap (30
samples), ensuring a resolution of one second. The methodologies from
Skotte et al.~and those generating the first feature rely exclusively on
the accelerometer's inclination(s). Hence, while they can determine time
in bed and participant's posture, they aren't precise indicators for
pinpointing exact in-bed and out-of-bed moments.

To provide a visual perspective, Figure~\ref{fig-screen_full} and
Figure~\ref{fig-screen_night} depict the Audacity interface displaying
all seven signal features as cataloged in
Table~\ref{tbl-man_signal_features}. Figure~\ref{fig-screen_full} offers
a glimpse of a week's data, whereas Figure~\ref{fig-screen_night} zooms
into an approximate 24-hour span, showcasing a single annotated night.

\begingroup

\footnotesize

\hypertarget{tbl-man_signal_features}{}
\begin{longtable}{lll}
\caption{\label{tbl-man_signal_features}Summary of the specific signal features utilized in Audacity for the
accurate detection and analysis of in-bed periods. }\tabularnewline

\toprule
Name & Description & Values \\ 
\midrule
Lying & Classification based on thigh and back & 1: lying, -1: not lying \\ 
Activity & Activity type classification & 1: Standing, moving, 0: Sitting, -1: Other \\ 
Time & Time categorized into four-hour windows & Time categorized throughout 24 h cycle \\ 
Thigh-SDacc & Thigh longitudinal acceleration SD & -1: No movement \\ 
Thigh-Inclination & Thigh device inclination angle & Range: −180 to 180 degrees \\ 
Hip-SDacc & Hip longitudinal acceleration SD & -1: No movement \\ 
Hip-Inclination & Hip device inclination angle & Range: −180 to 180 degrees \\ 
\bottomrule
\end{longtable}

\endgroup

\begin{figure}

{\centering \includegraphics{figures/audacity_full_view.png}

}

\caption{\label{fig-screen_full}Screenshot of the Audacity interface
showing the seven horizontal panels representing the included signal
features. See Table~\ref{tbl-man_signal_features} for a detailed
description of the features.}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/audacity_single_night.png}

}

\caption{\label{fig-screen_night}Screenshot of the Audacity interface
when zoomed in on a single night for the labeling of the in-bed period.
The seven horizontal panels represent the included signal features. See
Table~\ref{tbl-man_signal_features} for a detailed description of
features.}

\end{figure}

\hypertarget{annotation-process}{%
\subsection{Annotation Process}\label{annotation-process}}

Three experienced researchers, well-versed in working with accelerometer
data, were chosen as raters. Their proficiency ensured that they had the
requisite knowledge to accurately interpret the various data channels
presented to them. Each rater meticulously reviewed and labeled each
wav-file, marking specific timestamps that indicated in-bed and
out-of-bed activities. These annotations were then saved as individual
text files. For ensuring consistency and reliability in the annotations,
each wav-file underwent two rounds of labeling. Importantly, at no point
during this process were the raters privy to any prior annotations,
either made by themselves or their colleagues. This approach was adopted
to prevent any potential biases and ensure the highest degree of
objectivity in the annotations.

\hypertarget{establishing-the-ground-truth}{%
\subsection{Establishing the Ground
Truth}\label{establishing-the-ground-truth}}

The definitive ground truth for in-bed and out-of-bed time frames was
obtained from the sleep staging data derived from the ZM device. This
was established by identifying the first and last events at night that
did not present any sensor-related issues. Nights where the ZM detected
sensor problems, either at the onset or conclusion of the recording,
were excluded from further consideration. Such sensor issues typically
arise due to high impedance because of inadequate attachment of
electrodes. To maintain accuracy in data collection, all participants
were meticulously instructed to affix the ZM before bedtime and then
activate it precisely at their bedtime and to detach it upon waking.
These timestamps were then utilized as the ground truth for the study.

\hypertarget{statistics}{%
\subsection{Statistics}\label{statistics}}

For continuous variables, the descriptive characteristics were computed
using medians and interquartile ranges. Meanwhile, categorical variables
were assessed based on their proportions. To offer a clear distinction,
the characteristics for children and adults were presented separately.

Our statistical approach was geared towards discerning the degree of
agreement. To achieve this, we employed the intraclass correlation
coefficient (ICC) and the Bland--Altman analysis. Recognizing that human
raters were sampled from a broader population, we used a random-effects
model when assessing inter-rater reliability between different human
raters. Here, ICC(2,1) was chosen, reflecting the reliability of
individual rater's
ratings\textsuperscript{\protect\hyperlink{ref-shrout_1979}{130}}.
However, when comparing human raters against the ZM or sleep diaries, a
mixed-effects model was used. In this context, the human raters are
treated as random effects, while the ZM and sleep diaries are treated as
fixed effects. The corresponding ICC that represents this mixed model is
known as
ICC(3,k)\textsuperscript{\protect\hyperlink{ref-shrout_1979}{130}}. For
intra-rater reliability, where raters had repeated measurements, we
adopted ICC(3,1) to estimate the consistency of each individual rater's
ratings across
occasions\textsuperscript{\protect\hyperlink{ref-mcgraw_1996}{131}}. In
general, the ICC serves as a more nuanced tool than simple correlation;
it goes further by evaluating the alignment in magnitude between two
datasets, serving as a robust metric for consistency between
methodologies. The interpretation of ICC values were as follows:

\(ICC < 0.5\) indicates poor agreement

\(0.5 ≤ ICC < 0.75\) indicates moderate agreement

\(0.75 ≤ ICC < 0.9\) indicates good agreement

\(ICC ≥ 0.90\) indicates excellent agreement

In this research, the ICC values were interpreted based on their 95\%
confidence intervals, adhering to recommended
guidelines\textsuperscript{\protect\hyperlink{ref-koo_guideline_2016}{132}}.
The Bland--Altman analysis, on the other hand, is a tool to measure the
concurrence between two measuring
techniques\textsuperscript{\protect\hyperlink{ref-bland_measuring_1999}{133}}.
It calculates the average of the differences (representing bias) between
the two methods, and also establishes the limits of this agreement. A
positive mean difference suggests an earlier underestimation of the
in-bed or out-of-bed timestamp relative to the ZM, while a negative
difference indicates a later overestimation. To complement these metrics
and to offer a visual perspective on the congruence between the methods,
we incorporated probability density distribution plots. These plots
visualize the distribution of agreement and underscore the symmetry
between the methodologies. All statistical analyses for this study were
performed using the R statistical software (version 4.0.2, released on
22 June 2020) and RStudio (version 1.1.456).

\hypertarget{results}{%
\section{Results}\label{results}}

Descriptive characteristics of the included subjects of the current
study are reported in Table~\ref{tbl-man_describe}.

\begingroup

\footnotesize

\hypertarget{tbl-man_describe}{}
\begin{longtable}{ll}
\caption{\label{tbl-man_describe}Descriptive characteristics of the study participants. ISCE:
International Standard Classification of Education }\tabularnewline

\toprule
Characteristic &  \\ 
\midrule
\multicolumn{2}{l}{Children} \\ 
\midrule
N & 14 \\ 
Gender (\% female) & 28.6 \\ 
Age (years) & 9 (7–10) \\ 
\midrule
\multicolumn{2}{l}{Adults} \\ 
\midrule
N & 19 \\ 
Gender (\% female) & 57.9 \\ 
Age (years) & 42 (39–46) \\ 
ISCE &  \\ 
0–3 (\%) & 36.8 \\ 
4–6 (\%) & 47.4 \\ 
7–8 (\%) & 15.8 \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{intraclass-correlation-coefficient-analyses}{%
\subsection{Intraclass Correlation Coefficient
Analyses}\label{intraclass-correlation-coefficient-analyses}}

The Intraclass Correlation Coefficients (ICCs) analysis, as displayed in
Table 3, emphasized the remarkable agreement between ZM's automatic
annotations and the averaged manual annotations made by the three
raters. For the time to bed during Round 1 of the baseline assessment
(covering 94 nights), the ICC was 0.98, with a 95\% confidence interval
of (0.98; 0.99) indicating excellent agreement. Similar high agreement
was noted for time out of bed during the same round, with an ICC value
of 0.98. This level of agreement was sustained during the subsequent
Round 2 and the follow-up assessments (encompassing 54 nights), where
values like 0.95 (with a confidence interval of 0.92; 0.97) for time to
bed and 0.98 for time out of bed were observed. Reinforcing the strength
of these observations, the lower bounds of the 95\% confidence intervals
for all metrics consistently stayed above 0.9, underscoring a excellent
agreement in the recorded agreement (see
Table~\ref{tbl-man_icc_zm_man}).

\pagebreak

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_zm_man}{}
\begin{longtable}{lll}
\caption{\label{tbl-man_icc_zm_man}Intraclass correlation coefficients between ZM and the average of the
manual annotations between the three raters. }\tabularnewline

\toprule
 &  & ICC (95\% CI) \\ 
\midrule
\multicolumn{3}{l}{Baseline (n = 94 Nights)} \\ 
\midrule
To bed & Round 1 & 0.98 (0.98; 0.99) \\ 
To bed & Round 2 & 0.98 (0.96; 0.98) \\ 
Out of bed & Round 1 & 0.98 (0.97; 0.99) \\ 
Out of bed & Round 2 & 0.98 (0.96; 0.98) \\ 
\midrule
\multicolumn{3}{l}{Follow-Up (n = 54 Nights)} \\ 
\midrule
To bed & Round 1 & 0.96 (0.94; 0.98) \\ 
To bed & Round 2 & 0.95 (0.92; 0.97) \\ 
Out of bed & Round 1 & 0.98 (0.97; 0.99) \\ 
Out of bed & Round 2 & 0.97 (0.95; 0.98) \\ 
\bottomrule
\end{longtable}

\endgroup

A strong agreement between self-reports and ZM measurements was also
observed. For the baseline period (N=94), time to bed had an ICC of 0.98
with a 95\% CI of (0.98;0.99), while time out of bed posted an ICC of
0.98 and a CI of (0.97;0.99). The follow-up data (N=54) yielded similar
agreement: 0.96 ICC (CI: 0.94;0.98) for time to bed and 0.98 ICC (CI:
0.96;0.99) for time out of bed. Notably, the lower bound of the
confidence intervals never dropped below 0.94 (see
Table~\ref{tbl-man_icc_zm_self}).

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_zm_self}{}
\begin{longtable}{lll}
\caption{\label{tbl-man_icc_zm_self}Intraclass correlation coefficients between self-report and ZM. }\tabularnewline

\toprule
 & Baseline (N = 94) & Followup (N = 54) \\ 
\cmidrule(lr){2-2} \cmidrule(lr){3-3}
 & ICC (95\% CI) &  ICC (95\% CI) \\ 
\midrule
To bed & 0.98 (0.98; 0.99) & 0.96 (0.94; 0.98) \\ 
Out of bed & 0.98 (0.97; 0.99) & 0.98 (0.96; 0.99) \\ 
\bottomrule
\end{longtable}

\endgroup

Assessing the agreement among the three human raters when marking
timestamps for `to bed' and `out of bed' events, the ICC values reflect
excellent agreement between the raters across both rounds and
timepoints. Specifically, even the lower bounds of the 95\% confidence
intervals remained notably high, with the least value being 0.88. Yet, a
closer inspection reveals slight variations between annotations for `to
bed' versus `out of bed' (see Table~\ref{tbl-man_icc_man_man}).

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_man_man}{}
\begin{longtable}{lll}
\caption{\label{tbl-man_icc_man_man}Intraclass correlation coefficients between manual raters. }\tabularnewline

\toprule
 & Round & ICC (95\% CI) \\ 
\midrule
\multicolumn{3}{l}{Baseline} \\ 
\midrule
To bed & Round 1 & 0.91 (0.88; 0.94) \\ 
Out of bed & Round 1 & 0.93 (0.9; 0.95) \\ 
To bed & Round 2 & 0.92 (0.89; 0.94) \\ 
Out of bed & Round 2 & 0.97 (0.96; 0.98) \\ 
\midrule
\multicolumn{3}{l}{Follow-Up} \\ 
\midrule
To bed & Round 1 & 0.94 (0.9; 0.96) \\ 
Out of bed & Round 1 & 0.97 (0.96; 0.98) \\ 
To bed & Round 2 & 0.97 (0.95; 0.98) \\ 
Out of bed & Round 2 & 0.98 (0.98; 0.99) \\ 
\bottomrule
\end{longtable}

\endgroup

Across both rounds and all data points, each rater displayed strong
test-retest reliability, with ICCs suggesting good to excellent
consistency. This is bolstered by 95\% confidence intervals that always
maintain a lower limit above 0.86. Notably, while Raters 1 and 3
demonstrated a minor dip in their baseline to-bed consistency compared
to out-of-bed measures, Rater 2 had lower consistency on the follow-up
to-bed timestamp compared to out-of-bed (refer to
Table~\ref{tbl-man_icc_test_retest}).

\begingroup

\footnotesize

\hypertarget{tbl-man_icc_test_retest}{}
\begin{longtable}{lcccc}
\caption{\label{tbl-man_icc_test_retest}Test--retest intraclass correlation coefficients between the first and
second round of manual annotations. }\tabularnewline

\toprule
 & \multicolumn{2}{c}{Baseline (N = 110)} & \multicolumn{2}{c}{Followup (N = 62)} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
 & To Bed
ICC (CI 95\%) & Out of Bed
ICC (CI 95\%) & To Bed
ICC (CI 95\%) & Out of Bed
ICC (CI 95\%) \\ 
\midrule
Rater 1 & 0.91 (0.87; 0.94) & 0.98 (0.98; 0.99) & 0.96 (0.94; 0.98) & 1 (0.99; 1) \\ 
Rater 2 & 0.97 (0.96; 0.98) & 0.91 (0.87; 0.94) & 0.91 (0.86; 0.95) & 0.99 (0.98; 0.99) \\ 
Rater 3 & 0.91 (0.87; 0.94) & 0.96 (0.94; 0.97) & 0.98 (0.97; 0.99) & 0.98 (0.97; 0.99) \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{bland-altman-analyses}{%
\subsection{Bland-Altman Analyses}\label{bland-altman-analyses}}

Table~\ref{tbl-7} delineates the Bland--Altman analyses comparing both
manual annotation and self-report against the ZM system. The bias
observed for manual annotations vis-a-vis ZM fluctuates between -6
minutes to 5 minutes, suggesting a relatively narrow range of mean
differences across evaluations. Comparatively, the self-report's bias
against ZM is slightly more constrained. Remarkably, the range of the
limits of agreement remained consistent irrespective of the method being
contrasted with ZM. This uniformity in limits of agreement underscores
the good agreement of both manual annotations and self-reports when
compared with the ZM system.

\begingroup

\footnotesize

\hypertarget{tbl-7}{}
\begin{longtable}{lccc}
\caption{\label{tbl-7}Bland--Altman analysis was conducted to assess the inter-method
agreement. This analysis compared manual annotation to ZM and also
compared self-report to ZM. All the measurements in the analysis are
presented in minutes. }\tabularnewline

\toprule
Method & Bias & Lower\_LOA & Upper\_LOA \\ 
\midrule
\multicolumn{4}{l}{Baseline, to bed, n = 94} \\ 
\midrule
Manual, round 1 & 3.02 (-0.44; 6.47) & 36.07 (30.15; 42) & -30.04 (-35.96;-24.12) \\ 
Manual, round 2 & 0.48 (-2.42; 3.39) & 28.27 (23.29; 33.24) & -27.3 (-32.28;-22.32) \\ 
Self-report & 1.23 (-1.57; 4.03) & 28.02 (23.21; 32.82) & -25.56 (-30.37;-20.76) \\ 
\midrule
\multicolumn{4}{l}{Baseline, out of bed, n = 94} \\ 
\midrule
Manual, round 1 & 0.53 (-2.34; 3.4) & 27.96 (23.05; 32.88) & -26.9 (-31.82;-21.99) \\ 
Manual, round 2 & 0.98 (-1.47; 3.43) & 24.45 (20.24; 28.66) & -22.49 (-26.7;-18.28) \\ 
Self-report & -2.79 (-5.26; -0.32) & 20.87 (16.63; 25.11) & -26.45 (-30.69;-22.21) \\ 
\midrule
\multicolumn{4}{l}{Follow-up, to bed, n = 54} \\ 
\midrule
Manual, round 1 & -6.08 (-11.34; -0.83) & 31.64 (22.61; 40.67) & -43.81 (-52.84;-34.77) \\ 
Manual, round 2 & -0.4 (-5.3; 4.51) & 34.8 (26.37; 43.23) & -35.6 (-44.03;-27.17) \\ 
Self-report & 0.77 (-4.08; 5.62) & 35.59 (27.25; 43.93) & -34.06 (-42.4;-25.72) \\ 
\midrule
\multicolumn{4}{l}{Follow-up, out of bed, n = 54} \\ 
\midrule
Manual, round 1 & 4.95 (0.65; 9.25) & 35.85 (28.45; 43.25) & -25.95 (-33.35;-18.55) \\ 
Manual, round 2 & 2.57 (-0.76; 5.89) & 26.44 (20.72; 32.15) & -21.3 (-27.02;-15.59) \\ 
Self-report & 0.56 (-3.62; 4.74) & 30.57 (23.39; 37.76) & -29.45 (-36.64;-22.26) \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{density-plots}{%
\subsection{Density Plots}\label{density-plots}}

Figure~\ref{fig-ridge_plot} presents the probability density
distribution of the differences between the ``to-bed'' and
``out-of-bed'' timestamps, comparing manual annotations and self-reports
to the ZM. These plots offer a visual illustration of the bias and
spread around zero, showcasing how manual annotations and self-reports
diverge from ZM, as previously
highlighted\textsuperscript{\protect\hyperlink{ref-van_hees_estimating_2018}{100}}.

\begin{figure}

{\centering \includegraphics{figures/paper1_ridge_plot.pdf}

}

\caption{\label{fig-ridge_plot}Probability density distributions for
differences between manual in-bed annotations and self-report compared
to ZM.}

\end{figure}

\newpage

\hypertarget{paper-ii-generalizability-and-performance-of-methods-to-detect-non-wear-with-free-living-accelerometer-recordings}{%
\chapter{Paper II: Generalizability and Performance of Methods to Detect
Non-Wear With Free-Living Accelerometer
Recordings}\label{paper-ii-generalizability-and-performance-of-methods-to-detect-non-wear-with-free-living-accelerometer-recordings}}

This segment of the thesis encompasses the methods, results, and
discussion for Paper II. Wearable sensors, commonly used to track
physical activity, face challenges in detecting ``non-wear'' times.
While traditional methods use fixed interval heuristic algorithms, this
study explored decision trees that use raw acceleration and skin
temperature data. By training on thigh- and hip-worn devices from 64
children and validating with wrist-worn data from 42 adolescents,
results showed traditional methods excel for non-wear durations over 60
minutes. However, for durations below 60 minutes, decision tree models,
especially those with the top six predictors, were superior. The study
emphasizes method selection's significance and promotes external
validation for machine learning models in this area. Some of the details
presented here were previously mentioned in the published version of
Paper
I\textsuperscript{\protect\hyperlink{ref-skovgaard_generalizability_2023}{134}}.

\hypertarget{methods-1}{%
\section{Methods}\label{methods-1}}

The classification and generalizability of non-wear classification
methods were evaluated using free-living data collected from
accelerometers positioned on the wrist, thigh, and hip. This data
amalgamated findings from the Physical Activity in Schools After the
Reform
(PHASAR)\textsuperscript{\protect\hyperlink{ref-pedersen_protocol_2018}{135}}
study, which provided hip and thigh data, with an in-house validation
study that used wrist-worn accelerometers.
Figure~\ref{fig-paper2_flowchart} illustrates the data utilization
process. By leveraging these datasets, we ensured that established
non-wear classification methods underwent assessment on an external
dataset. Moreover, our decision tree models were tested on an
independent external dataset, including wear locations not initially
considered during model development. Therefore, all machine-learned
models underwent evaluation using test data from various anatomical
positions, regardless of their inclusion in the model's initial
development.

\hypertarget{reference-methods}{%
\subsection{Reference Methods}\label{reference-methods}}

To thoroughly evaluate and compare the performance of our three newly
developed algorithms, we incorporated four additional non-wear
classification methods. The selection of these existing methods was
grounded in our aim to span a broad range of methodological flexibility.
We specifically targeted techniques ranging from the most simplistic and
commonly used to the most recent and sophisticated.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textsf{\textbf{Consecutive Zeros-Algorithm (cz\_60):}} Over the
  years, there have been various consecutive zero-algorithms designed
  for accelerometer data, with the aim of identifying non-wear periods
  within stipulated timeframes, such as 30-, 60-, or 90-minute
  intervals\textsuperscript{\protect\hyperlink{ref-hecht_methodology_2009}{107},\protect\hyperlink{ref-troiano_physical_2008}{136},\protect\hyperlink{ref-choi_validation_2011}{137}}.
  In addition, van Hees and colleagues have developed non-wear
  algorithms for raw acceleration using a 30-minute
  interval\textsuperscript{\protect\hyperlink{ref-van_hees_estimation_2011}{138}}.
  They later expanded this approach to include a 60-minute
  interval\textsuperscript{\protect\hyperlink{ref-rasmussen_short-term_2020}{113}}.
  Another method utilizes a 135-minute interval with adjusted
  hyperparameters, as introduced by Syed et
  al.\textsuperscript{\protect\hyperlink{ref-syed_evaluating_2020}{139}}.
  In our study, we adopted a straightforward approach to this concept.
  Using Actigraphy counts, we identified periods of no movement that
  registered zero counts for at least 60 continuous minutes. Notably,
  these Actigraphy counts operate with a deadband set at 68 mg, which
  denotes the minimum detectable acceleration threshold.
\item
  \textsf{\textbf{Heuristic Algorithm (heu\_alg):}} As detailed by
  Rasmussen and
  colleagues\textsuperscript{\protect\hyperlink{ref-rasmussen_short-term_2020}{113}},
  this algorithm merges raw acceleration data with surface skin
  temperature measurements. Non-wear time is determined for periods
  surpassing 120 minutes with accelerations less than 20 mg. For
  durations between 45 to 120 minutes, non-wear is identified if the
  temperature falls below a personalized non-moving temperature
  threshold. Additionally, the algorithm can spot non-wear periods
  ranging from 10 to 45 minutes, but only if these intervals end within
  the anticipated awake hours.
\item
  \textsf{\textbf{Random Forests Model(sunda\_RF):}} Sundararajan et
  al.\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{98}}
  delineated a non-wear classification technique grounded in a random
  forest ensemble model. This model was informed by raw accelerometer
  data derived from 134 participants aged between 20 to 70 years. These
  subjects were fitted with an accelerometer on their wrist for a
  singular overnight PSG session. The verifiable labels for non-wear
  periods were anchored in the assumption that the accelerometer was
  donned only during the PSG. Any epoch with a standard deviation in the
  acceleration signal exceeding 13.0 mg outside the PSG was classified
  as wear time. The model utilized 36 predictors, and a nested
  cross-validation method was employed both to ascertain the model's
  generalization capability and to refine its hyperparameters.
\item
  \textsf{\textbf{Deep Convolutional Neural Network (syed\_CNN):}} This
  method, introduced by Syed et
  al.\textsuperscript{\protect\hyperlink{ref-syed_novel_2021}{115}},
  employs a unique approach. It's built upon a deep convolutional neural
  network (CNN) that diverges from traditional techniques. Initially,
  all potential non-wear episodes are discerned using a standard
  deviation threshold. However, instead of scrutinizing the acceleration
  within these intervals, the focus shifts to the signal shape of the
  raw acceleration immediately before and after a non-wear episode.
  Through the CNN, the method discerns non-wear periods by detecting the
  moments when the accelerometer is removed and reattached. For our
  study's purposes, we chose a window length of 10 seconds on each side
  of the identified non-wear episode, as this yielded the most accurate
  results. The training dataset that informed the CNN consisted of data
  from hip-mounted accelerometers worn by 583 participants. These
  individuals ranged in age from 40 to 84 years, with an average age of
  62.74 and a standard deviation of 10.25.
\end{enumerate}

\hypertarget{data-collection-and-devices-used}{%
\subsection{Data Collection and Devices
Used}\label{data-collection-and-devices-used}}

Both the PHASAR study and the in-house validation research utilized the
Axivity AX3 accelerometer (Axivity Ltd., Newcastle upon Tyne, UK) to
record raw acceleration data along with surface skin temperature. The
device, weighing a mere 11 g and with dimensions of 23 mm × 32.5 mm ×
7.6 mm, measures acceleration in gravity units (g) across three axes
(vertical, mediolateral, and anteroposterior). The sampling frequencies
were set at 50 Hz for the PHASAR study and 25 Hz for the in-house study.
However, all recorded data from both studies were uniformly resampled to
30 Hz.

\hypertarget{description-of-the-studies}{%
\subsection{Description of the
Studies}\label{description-of-the-studies}}

\emph{PHASAR Study:} The PHASAR study involved a representative sample
of over 2000 school-aged children from 31 public schools in Denmark. The
study, conducted between 2017 and 2018, captured data from 1,315 boys
(49\%) and 1,358 girls (51\%), aged between 8.1 to 17.9 years (mean age
= 12.14, SD = 2.40). Accelerometers were placed at two specific
anatomical sites: the right hip and midway on the right thigh. They were
worn for a recommended seven consecutive days to reliably estimate
habitual physical activity. For this analysis, data from 64 randomly
selected participants from the PHASAR cohort were used. A dataset
indicating genuine non-wear time was created via manual annotation, a
method elaborated in another publication. Essentially, non-wear periods
were determined by visually examining raw accelerations coupled with
skin temperature readings. True non-wear episodes with specific start
and end times were manually labelled in each dataset and were utilized
as reference labels in subsequent analyses.

\emph{In-House Validation Study:} This study consisted of accelerometer
data from 42 youth athletes, evenly split between boys and girls, aged
14.5 to 16.4 years (mean age = 15.4, SD = 0.37 years). These athletes,
part of a specialized talent program in the Region of Southern Denmark,
wore the Axivity accelerometer on their non-dominant wrist for 14
consecutive days. This study was initiated in the spring of 2021. A
dataset mirroring the one from the PHASAR study was created, including
all 42 participants.

\hypertarget{ethical-considerations}{%
\subsection{Ethical Considerations}\label{ethical-considerations}}

The PHASAR study was reviewed by the Regional Committee on Health
Research Ethics for Southern Denmark (ID: S-20170031) and was determined
not to require an ethics review, as per Danish regulations, which
mandate only biomedical research or risk-involved studies to undergo a
formal ethics review. Documentation regarding this decision is available
upon request from the principal author. Conversely, the in-house
validation study received an ethical approval waiver from the Research
\& Innovation Organization and the legal department of the University of
Southern Denmark. All participants, or their legal guardians, provided
written informed consent for both studies, which adhered to the Danish
Data Protection Agency (2015-57-0008) standards and globally recognized
guidelines like the Declaration of Helsinki.

\begin{figure}

{\centering \includegraphics{figures/paper2_flowchart.pdf}

}

\caption{\label{fig-paper2_flowchart}The flowchart depicts the division
of the PHASAR dataset into training and testing segments. On the left,
boxes signify 79.2\% of the PHASAR data designated for training across
five-fold resamples. On the right, the yellow and blue boxes
collectively represent 20.2\% of the PHASAR data, specifically
delineating the hip and thigh data for testing. The green box represents
our separate in-house test dataset, which was gathered from wrist-worn
devices.}

\end{figure}

\hypertarget{development-of-decision-tree-models}{%
\subsection{Development of Decision Tree
Models:}\label{development-of-decision-tree-models}}

For our decision tree models, we sourced 12 predictors from the raw
PHASAR accelerometer data, which encompassed elements like temperature,
time of day, indicators for device placement, day of the week, and
moving average statistics (detailed in Table~\ref{tbl-8}). These moving
average metrics were collated in 10-second increments. To train the
model, we utilized 79.2\% of the PHASAR data, incorporating data from
both hip- and thigh-worn devices (as shown in
Figure~\ref{fig-paper2_flowchart}). A critical aspect of our methodology
was the data partitioning: we made certain that data from individual
participants was exclusively allocated to either the training or test
datasets. This strategy was crucial in ensuring that the model could
effectively generalize to unfamiliar data, rather than overfitting to
specific participant data. During the tuning phase, to boost model
accuracy and avoid overfitting, we opted for a five-fold
cross-validation approach. This process entailed refining several
hyperparameters, such as the tree's depth, its cost-complexity, and the
minimum amount of data points necessary in a node for it to split
further. To effectively explore the hyperparameter space, we employed
Latin hypercube sampling. This method systematically divides the
parameter range into segments, randomly drawing a value from each
segment, resulting in a well-distributed set of parameter combinations.
In our case, we established a 10-level parameter grid, guaranteeing a
comprehensive exploration of the hyperparameter space.

Following this procedure, we introduced three distinct model variations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  A full-scope model (\emph{tree\_full}) incorporating every predictor.
\item
  A refined model (\emph{tree\_imp6}) centered on the six most crucial
  predictors, as established by permutation predictor importance
  (Figure~\ref{fig-importance}).
\item
  A model excluding surface skin temperature data
  (\emph{tree\_no\_temp}).
\end{enumerate}

In sum, our methodology generated 50 distinct models for each decision
tree variant. Given our data's distribution - 55.8\% wear time compared
to 44.2\% non-wear time - there was no need to adopt synthetic minority
oversampling methods like SMOTE or other balancing techniques.

\begingroup

\footnotesize

\hypertarget{tbl-8}{}
\begin{longtable}{ll}
\caption{\label{tbl-8}Predictors derived from the raw sensor signals. }\tabularnewline

\toprule
Predictor & Description \\ 
\midrule
Weekday & Day of week ([1:7]) \\ 
time\_day & Time of day (milliseconds) \\ 
Location & Device wear location: 0 = thigh, 1 = hip \\ 
macc\_x & Moving average of the z axis acceleration \\ 
macc\_y & Moving average of the y axis acceleration \\ 
macc\_z & Moving average of the z axis acceleration \\ 
sdacc\_x & Moving average of the standard deviation on the x axis acceleration \\ 
sdacc\_y & Moving average of the standard deviation of the y axis acceleration \\ 
sdacc\_z & Moving average of the standard deviation of the z axis acceleration \\ 
Sdmax & Maximum standard deviation \\ 
Incl & Inclination angle of the device in relation to the direction of the gravitational force \\ 
Temp & Surface skin temperature (degrees Celsius) \\ 
\bottomrule
\end{longtable}

\endgroup

\newpage

\begin{figure}

{\centering \includegraphics{figures/paper2_vip.pdf}

}

\caption{\label{fig-importance}Permutation importance plot depicting the
significance of predictors in the decision tree. The top six predictors
informed the tree\_imp6 model, while a third model, tree\_no\_temp, was
trained using all predictors except temperature.}

\end{figure}

\hypertarget{statistics-1}{%
\subsection{Statistics}\label{statistics-1}}

We assessed the classification performance to each ground truth test
dataset, which combined consisted of over 7 million 10-second epochs
from 104 distinct subjects. True positives (TP) represent correctly
identified non-wear time, and true negatives (TN) denote correctly
identified wear time. Both TPs and TNs are vital for the algorithm's
accuracy. These correct classifications are vital for the high accuracy
of our non-wear time algorithm. Misclassifications, where non-wear time
is labeled as wear and vice-versa, resulted in False Negatives (FN) and
False Positives (FP). To determine these classifications, we analyzed
the acceleration data in 10-second intervals, comparing inferred results
with ground truth labels. This comparison allowed us to construct a
confusion matrix. We then computed the overall accuracy, sensitivity,
precision, and F1-score to evaluate the effectiveness of each non-wear
detection method. Notably, a high F1-score, which is the harmonic mean
of precision and sensitivity, indicates superior classification
performance. We further delved into the permutation predictor importance
to discern the factors behind the enhanced performance of our decision
tree models. All our analyses and model developments were conducted
using R (version 4.1.2, Bird Hippie) and RStudio (version 2021.9.1.372,
Ghost Orchid), with Tidymodels for machine learning and the rpart
package serving as the decision tree algorithm engine.

\[accuracy = \frac{TP+TN}{TP+TN+FP+FN}\]
\[sensitivity = \frac{TP}{TP+FN}\] \[precision = \frac{TP}{TP+FP}\]
\[F_1 = 2 \cdot \frac{precision \cdot sensitivity}{precision + sensitivity}\]

The F1-score, which is the harmonic mean of precision and sensitivity,
provides an indicator of the classification performance. A high F1-score
suggests commendable classification prowess.

Additionally, we delved into the permutation predictor importance to
discern what factors contributed to the superior performance of certain
decision tree models.

For all analytical processes and model development, we utilized R
(version 4.1.2, Bird Hippie) and RStudio (version 2021.9.1.372, Ghost
Orchid). The machine learning tasks were primarily facilitated by the
Tidymodels\textsuperscript{\protect\hyperlink{ref-kuhn_tidymodels_2020}{140}}
suite of packages, and we used the
rpart\textsuperscript{\protect\hyperlink{ref-rpart}{141}} package as the
engine for our decision tree algorithms.

\hypertarget{results-1}{%
\section{Results}\label{results-1}}

In our gold standard datasets spanning three wear locations, there were
1,598 non-wear time episodes. Of these, 1,148 episodes (or 71.8\%)
lasted 60 minutes or more, with an average duration of about 13 hours
(794 minutes with a standard deviation of 1,142 minutes). In contrast,
episodes lasting 60 minutes or less made up 28.2\% (450 episodes) with
an average duration of 26.4 minutes (SD = 16.4). Interestingly, the
briefest episodes (less than 60 minutes) made up just 1.3\% of the total
non-wear time across all wear locations (refer to Table~\ref{tbl-9}).
Figure~\ref{fig-paper2_nw_dists} depicts the frequency distribution for
episodes shorter than 60 minutes and those 60 minutes or longer. The
PHASAR dataset showed a bimodal distribution for shorter episodes, with
longer episodes peaking around 10 hours. For the in-house wrist-worn
dataset, shorter episodes displayed a uniform distribution, while longer
episodes were significantly right-skewed.

\begingroup

\footnotesize

\hypertarget{tbl-9}{}
\begin{longtable}{lrrr}
\caption{\label{tbl-9}Overview of non-wear episodes grouped in short and long non-wear
episodes. ¹ Aggregated in minutes. ² Proportion of total non-wear time
by wear location. }\tabularnewline

\toprule
Wear location & Mean¹ & Cumulated¹ & Proportion² \\ 
\midrule
\multicolumn{4}{l}{<60 minutes} \\ 
\midrule
hip & $28$ & $3,202$ & $1.1\%$ \\ 
thigh & $25$ & $3,975$ & $1.4\%$ \\ 
wrist & $27$ & $4,691$ & $1.3\%$ \\ 
\midrule
\multicolumn{4}{l}{≥60 minutes} \\ 
\midrule
hip & $828$ & $279,785$ & $98.9\%$ \\ 
thigh & $776$ & $280,294$ & $98.6\%$ \\ 
wrist & $782$ & $351,179$ & $98.7\%$ \\ 
\bottomrule
\end{longtable}

\endgroup

\begin{figure}

{\centering \includegraphics{figures/paper2_plot_nw_dists.pdf}

}

\caption{\label{fig-paper2_nw_dists}Distribution of the length of the
non-wear episodes across hip, thigh, and wrist data. Distributions are
shown for episodes shorter than 60 min (binwidth = 1 minute) and longer
than 60 min (binwidth = 1 hour).}

\end{figure}

\hypertarget{classification-performance}{%
\subsection{Classification
Performance}\label{classification-performance}}

In assessing classification performance,
Figure~\ref{fig-paper2_preds_ex} visually contrasts the results from
machine-learned models and rule-based algorithms against the ground
truth non-wear time, which is highlighted with a light blue background.
This visualization underscores that while tree-based models tend to be
precise, they can also be unpredictable. On the other hand,
threshold-based methods, such as Syed\_CNN, heu\_alg, and cz\_60, offer
more consistency. Notably, both cz\_60 and heu\_alg algorithms fall
short in identifying shorter non-wear episodes.

Detailing further, Figure~\ref{fig-paper2_performance_all} compiles
performance metrics from all methods evaluated in this study. The CNN
model by Syed et al.~demonstrated consistency across three datasets,
achieving an overall accuracy between 75\% and 80\%. It stood out with a
sensitivity score between 93\% and 96\%. However, its F1 scores, which
hovered between 82\% and 84\%, were hampered by only average precision.
Conversely, the random forests model by Sundararajan et al.~shone with
wrist data, boasting an F1 score of 94\% and accuracy of 93\%. Still,
its performance dwindled with hip and thigh data, marking an overall
accuracy of 56\% and precision of 59\%. This drop suggests a significant
number of false positives.

Among the decision tree models, the variant excluding surface skin
temperature as a predictor fared the poorest for wrist data, achieving a
mere 72\% accuracy. While it secured a high sensitivity score of 98\%,
its subpar precision dragged its F1 score down to 81\%. The other two
decision tree models---one incorporating the six most critical
predictors and the other using all predictors---consistently performed
well across metrics and datasets. Remarkably, both the heu\_alg and
cz\_60 algorithms approached perfection across evaluations.

Further, Figure~\ref{fig-paper2_performance_short} zeroes in on
performance metrics for episodes 60 minutes or shorter. The consecutive
zeros algorithm was unable to detect any non-wear, a result absent from
the figure. Syed et al.'s deep learning model underperformed, detecting
a mere 1--2\% of all non-wear time, leading to F1 scores below 5\%.
Although the heu\_alg algorithm boasted high precision, its lackluster
sensitivity resulted in F1 scores spanning from 12\% to 16\% across wear
locations. The random forest model displayed average results for thigh
and wrist data but faltered with hip data, recording F1 scores of 46\%,
57\%, and 8\%, respectively. Among the trio of decision tree models, the
one leveraging the six pivotal predictors outshone the rest, with F1
scores between 72\% and 79\%. Meanwhile, the decision tree model
encompassing all predictors faced challenges with hip data due to a 23\%
sensitivity score. Excluding the surface skin temperature, another
decision tree model exhibited commendable precision; however, its low
sensitivity culminated in F1 scores ranging from 45\% to 57\%.

\begin{figure}

{\centering \includegraphics{figures/paper2_plot_preds_example.pdf}

}

\caption{\label{fig-paper2_preds_ex}Visual example of the output of
non-wear detection models and algorithms for a random person from the
in-house wrist dataset (14 consecutive days). The grey shade is
ground-truth non-wear time. Syed\_CNN, cz\_60, and tree\_full are
vertically offset for easier interpretation.}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/paper2_performance_all.pdf}

}

\caption{\label{fig-paper2_performance_all}Classification performance
metrics on all non-wear episodes for the seven included methods for
classifying non-wear time. Metrics are shown for the three different
ground-truth dataset including hip-worn, thigh-worn, and wrist-worn raw
accelerometer data.}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/paper2_performance_short.pdf}

}

\caption{\label{fig-paper2_performance_short}Classification performance
for episodes no longer than 60 min in length. Metrics are shown for the
three different gold-standard dataset including hip-worn, thigh-worn,
and wrist-worn raw accelerometer data.}

\end{figure}

\newpage

\hypertarget{paper-iii-improving-sleep-quality-estimation-in-children-and-adolescents-a-comparative-study-of-machine-learning-and-deep-learning-techniques-utilizing-free-living-accelerometer-data-from-thigh-worn-devices-and-eeg-based-sleep-tracking}{%
\chapter{Paper III: Improving Sleep Quality Estimation in Children and
Adolescents: A Comparative Study of Machine Learning and Deep Learning
Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn
Devices and EEG-Based Sleep
Tracking}\label{paper-iii-improving-sleep-quality-estimation-in-children-and-adolescents-a-comparative-study-of-machine-learning-and-deep-learning-techniques-utilizing-free-living-accelerometer-data-from-thigh-worn-devices-and-eeg-based-sleep-tracking}}

This segment of the thesis encompasses the methods, results, and
discussion for Paper III. Polysomnography, the premier method for sleep
evaluation, is not always feasible for extensive research due to its
high costs and impracticality. Wearable accelerometers present an
affordable solution. While wrist and hip-worn devices dominate sleep
studies, the potential of thigh-worn accelerometers remains largely
untapped. This paper delves into the use of machine learning and deep
learning models that leverage data from thigh-worn accelerometers to
gauge sleep and its quality. By comparing these models with an EEG-based
sleep monitor and utilizing data from 585 days and nights of children
aged 4-17 years, we discerned that the XGBoost model, particularly when
applied to 5-minute median filtered data, showcased the most promise.
This model demonstrated minimal biases and a robust correlation with
total sleep time, highlighting its applicability. Nevertheless, our
findings also exposed certain limitations, especially in determining
awake intervals during in-bed periods. Thus, while our results are
encouraging for group-level sleep quality estimation using machine
learning, further refinement is essential for precise individual
assessments due to observed limits of agreement in thigh-worn
accelerometry data.

\hypertarget{methods-2}{%
\section{Methods}\label{methods-2}}

\hypertarget{dataset-and-participants}{%
\subsection{Dataset and Participants}\label{dataset-and-participants}}

The current study uses data from the SCREENS trial, which took place
from June 2019 to March 2021 in the Region of Southern Denmark.
Conducted by Rasmussen and
Pedersen\textsuperscript{\protect\hyperlink{ref-rasmussen_short-term_2020}{113},\protect\hyperlink{ref-pedersen_effects_2022}{142}},
the trial aimed to evaluate the impact of limiting screen media usage
among Danish families. We specifically analyzed data from children
between the ages of 4 and 17, with a mean age of 9.1 years, who were
part of the SCREENS cohort. To gather our primary data, we utilized
accelerometer readings from Axivity AX3 devices attached to the
children's thighs and sleep metrics derived from EEG readings using the
ZM device by General Sleep Corporation.

The Axivity AX3 is a 3-axis accelerometer positioned midway between the
hip and knee on the right anterior thigh. This device records movement
data, and it is unobtrusive, allowing for natural behavior from the
children. On the other hand, the ZM device uses advanced EEG hardware
and signal processing algorithms to gather sleep data. It features three
self-adhesive, disposable sensors placed outside the hairline, ensuring
reliable EEG signal acquisition. Participants were instructed to attach
the device at bedtime and remove it upon leaving bed. To process the
sleep data, the ZM device uses two proprietary algorithms, Z-ALG and
Z-PLUS. The former is known for its accurate sleep detection
capabilities, which make it suitable for in-home monitoring as supported
by Kaplan et
al.\textsuperscript{\protect\hyperlink{ref-kaplan_performance_2014}{52}},
while the latter differentiates between sleep stages and aligns well
with expert evaluations using PSG data, as demonstrated by Wang et
al.\textsuperscript{\protect\hyperlink{ref-wang_evaluation_2015}{53}}.

In this study, we didn't focus on different sleep stages like light
sleep (N1 \& N2), deep sleep (N3), and REM sleep; instead, we
categorized the output of the ZM into ``awake'' and ``asleep.'' This
simplification was made to streamline the data for the machine learning
algorithms and because distinguishing between sleep stages was not
crucial for the sleep quality metrics of interest. As illustrated in
Figure~\ref{fig-paper3_flow}, we only considered recordings that had
complete accelerometer data from the Axivity AX3 and ZM readings lasting
between 7 and 14 hours. Recordings with sensor issues reported by the ZM
were excluded. As a result, our study included a total of 585 nights
from 151 children, with an average of 3.87 nights per child (SD = 1.86).
The mean age of these children was 9.4 years, with a standard deviation
of 2.1. Our study encompassed 696,779 epochs, each lasting 30 seconds,
and about 84\% of the ZM recordings were classified as sleep.

Lastly, the study adhered to ethical guidelines, receiving approval from
the Regional Scientific Committee of Southern Denmark. All data handling
processes were in compliance with the General Data Protection Regulation
(GDPR), ensuring the secure and ethical management of participant
information.

\begin{figure}

{\centering \includegraphics{figures/paper3_flowchart.pdf}

}

\caption{\label{fig-paper3_flow}Flowchart of eligible ZM recording
nights included in the study.}

\end{figure}

\hypertarget{data-preprocessing-and-feature-extraction}{%
\subsection{Data preprocessing and Feature
Extraction}\label{data-preprocessing-and-feature-extraction}}

In this study, we began by processing raw accelerometer data through a
low-pass filtration step, utilizing a 4th order Butterworth filter with
a 5 Hz cut-off frequency to remove high-frequency noise as described by
Skotte and
colleagues\textsuperscript{\protect\hyperlink{ref-skotte_detection_2014}{65}}.
Non-wear data was identified and eliminated using the methods outlined
in Paper
2\textsuperscript{\protect\hyperlink{ref-skovgaard_generalizability_2023}{134}},
and the remaining data was resampled into 30-second epochs to align with
ZM recordings. We then conducted feature extraction, generating 64
features that offered a comprehensive characterization of the data.
These features were derived from both accelerometer and temperature
signals and included temporal elements, which utilized both lag and lead
values to capture dynamic data trends. Additionally, we took inspiration
from Walch et
al.\textsuperscript{\protect\hyperlink{ref-walch_sleep_2019}{143}} to
include sensor-independent features that encapsulate circadian rhythms,
offering unique insights that are not directly discernible from sensor
outputs (see Figure~\ref{fig-paper3_sensor_independent}). We further
enriched the feature set by incorporating signal characteristics such as
vector magnitude, mean crossing rate, skewness, and kurtosis for each of
the x, y, and z dimensions. The ZM recordings and the corresponding
accelerometer data were then merged. Any time overlap between these two
sets of data was categorized as `in-bed' time, while the remaining time
was considered `out-of-bed.' This process yielded a comprehensive
dataset that provided a 24-hour view of each participant's activity and
sleep patterns.

Upon examining the raw ZM predictions, we observed that the device
appeared to overestimate the number of awakenings among the children
studied. Although the ZM software addresses many of these awakenings by
counting only three consecutive awake epochs towards wake time, this
approach renders the raw predictions less suitable as training data for
machine learning algorithms. In fact, many of these awakenings, labeled
by the ZM, would be more aptly described as arousals rather than actual
awakenings. Separately, the ZM device's sleep efficiency rating for our
sample was 83\%, which is below recognized standards. An efficiency of
85\% is considered good, and over 90\% is seen as ideal. This contrasts
with prior research on similar child cohorts that reported a sleep
efficiency of
88.3\%\textsuperscript{\protect\hyperlink{ref-galland_2018}{144}}.
Recommendations from an expert panel by the National Sleep Foundation
emphasize that fewer than 2 awakenings lasting more than 5 minutes each
night qualify as good sleep across all age
groups\textsuperscript{\protect\hyperlink{ref-ohayon_2017}{145}}.
Additionally, it's widely recognized that children typically experience
between five to eight sleep cycles every night, with awakenings most
likely occurring at the conclusion of each
cycle\textsuperscript{\protect\hyperlink{ref-galland_normal_2012}{146}}.
However, definitions of a ``waking bout'' vary across studies. Some
demand at least 5 continuous minutes of wakefulness for it to be counted
as one bout, while others find a 1-minute duration adequate. Of
particular note, many short arousal epochs labeled as awake by the ZM
did not show significant shifts in the accelerometer signal. This
misalignment might distort underlying patterns for machine learning
algorithms. While this might not be outright mislabeling, categorizing
all such epochs as true awakenings could introduce noise, jeopardizing
model accuracy. In light of these observations, we opted to process both
the raw ZM output and versions with 5-minute and 10-minute median
filtering for our model training and evaluation. This approach minimized
noise and offered an awakening count more aligned with typical patterns
in children's sleep (see Table~\ref{tbl-10} for details).

\begin{figure}

{\centering \includegraphics{/home/esbenlykke/projects/thesis/figures/paper3_sensor_independent.pdf}

}

\caption{\label{fig-paper3_sensor_independent}Sensor-independent
features of circadian rhythms across two consecutive nights. A) cosinus
feature, B) linear feature.}

\end{figure}

\begin{figure}

{\centering \includegraphics{/home/esbenlykke/projects/thesis/figures/paper3_zm_raw_vs_filtered.pdf}

}

\caption{\label{fig-paper3_raw_filt}The difference in number of
awakenings between the raw ZM predictions vs.~5-minute, and 10-minute
median filtered predictions for a random night (boy, 9 years). Grey line
is the raw predictions, black line is the median filtered predictions.
A: 5-minute median filter on raw ZM predictions, B: 10-minute median
filter on raw ZM predictions.}

\end{figure}

\hypertarget{algorithms}{%
\subsection{Algorithms}\label{algorithms}}

In our study to assess sleep patterns, we utilized thigh-mounted
accelerometer data and employed two distinct modeling strategies. The
first approach involved a sequential strategy using a series of binary
classifiers, aiming to simplify the task by breaking down the multiclass
problem into more manageable parts. Initially, we predicted `in-bed'
times, which were then subjected to a 5-minute median filter to
eliminate transient blips. This allowed us to identify a single
continuous time interval, termed the Sleep Period Time (SPT), which
represents the total time spent in bed attempting to sleep. The SPT
served as the input for a second set of binary classifiers focused on
predicting `sleep' time, thereby improving their predictive accuracy.

Four machine learning algorithms were applied in this sequential
strategy. Logistic regression acted as a fast and straightforward
baseline model, although its linear nature limited its ability to
capture complex, non-linear patterns. Decision trees, capable of
handling non-linear patterns, were implemented with a maximum tree depth
of 8 to mitigate overfitting and maintain easy interpretability.
Single-layer feed-forward neural networks, while challenging to
interpret, were effective in capturing non-linear relationships. Careful
tuning was required to avoid overfitting. Lastly, XGBoost was used for
its high accuracy and built-in overfitting prevention techniques,
despite its computational intensity and interpretational challenges.

Simultaneously, we also explored a second modeling strategy using a
multiclass algorithm based on a bidirectional Long Short-Term Memory
(biLSTM) neural
network\textsuperscript{\protect\hyperlink{ref-hochreiter_long_1997}{147}}.
This model was designed to predict three distinct sleep states:
`out-of-bed-awake,' `in-bed-awake,' and `in-bed-asleep.' It featured
four layers and 128 hidden units per layer, balancing model complexity
and training efficiency. The bidirectional architecture doubled the
hidden units at each time step, enhancing data interpretation and
reducing the risk of overfitting. The model accepted sequences of
tensors spanning 10 minutes with a step size of one epoch. This approach
is supported by previous research such as studies by Sano et
al.~(2019)\textsuperscript{\protect\hyperlink{ref-sano_multimodal_2019}{148}}{]}
and Chen et
al.~(2021)\textsuperscript{\protect\hyperlink{ref-chen_attention_2021}{149}}{]},
which have demonstrated the efficacy of LSTM models in sleep detection
by capturing complex temporal patterns in accelerometer data.

\hypertarget{model-training}{%
\subsection{Model Training}\label{model-training}}

We trained a total of four pairs of models sequentially to distinguish
between two sets of states: in-bed/out-of-bed and asleep/awake. The
dataset was randomly split into a training and a testing set, each
containing approximately half of the subjects. To ensure the robustness
of the results, we made sure that data from the same night was not
distributed across both sets. To optimize our models, we used a specific
set of hyperparameters for each type of machine learning algorithm. For
the Decision Tree, we tuned the cost complexity, tree depth, and minimum
number of samples required at a leaf node. The decision tree model was
set up using the
\texttt{rpart}\textsuperscript{\protect\hyperlink{ref-rpart}{141}}
engine for classification, with tree depth ranging from 3 to 7. For
Logistic Regression, implemented using the
\texttt{glmnet}\textsuperscript{\protect\hyperlink{ref-friedman_glmnet_2010}{150}}
engine, we considered tuning the penalty and mixture parameters. The
feed-forward neural network was implemented with a single-layer
feed-forward architecture using the
\texttt{nnet}\textsuperscript{\protect\hyperlink{ref-nnet}{151}} engine,
with the maximum number of allowable weights set to 7000 as a form of
regularization. The hyperparameters we tuned for this model were the
number of hidden units, the penalty, and the number of epochs. The range
for the number of hidden units was between 3 and 27. Lastly, the XGBoost
model was configured with the
\texttt{xgboost}\textsuperscript{\protect\hyperlink{ref-xgboost}{152}}
engine. The hyperparameters subjected to tuning included tree depth,
learning rate, loss reduction, minimum number of samples required at a
leaf node, sample size, and number of trees. For this algorithm, the
number of trees was specifically tuned within a range of 200 to 800.
These hyperparameters were optimized using a 10-fold Monte Carlo
cross-validation, carried out on a regular grid comprising different
combinations of these parameters. By providing the range and the
specific hyperparameters considered for each model, we ensured the most
robust and optimal model fitting.

After identifying the best-performing hyperparameters, we proceeded to
fit the models to the full training dataset. This approach made it
possible to use all available data for model parameter estimation, thus
maximizing performance. However, an imbalance issue was noted after the
initial step of our sequential model strategy. This imbalance in the
resulting dataset - the awake in-bed class was underrepresented, making
up only about 15\% of the training data - could induce biases during
model training, as models tend to favor the majority class. To correct
this, we employed the Synthetic Minority Over-sampling Technique (SMOTE)
as outlined by Chawla et
al.\textsuperscript{\protect\hyperlink{ref-chawla_smote_2002}{153}}.
Using the themis R
package\textsuperscript{\protect\hyperlink{ref-themis}{154}}, we
implemented SMOTE to achieve a balanced distribution of training samples
across both classes. The F1 score served as the optimization metric
because it balances both precision and recall, and therefore is more
robust to class imbalance.

In parallel to these sequential models, we also trained a bidirectional
Long Short-Term Memory (biLSTM) model to classify three distinct states:
out-of-bed-awake, in-bed-awake, and in-bed-asleep. The data for this
model was divided into training, validation, and test sets, adhering to
a 50/25/25 split ratio. Again, caution was exercised to avoid having
data from the same night across different sets. For efficient and
adaptive learning, the Adam optimizer was used during the training
process. Given that we were dealing with a multiclass classification
task with mutually exclusive classes, the cross-entropy loss function
was employed. At the output layer, a softmax activation function was
applied to obtain a probability distribution over the classes. We
monitored the model's performance using the F1 score for both the
training and validation sets and employed early stopping with a patience
of 3 epochs, ceasing training if no improvement in the validation loss
was observed over three consecutive epochs.

\hypertarget{model-validation}{%
\subsection{Model Validation}\label{model-validation}}

In our study, we utilized standard evaluation metrics to assess the
performance of each model on an epoch-to-epoch basis. These include
\[accuracy = \frac{TP+TN}{TP+TN+FP+FN}\]
\[sensitivity = \frac{TP}{TP+FN}\] \[specificity = \frac{TN}{TN+FP}\]
\[precision = \frac{TP}{TP+FP}\] \[NPV = \frac{TN}{TN + FN}\]
\[F_1 = 2 \cdot \frac{precision \cdot sensitivity}{precision + sensitivity}\]

where \(NPV\) is negative predictive value, \(F_1\) is the F1 score,
\(TP\) is true positives, \(FP\) is false positives, \(TN\) is true
negatives, and \(FN\) is false negatives.

In our sequential model strategy, we initially focused on models that
carried out binary classification tasks distinguishing between in-bed
and out-of-bed states. We gauged these models' performance through
various metrics, including the F1-score, accuracy, sensitivity,
specificity, and precision. Subsequently, we shifted our focus to models
that could identify the binary state of being asleep or awake, using the
same metrics as well as the negative predictive rate. Due to the class
imbalance, we calculated the F1 score as an unweighted macro-average. We
also scrutinized a multiclass biLSTM classifier using the same metrics,
interpreting its multiclass output as two separate binary
classifications: out-of-bed versus all other states, and in-bed-awake
versus in-bed-asleep. To give a comprehensive view of model performance,
we offered confusion matrices for the entire dataset, covering both
in-bed and out-of-bed data. These matrices report relative counts,
column percentages for accurate predictions of the true class, and row
percentages for correctly classified predictions. Both in-bed/out-of-bed
and awake/asleep classification tasks were treated as binary,
designating `in-bed' and `asleep' as positive labels and `out-of-bed'
and `awake' as negative labels, in line with prior
studies\textsuperscript{\protect\hyperlink{ref-hjorth_measure_2012}{74},\protect\hyperlink{ref-kushida_comparison_2001}{155}}.

To evaluate how well our models performed in generating sleep quality
metrics, we employed Bland-Altman plots and Pearson correlations.
Specifically, the Bland-Altman approach was used to gauge the level of
agreement between two different measurement techniques. Since our
dataset included multiple but uneven observations per subject, we used a
bootstrap procedure to account for extra variability. We initially
calculated the mean difference or bias, and then determined the limits
of agreement (LOA) as the bias ± 1.96 times the standard deviation of
these differences. Given the possibility of non-normal distribution and
skewness in our data, we opted for a bias-corrected and accelerated
(BCa) bootstrap method {[}@diciccio\_bootstrap\_1996{]}. This allowed
for more accurate estimation, taking into account intra-subject
variability. Using 10,000 bootstrap replicates, we confirmed 95\%
confidence intervals for both the bias and LOA, thereby ensuring robust
measurements. Our sleep quality metrics conformed to ZM definitions and
included the following:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sleep Period Time (SPT) - This refers to the total duration of time in
  bed with the intention to sleep, which is defined as the time from the
  start to the end of the ZM recording.
\item
  Total Sleep Time (TST) - This is the time spent asleep within the SPT.
\item
  Sleep Efficiency (SE) - This is the ratio between TST and SPT,
  representing the proportion of the sleep period that was actually
  spent asleep.
\item
  Latency Until Persistent Sleep (LPS) - This metric represents the time
  it takes to transition from wakefulness to sustained sleep. It is
  calculated as the time from the beginning of the ZM recording until
  the first period when 10 out of 12 minutes are scored as sleep.
\item
  Wake After Sleep Onset (WASO) - This refers to the time spent awake
  after initially falling asleep and before the final awakening. In our
  analysis, a period is counted as `awake' only if it consists of 3 or
  more contiguous 30-second epochs which is also how the ZM summarizes
  WASO.
\end{enumerate}

The technical frameworks used for model development and analyses were R
version
4.3.0\textsuperscript{\protect\hyperlink{ref-rcoreteam_2023}{156}} along
with the
Tidymodels\textsuperscript{\protect\hyperlink{ref-kuhn_tidymodels_2020}{140}}
and
Tidyverse\textsuperscript{\protect\hyperlink{ref-wickham_tidyverse_2019}{157}}
package suites. For the biLSTM model, we used Python version
3.10.6\textsuperscript{\protect\hyperlink{ref-vanrossum_python_2009}{158}}
and
PyTorch\textsuperscript{\protect\hyperlink{ref-paszke_pytorch_2019}{159}}.

\hypertarget{results-2}{%
\section{Results}\label{results-2}}

As indicated in Table~\ref{tbl-10}, the application of 5-minute and
10-minute median filters led to modifications in the sleep quality
metrics derived from ZM predictions. SPT remained consistent between raw
and filtered data sets, with a mean duration of 9.2 ± 2.1 hours, which
aligns with the length of the ZM recording. Interestingly, bothTST and
SE saw increases in the filtered datasets, suggesting that the filters
may be classifying some periods of wakefulness as sleep. Specifically,
the mean TST rose from 7.7 ± 1.9 hours in the raw data to 8.1 ± 2.0
hours with a 5-minute filter and 8.2 ± 2.1 hours with a 10-minute
filter. Similarly, SE increased from an initial mean of 82.6 ± 12.0\% to
86.4 ± 12.7\% and 87.5 ± 12.9\% for the 5-minute and 10-minute filters,
respectively.

Furthermore, the LPS also saw an increase, implying that the filters may
be removing brief awakenings at the onset of sleep, thereby lengthening
the time it takes to achieve persistent sleep. On the other hand, the
WASO metric decreased from a raw average of 39.0 ± 33.6 minutes to 30.6
± 46.8 minutes and 22.3 ± 55.4 minutes in the 5-minute and 10-minute
filtered data, respectively. Notably, the application of these filters
also led to a significant reduction in the average number of awakenings
per night. In the unfiltered data, the mean number of awakenings stood
at 34.46 ± 11.33, which dramatically dropped to 4.43 ± 3.26 and 1.95 ±
2.01 in the 5-minute and 10-minute filtered datasets, respectively.

\begingroup

\footnotesize

\hypertarget{tbl-10}{}
\begin{longtable}{lrrrrrr}
\caption{\label{tbl-10}Overview of characteristics of the ZM sleep quality summaries per night
(585 nights from 151 children). Values are represented as mean (SD).
Hrs: hours, min: minutes. }\tabularnewline

\toprule
 & SPT (hrs) & TST (hrs) & SE (\%) & LPS (min) & WASO (min) & Awakenings (N) \\ 
\midrule
Raw ZM Predictions & 9.2 (2.1) & 7.7 (1.9) & 82.6 (12) & 34.5 (27.9) & 39 (33.6) & 34.5 (11.3) \\ 
5-Min Median & 9.2 (2.1) & 8.1 (2) & 86.4 (12.7) & 36.3 (39.8) & 30.6 (46.8) & 4.4 (3.3) \\ 
10-Min Median & 9.2 (2.1) & 8.2 (2.1) & 87.5 (12.9) & 38 (48.7) & 22.3 (55.4) & 1.9 (2) \\ 
\bottomrule
\end{longtable}

\endgroup

\hypertarget{performance-on-epoch-to-epoch-basis}{%
\subsection{Performance on Epoch-to-Epoch
Basis}\label{performance-on-epoch-to-epoch-basis}}

As delineated in Table~\ref{tbl-11}, the epoch-to-epoch evaluation for
predicting in-bed time shows virtually identical performance across
various model types. The F1 score fluctuates slightly, ranging from
94.4\% in the Decision Tree model to 95.4\% in the XGBoost model.
Likewise, accuracy varies minimally from 95.3\% for the Decision Tree
model to 96.1\% for the XGBoost model. Other metrics such as
Sensitivity, Precision, and Specificity also exhibit uniform performance
across the different models. While the XGBoost model does exhibit the
highest performance with an F1 score of 95.4\% and an accuracy of
96.1\%, it only marginally surpasses the other models in these metrics.

\begingroup

\footnotesize

\hypertarget{tbl-11}{}
\begin{longtable}{lrrrrr}
\caption{\label{tbl-11}Performance metrics of the classification of in-bed/out-of-bed time of
the included models. }\tabularnewline

\toprule
 & F1 Score (\%) & Accuracy (\%) & Sensitivity (\%) & Precision (\%) & Specificity (\%) \\ 
\midrule
Decision Tree & $94.4$ & $95.3$ & $93.1$ & $95.6$ & $96.9$ \\ 
Logistic Regression & $95.0$ & $95.7$ & $95.0$ & $94.9$ & $96.3$ \\ 
Feed-Forward Neural Net & $95.0$ & $95.8$ & $95.1$ & $95.0$ & $96.3$ \\ 
XGBoost & $95.4$ & $96.1$ & $95.8$ & $94.9$ & $96.2$ \\ 
biLSTM & $95.2$ & $95.3$ & $95.3$ & $95.1$ & $95.3$ \\ 
\bottomrule
\end{longtable}

\endgroup

As noted in Table~\ref{tbl-12}, the performance metrics for all types of
sequential models in raw and median-filtered (5 and 10 minute) ZM
predictions for sleep/wake classification are summarized. In the raw ZM
predictions, the F1 scores, calculated as unweighted macro averages,
vary from 65.6\% for the biLSTM model to 76.2\% for the XGBoost model.
While all models demonstrate similar performance, low specificity values
ranging from 62.5\% to 70.9\% indicate challenges in accurately
classifying awake epochs. When a 5-minute median filter is applied,
there is a noticeable improvement in performance metrics, with the
XGBoost model achieving the highest F1 score of 79.2\% and an NPV of
74.0\%. Nonetheless, specificity continues to be low across all models,
registering values between 54.7\% for XGBoost and 74.8\% for Logistic
Regression. Upon application of a 10-minute median filter, the metrics
experience further improvement. The XGBoost model retains its leading
position with an F1 score of 80.9\% and an NPV of 75.9\%. Despite these
improvements, specificity remains a challenge, showing a range from
57.5\% for the Decision Tree model to 76.4\% for Logistic Regression
across all model types.

\begingroup

\footnotesize

\hypertarget{tbl-12}{}
\begin{longtable}{lrrrrr}
\caption{\label{tbl-12}Performance metrics of the sleep/wake classification of the included
models. }\tabularnewline

\toprule
 & F1 Score (\%) & Precision (\%) & NPV (\%) & Sensitivity (\%) & Specificity (\%) \\ 
\midrule
\multicolumn{6}{l}{Raw ZM Predictions} \\ 
\midrule
Decision Tree & $72.9$ & $93.2$ & $48.4$ & $86.3$ & $67.1$ \\ 
Logistic Regression & $71.0$ & $93.7$ & $43.9$ & $82.7$ & $70.9$ \\ 
Neural Network & $71.8$ & $93.8$ & $45.1$ & $83.6$ & $70.8$ \\ 
XGBoost & $76.2$ & $92.8$ & $58.0$ & $91.3$ & $62.8$ \\ 
biLSTM & $65.6$ & $80.6$ & $80.6$ & $62.5$ & $62.5$ \\ 
\midrule
\multicolumn{6}{l}{5-Min Median} \\ 
\midrule
Decision Tree & $75.5$ & $94.2$ & $55.5$ & $93.4$ & $59.0$ \\ 
Logistic Regression & $68.3$ & $95.8$ & $36.0$ & $81.4$ & $74.8$ \\ 
Neural Network & $71.7$ & $95.8$ & $41.6$ & $85.6$ & $73.1$ \\ 
XGBoost & $79.2$ & $93.9$ & $74.0$ & $97.3$ & $54.7$ \\ 
biLSTM & $70.3$ & $84.6$ & $84.6$ & $66.2$ & $66.2$ \\ 
\midrule
\multicolumn{6}{l}{10-Min Median} \\ 
\midrule
Decision Tree & $76.3$ & $94.7$ & $58.1$ & $94.9$ & $57.5$ \\ 
Logistic Regression & $68.0$ & $96.5$ & $34.3$ & $81.9$ & $76.4$ \\ 
Neural Network & $71.0$ & $96.1$ & $39.5$ & $86.5$ & $71.4$ \\ 
XGBoost & $80.9$ & $94.9$ & $75.8$ & $97.7$ & $57.6$ \\ 
biLSTM & $70.9$ & $75.1$ & $75.1$ & $68.5$ & $68.5$ \\ 
\bottomrule
\end{longtable}

\endgroup

Figure~\ref{fig-bin_conf_mat} and Figure~\ref{fig-mul_conf_mat} presents
a comprehensive set of confusion matrices generated from data that
includes both out-of-bed and in-bed times. These matrices offer insights
into the epoch-to-epoch performance of all sequential models when
differentiating between `awake' and `asleep' states, irrespective of
whether the subject is in bed or out of bed. However, it's crucial to
acknowledge that the sequential models, owing to their binary nature,
are not equipped to directly classify the `in-bed-awake' state. In
contrast, the biLSTM model, which does identify the `in-bed-awake' state
as a separate class, seems to be less successful in classifying this
specific state.

\begin{figure}

{\centering \includegraphics{figures/all_binary_conf_mats.pdf}

}

\caption{\label{fig-bin_conf_mat}Confusion matrices for the binary
predictions. The middle of each tile is the normalized count (overall
percentage). The bottom number of each tile is the column percentage and
the right side of each tile is the row percentage. i) decision tree, ii)
logistic regression, iii) feed-forward neural net, iv) XGBoost}

\end{figure}

\begin{figure}

{\centering \includegraphics{figures/all_multiclass_conf_mats.pdf}

}

\caption{\label{fig-mul_conf_mat}Confusion matrices for the biLSTM
predictions. The middle of each tile is the normalized count (overall
percentage). The bottom number of each tile is the column percentage and
the right side of each tile is the row percentage.}

\end{figure}

\hypertarget{evaluation-of-sleep-quality-metrics}{%
\subsection{Evaluation of Sleep Quality
Metrics}\label{evaluation-of-sleep-quality-metrics}}

The comparative analysis of the models used for predicting various sleep
quality metrics such as SPT, TST, SE, LPS, and WASO is provided in
Table~\ref{tbl-13}. The complete table, which also includes models
developed from raw ZM predictions and 10-minute median-filtered ZM
predictions, can be found in table 1 of the supplementary materials.
Concerning bias, the Decision Tree model tends to underestimate SPT,
TST, and SE while overestimating LPS and WASO when compared to ZM.
Similar trends are evident in the Logistic Regression model, although
the underestimation in TST and overestimation in LPS are more
pronounced. The Feed-forward Neural Network shows a similar bias pattern
as the Decision Tree and Logistic Regression models but has higher
overestimation in WASO. In contrast, the XGBoost model exhibits the
least bias, particularly in its 5-minute median predictions.

When examining the Limits of Agreement (LOA), the Decision Tree model
displays higher variability in the differences across the sleep quality
metrics and filtering techniques, particularly for LPS and WASO,
suggesting lower agreement with ZM. Other models exhibit comparable LOA
but with some noteworthy exceptions; for instance, the LOA for TST in
the Logistic Regression model is particularly wide when 5-minute median
predictions are considered. In terms of correlation, the Pearson
coefficient indicates that the XGBoost model consistently shows the
highest correlation with ZM across all sleep quality metrics and
filtering methods. Notably, the strongest correlation (0.66) for TST is
observed in the XGBoost model's 5-minute median predictions among all
models and filtering techniques.

\begingroup

\footnotesize

\hypertarget{tbl-13}{}
\begin{longtable}{lrrrr}
\caption{\label{tbl-13}Summary of bias, limits of agreement, and Pearson correlation for
various sleep parameter predictions (SPT, TST, SE, LPS, WASO) using
different machine learning and deep learning models (decision tree,
logistic regression, feed-forward neural network, XGBoost) on raw ZM
predictions, 5-minute and 10-minute median predictions. Each value is
provided with its 95\% confidence interval (CI). }\tabularnewline

\toprule
 & Bias (95\% CI) & lower LOA (95\% CI) & upper LOA (95\% CI) & Pearson, \emph{r} (95\% CI) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - Decision Tree} \\ 
\midrule
SPT (min) & -21.6 (-25.6;-17.6) & -117.5 (-125.6;-110.7) & 74.2 (63.9;85.9) & 0.54 (0.48;0.6) \\ 
TST (min) & -148 (-153.8;-142.4) & -283 (-295.5;-272.6) & -13.1 (-22.8;-1) & 0.3 (0.22;0.37) \\ 
SE (\%) & -22.7 (-23.7;-21.8) & -45.5 (-47.5;-43.8) & 0 (-1.6;1.9) & 0.17 (0.09;0.24) \\ 
LPS (min) & 28.9 (24.5;33.2) & -76 (-87.6;-69.8) & 133.8 (124.6;144.7) & 0.13 (0.05;0.21) \\ 
WASO (min) & 46.1 (43;49.4) & -33.2 (-43.4;-26.2) & 125.4 (117.7;138.8) & 0.29 (0.22;0.37) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - Decision Tree} \\ 
\midrule
SPT (min) & -21.6 (-25.6;-17.6) & -117.5 (-125.6;-110.7) & 74.2 (63.9;85.9) & 0.54 (0.48;0.6) \\ 
TST (min) & -50.5 (-55.2;-46) & -161.4 (-175.8;-151.3) & 60.4 (51.5;71.7) & 0.48 (0.42;0.54) \\ 
SE (\%) & -5.5 (-6.3;-4.7) & -23.9 (-26.4;-22.2) & 12.9 (11.6;14.6) & 0.22 (0.14;0.29) \\ 
LPS (min) & 24.6 (19.7;29.1) & -88.8 (-115;-77.3) & 138 (126.2;156.7) & 0.06 (-0.02;0.14) \\ 
WASO (min) & 9.9 (6.5;14) & -79.4 (-109;-63.1) & 99.2 (80;136.1) & 0.15 (0.07;0.22) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - Decision Tree} \\ 
\midrule
SPT (min) & -21.8 (-25.7;-17.8) & -117.3 (-125.2;-110.4) & 73.7 (63.4;85.4) & 0.54 (0.48;0.6) \\ 
TST (min) & -31.5 (-35.7;-27.4) & -129.9 (-140.9;-121.8) & 67 (58.3;77.7) & 0.56 (0.5;0.61) \\ 
SE (\%) & -2.1 (-2.8;-1.4) & -18 (-19.9;-16.6) & 13.9 (12.6;15.3) & 0.22 (0.14;0.29) \\ 
LPS (min) & 22.8 (17.1;27.6) & -102.7 (-137.1;-83.3) & 148.4 (131.9;173.6) & 0.06 (-0.02;0.14) \\ 
WASO (min) & 9 (5.2;14.3) & -97.4 (-133.5;-72.1) & 115.3 (85.2;163) & 0.07 (-0.02;0.15) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - Logistic Regression} \\ 
\midrule
SPT (min) & -4 (-8.3;0.7) & -113.5 (-122.7;-106.1) & 105.5 (95;118.7) & 0.37 (0.29;0.43) \\ 
TST (min) & -139.2 (-145.7;-132.8) & -291.6 (-306.1;-279.2) & 13.1 (3.8;23.5) & 0.12 (0.04;0.2) \\ 
SE (\%) & -23.1 (-24;-22.1) & -45.6 (-47.4;-44) & -0.6 (-2;1) & 0.18 (0.1;0.26) \\ 
LPS (min) & 47.5 (43.6;51.4) & -46.2 (-57;-38.6) & 141.2 (131;154.5) & 0.1 (0.01;0.18) \\ 
WASO (min) & 48.7 (45.3;52.1) & -34.7 (-46.2;-28) & 132.1 (124.6;147.3) & 0.25 (0.17;0.33) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - Logistic Regression} \\ 
\midrule
SPT (min) & -3.7 (-8;1) & -112.2 (-120.9;-105.2) & 104.8 (94;117.4) & 0.38 (0.3;0.44) \\ 
TST (min) & -139.7 (-146.9;-133) & -305.6 (-323.6;-291.8) & 26.2 (16.1;38.6) & 0.09 (0.01;0.17) \\ 
SE (\%) & -23.2 (-24.3;-22.2) & -48.1 (-50.9;-46.1) & 1.7 (0.1;3.8) & 0.13 (0.05;0.21) \\ 
LPS (min) & 58.1 (53.4;62.6) & -52.3 (-75;-40.1) & 168.6 (155.9;187.7) & 0.05 (-0.03;0.13) \\ 
WASO (min) & 45.4 (41.7;49.7) & -50.7 (-74.4;-38.4) & 141.5 (126.8;173) & 0.19 (0.11;0.27) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - Logistic Regression} \\ 
\midrule
SPT (min) & -4.2 (-8.6;0.5) & -113.4 (-122.4;-106) & 105 (94.2;118) & 0.37 (0.3;0.44) \\ 
TST (min) & -130.9 (-138;-124.2) & -295.1 (-311.8;-281.4) & 33.2 (23.3;45.1) & 0.09 (0.01;0.17) \\ 
SE (\%) & -21.6 (-22.6;-20.6) & -45.7 (-48.2;-43.8) & 2.5 (1;4.3) & 0.13 (0.05;0.21) \\ 
LPS (min) & 60.7 (54.9;65.6) & -64.8 (-100.8;-43.9) & 186.2 (168.1;213.6) & 0.02 (-0.06;0.1) \\ 
WASO (min) & 44.8 (40.8;50) & -66 (-98.3;-45.1) & 155.7 (130.2;197.8) & 0.17 (0.09;0.25) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - Feed-Forward Neural Net} \\ 
\midrule
SPT (min) & -3.9 (-8.1;0.9) & -112.7 (-122;-105.2) & 104.9 (94.1;118.4) & 0.38 (0.3;0.44) \\ 
TST (min) & -154 (-159.9;-148) & -297 (-308.6;-287) & -10.9 (-20;-0.5) & 0.25 (0.17;0.32) \\ 
SE (\%) & -25.6 (-26.5;-24.7) & -48.2 (-50;-46.6) & -3 (-4.5;-1.2) & 0.23 (0.15;0.31) \\ 
LPS (min) & 34.3 (30.2;38.6) & -67.7 (-80.1;-60.5) & 136.4 (126.4;149.3) & 0.11 (0.03;0.19) \\ 
WASO (min) & 58.7 (55.4;62.1) & -23.8 (-33.9;-17.5) & 141.2 (133.9;155.6) & 0.33 (0.26;0.4) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - Feed-Forward Neural Net} \\ 
\midrule
SPT (min) & -3.9 (-8.1;0.9) & -112.7 (-122;-105.2) & 104.9 (94.1;118.4) & 0.38 (0.3;0.44) \\ 
TST (min) & -126.5 (-132.8;-120.3) & -276.8 (-291.3;-264.7) & 23.9 (14.8;33.9) & 0.25 (0.17;0.32) \\ 
SE (\%) & -20.9 (-21.9;-19.9) & -44.3 (-46.3;-42.5) & 2.5 (1.1;4) & 0.21 (0.13;0.29) \\ 
LPS (min) & 35.3 (30.7;39.8) & -75.8 (-102.3;-63.4) & 146.5 (134.4;166.9) & 0.07 (-0.01;0.15) \\ 
WASO (min) & 45 (41.2;49.2) & -51.8 (-76.4;-39.1) & 141.7 (125.8;174.1) & 0.21 (0.14;0.29) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - Feed-Forward Neural Net} \\ 
\midrule
SPT (min) & -4.1 (-8.5;0.6) & -112.6 (-121.7;-105) & 104.5 (93.5;117.6) & 0.38 (0.31;0.45) \\ 
TST (min) & -116.3 (-122.9;-110.3) & -266.2 (-280.4;-254.2) & 33.6 (24.7;43.4) & 0.29 (0.21;0.36) \\ 
SE (\%) & -19.1 (-20.1;-18.1) & -42.9 (-44.8;-41.1) & 4.7 (3.3;6.2) & 0.25 (0.17;0.33) \\ 
LPS (min) & 33.8 (28;38.6) & -91.1 (-127.2;-70.2) & 158.6 (141.2;184.7) & 0.05 (-0.03;0.13) \\ 
WASO (min) & 53.4 (49.2;58.7) & -58.6 (-89.6;-38.6) & 165.4 (140.4;206.7) & 0.22 (0.14;0.3) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - XGboost} \\ 
\midrule
SPT (min) & 0.2 (-3.7;4.5) & -97.4 (-106.2;-90.3) & 97.8 (86.6;111) & 0.56 (0.5;0.61) \\ 
TST (min) & -66 (-70.8;-61.4) & -178.1 (-187.9;-169.6) & 46.1 (38.9;54.5) & 0.47 (0.4;0.53) \\ 
SE (\%) & -11.1 (-11.8;-10.4) & -28.8 (-30.2;-27.5) & 6.5 (5.5;7.7) & 0.37 (0.29;0.44) \\ 
LPS (min) & 34.5 (30.6;38.5) & -62.4 (-75.8;-55.2) & 131.3 (121.1;143.9) & 0.2 (0.12;0.28) \\ 
WASO (min) & 18.4 (15.6;21.2) & -50.2 (-62.7;-43.1) & 86.9 (79.8;104.2) & 0.36 (0.28;0.43) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - XGboost} \\ 
\midrule
SPT (min) & 0.2 (-3.7;4.5) & -97.4 (-106.2;-90.3) & 97.8 (86.6;111) & 0.56 (0.5;0.61) \\ 
TST (min) & -7 (-10.8;-3.3) & -95.5 (-105.2;-88) & 81.4 (72.4;92.5) & 0.66 (0.61;0.7) \\ 
SE (\%) & -1.1 (-1.7;-0.5) & -15.6 (-17;-14.4) & 13.3 (12.2;14.7) & 0.44 (0.38;0.51) \\ 
LPS (min) & 28.5 (23.9;32.6) & -76.4 (-104.2;-63.3) & 133.4 (120.4;154.2) & 0.12 (0.04;0.2) \\ 
WASO (min) & -0.9 (-3.9;3) & -83.4 (-113.1;-66) & 81.7 (62;119.6) & 0.26 (0.18;0.33) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - XGboost} \\ 
\midrule
SPT (min) & 0.2 (-3.8;4.4) & -97.4 (-106.1;-90) & 97.9 (86.7;111.1) & 0.56 (0.5;0.61) \\ 
TST (min) & -4.2 (-7.7;-0.5) & -90.6 (-101.3;-82.9) & 82.3 (72.3;95.3) & 0.67 (0.62;0.71) \\ 
SE (\%) & -0.6 (-1.2;-0.1) & -14.5 (-16;-13.3) & 13.2 (12.1;14.9) & 0.43 (0.36;0.49) \\ 
LPS (min) & 26.4 (21;30.8) & -92.2 (-130;-69.5) & 145 (125.5;173.7) & 0.1 (0.02;0.18) \\ 
WASO (min) & 3.8 (0.3;9.1) & -98.1 (-135.4;-71.9) & 105.7 (74.5;153.4) & 0.2 (0.13;0.28) \\ 
\midrule
\multicolumn{5}{l}{Raw ZM Predictions - biLSTM} \\ 
\midrule
SPT (min) & -36.7 (-42.6;-30.3) & -141.4 (-153.2;-132) & 68 (54.5;85.5) & 0.5 (0.4;0.58) \\ 
TST (min) & 39 (33.3;44.9) & -60.1 (-72.9;-51.1) & 138 (126;152) & 0.53 (0.44;0.61) \\ 
SE (\%) & 12.6 (11.8;13.3) & 0 (-1.6;1.1) & 25.2 (23.6;27.2) & 0.07 (-0.05;0.18) \\ 
LPS (min) & -17.6 (-24.1;-11.3) & -127.2 (-177.4;-97.4) & 92.1 (63.4;143.8) & 0.05 (-0.06;0.17) \\ 
WASO (min) & -15.9 (-21;-8.9) & -116.1 (-158.9;-95.4) & 84.3 (58.9;138.2) & 0.04 (-0.07;0.16) \\ 
\midrule
\multicolumn{5}{l}{5-Min Median - biLSTM} \\ 
\midrule
SPT (min) & -36.1 (-41.7;-30) & -136.1 (-146.3;-126.9) & 64 (51.1;78.6) & 0.54 (0.45;0.62) \\ 
TST (min) & 12.8 (7.4;18.3) & -80.1 (-89.8;-72.3) & 105.8 (94.3;118.8) & 0.63 (0.55;0.69) \\ 
SE (\%) & 8 (7.2;8.8) & -5.1 (-6.8;-3.8) & 21.1 (19.5;23.1) & 0.16 (0.04;0.27) \\ 
LPS (min) & -15.7 (-25.9;-7.5) & -169 (-230.7;-127.9) & 137.6 (101.1;184.9) & 0.09 (-0.02;0.2) \\ 
WASO (min) & -3 (-9.9;7.7) & -144.1 (-197.2;-107.2) & 138.1 (90.8;211.4) & 0.02 (-0.1;0.13) \\ 
\midrule
\multicolumn{5}{l}{10-Min Median - biLSTM} \\ 
\midrule
SPT (min) & -83.7 (-90.7;-76.1) & -207.4 (-221.3;-195.2) & 40 (27.7;57.1) & 0.3 (0.19;0.4) \\ 
TST (min) & -42.2 (-49.3;-35.1) & -162 (-176.9;-149.6) & 77.6 (66.3;90.4) & 0.4 (0.29;0.49) \\ 
SE (\%) & 6.4 (5.7;7.2) & -6.5 (-7.8;-5.3) & 19.2 (17.7;21.2) & 0.16 (0.04;0.27) \\ 
LPS (min) & -21.5 (-32.7;-12.8) & -187.2 (-253.4;-138.6) & 144.3 (104.3;192.6) & 0.06 (-0.05;0.18) \\ 
WASO (min) & 26.8 (19.2;38) & -128.2 (-176.3;-90.8) & 181.8 (132.8;250.7) & 0.12 (0.01;0.23) \\ 
\bottomrule
\end{longtable}

\endgroup

The Bland-Altman plot and scatterplot presented in
Figure~\ref{fig-xgb_ba_cor} demonstrate the level of agreement between
the XGBoost model, trained on 5-minute median filtered ZM predictions,
and ZM-derived sleep quality metrics that were also median-smoothed over
5 minutes. For the sleep quality metrics SPT and TST, the bias is
notably close to zero, revealing a minimal average difference with the
ZM. The scatterplot for SPT also suggests a moderate linear correlation
between the model's predictions and the ZM-derived metrics. Similarly,
the bias and LOA for TST align closely with those for SPT, reflecting a
consistent agreement between the XGBoost model and ZM. The TST
scatterplot further indicates a slightly higher correlation, mainly due
to the lack of extreme outliers. In contrast, the remaining sleep
quality metrics, namely SE, LPS, and WASO, show signs of
heteroscedasticity unlike SPT and TST. While a moderate positive linear
correlation exists between the XGBoost model and the ZM-derived SE
metrics, poorer correlations are observed for LPS and WASO.

\begin{figure}

{\centering \includegraphics{figures/median_5_xgboost_ba_cor.pdf}

}

\caption{\label{fig-xgb_ba_cor}Comparison of sleep quality metrics
derived from the XGBoost model trained on the 5-minute smoothed ZM
predictions. The left column displays Bland-Altman plots. Dashed lines
represent the bias (the average difference between the two measurements)
and LOA, with the 95\% confidence intervals represented as the grayed
areas. The right column displays scatter plots of XGBoost-derived vs
ZM-derived sleep quality metrics. The dashed line represents the
identity line, while the full-drawn line represents the best linear fit.
Pearson's correlations are annotated in the upper left corner}

\end{figure}

\hypertarget{summary-and-discussion-of-results}{%
\chapter{Summary and Discussion of
Results}\label{summary-and-discussion-of-results}}

The following section\ldots{}

\hypertarget{manual-annotation}{%
\section{Manual Annotation}\label{manual-annotation}}

In this study, we introduced a methodology for manually annotating
periods spent in bed using accelerometry data. The accuracy of this
method was rigorously evaluated through multiple raters and then
compared to sleep assessments made with EEG-based ZM and self-reported
sleep data. When examining the lower limit of the 95\% confidence
interval in Intraclass Correlation Coefficient (ICC) analyses, we found
several noteworthy results. First, the method exhibited
good-to-excellent interrater reliability. Second, intra-rater
reliability also showed good to excellent agreement across all three
raters between their first and second rounds of annotations. Third, when
compared to ZM, the average manual in-bed annotations from all raters
ranged from good to excellent in terms of agreement. Fourth, the
self-reported in-bed timestamps were also in good to excellent agreement
with ZM. Additionally, Bland-Altman analysis indicated that the mean
bias between both the manual annotations and self-reported sleep times
compared to ZM was within a range of ±6 minutes, with Limits of
Agreement (LOA) not exceeding ±45 minutes. Probability density
distribution plots further substantiated these findings, showing
comparable symmetry, spread around zero, and positioning of outliers
when the manual annotations and self-reported sleep times were compared
to ZM.

The high accuracy observed in the prospective sleep diaries in this
study can be attributed to their being synchronized with ZM. Having
participants manually start and end ZM recordings every morning and
evening enhances their ability to accurately recall their times of going
to bed and getting out of bed. This minimizes the usual discrepancies
often seen between objectively and subjectively measured sleep
durations\textsuperscript{\protect\hyperlink{ref-aili_reliability_2017}{160}}.
If participants had been instructed to log their sleep using only
subjective measures without these protocol anchors, we would not expect
to see such strong agreement between the manual annotations, sleep
diaries, and ZM data.

Compared to ZM, our study found that the manual annotation of in-bed
periods was more prone to errors when estimating the time of going to
bed. This issue mainly arose from raters' difficulties in
differentiating between inactive behaviors before sleep and actual sleep
time. Despite this significant limitation, the manual annotation method
displayed reassuring accuracy, especially considering the limited formal
training provided to the raters. This ease of use was aided by the
specific signal features we selected for study in Audacity, as evidenced
by the excellent ICC scores among raters.

Interestingly, our findings suggest a learning curve for the raters, as
evidenced by the narrower LOAs and the density plots in the second round
of manual scoring. These indicators suggest that additional rounds of
scoring could further improve result consistency or that preliminary
training could be beneficial for the raters. Consequently, future
research should explore methods to optimize the uniformity of these
manual annotations.

While there are various tools available for annotating time series data,
such as Label
Studio\textsuperscript{\protect\hyperlink{ref-label_studio}{129}} and
Visplore\textsuperscript{\protect\hyperlink{ref-visplore}{128}}, our
study found that Audacity was particularly well-suited for the task at
hand. Label Studio, for example, may struggle with handling week-long
accelerometer data consisting of over 100 million entries, whereas
Audacity excels in managing and navigating such large data sets. Our
feature selection was intentionally designed to avoid overwhelming the
raters with redundant information, opting for a limited but effective
combination of features based on domain knowledge. This approach could
be adapted for annotating other behaviors, like walking, though that
would necessitate a different set of features.

The raters in this study gained valuable insights despite the absence of
explicit guidelines for data annotation, highlighting the intuitive
nature of the method. It's important to note that labeling data
inherently involves a certain level of understanding of human behavior.
If such labels could be accurately determined based on a set of formal
rules, it raises the question of whether training an AI model would even
be necessary. Therefore, we recommend additional research to identify
the most critical features for successful manual annotations. Examining
the impact of varying feature sets could yield further insights that
would streamline the manual annotation of accelerometer time series
data.

To date, many studies comparing actigraphy and self-report methods to
polysomnography (PSG) or EEG-based methodologies have focused primarily
on evaluating aggregate sleep parameters. These include total sleep
time, wake after sleep onset, sleep latency, and sleep efficiency. These
aggregate measures incorporate both sleep onset and wake onset times,
analogous to the ``to-bed'' and ``out-of-bed'' timestamps used in our
current study. However, the precision of these specific time points is
rarely assessed, making direct comparisons with our study's measurements
challenging.

Our novel method for annotating time in bed has produced Intraclass
Correlation Coefficient (ICC) values that are on par with, or even
better than, previous studies that compared actigraphy sleep parameters
to
PSG\textsuperscript{\protect\hyperlink{ref-haghayegh_application_2020}{161},\protect\hyperlink{ref-yavuz-kodat_2019}{162}}.
One such study cited mean absolute errors of 39.9 minutes for sleep
onset time and 29.9 minutes for wake-up time, with 95\% limits of
agreement exceeding ±3 hours when comparing an algorithm to
PSG\textsuperscript{\protect\hyperlink{ref-van_hees_estimating_2018}{100}}.
In contrast, our methodology allows for a more precise estimation of
specific timestamps rather than durations of behaviors, resulting in
less room for error and better agreements.

Moreover, our manual annotation method demonstrated robust performance
across various age and gender groups. The study sample included both
children and adults of both genders, suggesting that our approach is
accurate regardless of the specific behaviors associated with different
developmental age groups and genders. This finding also indicates that
our manual annotation method may offer higher precision in estimating
exact time points compared to existing automated methodologies. Given
that the accuracy of sleep parameter assessments is often highly
contingent on the target population, the results of our study have
promising implications for their broad generalizability, particularly
among populations of normal sleepers.

Identifying sleep periods as opposed to merely lying down is a critical
aspect of 24-hour behavior profiling. Traditional studies on sleep
detection often rely on participants to self-report their time in bed,
sleep onset, and wake-up
times\textsuperscript{\protect\hyperlink{ref-girschik_validation_2012}{44},\protect\hyperlink{ref-littner_2003}{77},\protect\hyperlink{ref-lockley_1999}{123}}.
However, the manual annotation methodology using Audacity offers an
alternative that not only reduces the burden on participants but also
mitigates the recall bias inherent in self-reported measures. This
method can be easily applied to free-living data, making it incredibly
versatile for various applications beyond sleep detection.

For instance, the methodology is useful for annotating non-wear time,
manually synchronizing clocks across different devices, and validating
raw data. Its applicability also extends to multi-channel data,
providing a comprehensive overview that can incorporate variables like
orientation from gyroscopic data, temperature, battery voltage, and
light. Audacity stands out for its capability to handle large
multi-channel data files effortlessly. Researchers can quickly zoom to
any resolution and scroll through time without experiencing lag, which
makes it an ideal tool for adding labels. This fluidity in workflow
suggests that Audacity could become a standard tool for researchers
working with raw data and machine learning applications. Thus, the
incorporation of this Audacity-based methodology into raw accelerometer
data annotation is poised to significantly contribute to future human
behavior research.

For years, the transition from raw sensor data to operational predictive
models has relied on labeled data. Despite this, no previous research
has offered a methodology that allows researchers to optimally utilize
their available accelerometry data. Our study demonstrates that with a
judicious selection of features, manual annotation for identifying sleep
periods can yield results comparable to those achieved with EEG-based
sleep classification hardware. However, it's crucial to clarify that we
are not advocating for our manual annotation method to replace more
established techniques for sleep estimation, such as EEG or
tracheal-sound-based methods, in ongoing studies. Instead, our
methodology can be valuable as a post-hoc procedure to enrich existing
datasets with an additional measure of sleep.

This study boasts several strengths, notably the continuous, multi-day
data collection of accelerometry, sleep diary, and ZM recordings carried
out in participants' homes, which provides high-quality free-living
data. However, the study is not without limitations. One such limitation
pertains to rater generalizability. The three manual raters were fixed,
not selected randomly from a broader pool of eligible raters with
varying characteristics. Nevertheless, given the minimal pre-briefing
instructions for labeling raw data, we believe this methodology could be
generalizable to other researchers working with accelerometer data.

A logical next step in this research would be to create and validate a
standardized procedure for manual sleep annotation, akin to what is
available for EEG-based sleep annotation in the AASM Scoring
Manual\textsuperscript{\protect\hyperlink{ref-aasm}{163}}. This would
make the methodology more accessible to individuals with limited
experience in the field of accelerometry. Another concern is the
challenge of recording true free-living behavior using
participant-mounted devices like ZM, as wearing such a device during
sleep could affect participants' natural behavior, thereby posing a
study limitation.

Moreover, although the criterion measure in our study has been validated
against PSG, utilizing PSG as the criterion measure would have been more
optimal. Finally, the study did not consider napping behavior; its focus
was solely on sleep as it relates to circadian rhythms. As such, future
research is required to validate the utility of this manual annotation
methodology for detecting naps.

\hypertarget{non-wear-detection-and-generalizability}{%
\section{Non-Wear Detection and
Generalizability}\label{non-wear-detection-and-generalizability}}

In our study, we evaluated various methods for classifying non-wear
episodes in accelerometer data, focusing on episodes longer than 60
minutes and those shorter than 60 minutes. Our findings showed that the
simplest methods, specifically cz\_60 and heu\_alg, excelled in
identifying non-wear episodes longer than 60 minutes across all three
sensor wear locations: wrist, hip, and thigh. They were closely followed
in performance by decision tree models that included surface skin
temperature as a predictive variable. On the other hand, the random
forest model demonstrated excellent performance only on the wrist,
delivering mediocre results on the hip and thigh. When we shifted our
focus to short non-wear episodes lasting less than 60 minutes, we found
limitations in the cz\_60 and heu\_alg algorithms due to their built-in
minimum episode durations of 60 and 20 minutes, respectively. As a
result, their performance was poor for these shorter episodes.
Similarly, the deep learning model showed poor results, mainly
attributable to a low sensitivity score that led to many episodes being
misclassified as non-wear time. The random forest model's performance
was also poor on the hip and only mediocre on the thigh and wrist.
Decision tree models, both without temperature and with all predictors,
showed mediocre performance as well. However, a decision tree model
trained on the six most important predictors stood out as the best
performer for short non-wear episodes. Our study also highlighted the
value of incorporating surface skin temperature as a predictor to
enhance the performance of non-wear time classification. Overall, these
results provide valuable insights into the effectiveness of various
methods for classifying non-wear episodes in accelerometer data,
emphasizing the potential of simple algorithms like cz\_60 and heu\_alg,
especially for longer episodes, and the benefit of including surface
skin temperature as a predictive variable.

We discovered that most non-wear episodes in our ground truth datasets
had a duration exceeding 60 minutes, with a noticeable peak around the
10-hour mark. This finding contrasts with previous research that
typically reported shorter episodes as being more
prevalent\textsuperscript{\protect\hyperlink{ref-aadland_comparison_2018}{110},\protect\hyperlink{ref-jaeschke_variability_2018}{126},\protect\hyperlink{ref-hutto_identifying_2013}{164}}.
Our data prominently features children and physically active
adolescents, a demographic known to spend less time in sedentary
activities and to frequently interrupt such
periods\textsuperscript{\protect\hyperlink{ref-cooper_objectively_2015}{165},\protect\hyperlink{ref-kwon_breaks_2012}{166}}.
This likely contributed to both the longer non-wear episodes and
clarified the differentiation between sedentary behavior and non-wear
time in our study. The data favored simple heuristic algorithms for
classifying non-wear time, largely because the limitations imposed by
minimum window lengths had a negligible impact on the proportion of
non-wear time that was incorrectly classified. These algorithms achieved
excellent precision scores, confirming that neither sedentary time nor
sleep was misclassified as non-wear time. This is a significant finding,
given that multiple previous studies have pointed out the complexities
in making this very
distinction\textsuperscript{\protect\hyperlink{ref-duncan_wear-time_2018}{112},\protect\hyperlink{ref-doherty_large_2017}{120},\protect\hyperlink{ref-troiano_physical_2008}{136},\protect\hyperlink{ref-choi_validation_2011}{137},\protect\hyperlink{ref-barouni_ambulatory_2020}{167}}.
Our study suggests that a consecutive zeros algorithm could be deemed
best practice for capturing non-wear episodes lasting over 60 minutes in
children and adolescents. This recommendation is applicable across the
various wear locations that we evaluated, including the hip, thigh, and
wrist. However, it's important to consider that the specific behaviors
of children and adolescents may not make these findings directly
transferable to older adults. Yet, certain standardized procedures like
the syed\_CNN model for mounting and unmounting accelerometers might
have more universal applicability.

Creating a model to classify non-wear time appears to be a relatively
straightforward task, likely because the decision boundary involved is
close to linear. In this context, the use of complex models, as we've
included in our current study, may lead to overfitting. This overfitting
would capture random variations specific to the training dataset,
thereby reducing the model's ability to generalize to new, unseen data.
Consequently, we hypothesize that a well-optimized logistic regression
model could perform just as well as the more intricate methodologies
we've tested. The reason for this is that a logistic regression model
would establish a separating linear hyperplane capable of distinguishing
between wear and non-wear time effectively. Therefore, employing highly
non-linear models for this classification task might be an unnecessary
complication, particularly if the goal is to develop a machine learning
model that can be applied across diverse populations and wear locations.
It is also crucial to enrich the training data with multiple wear
locations and various physical activity profiles to improve
generalizability.

Incorporating surface skin temperature for the classification of
non-wear time has been minimally explored in the realm of machine
learning. One study did indicate that using acceleration data along with
rate-of-change in surface skin temperature could create a robust
decision tree model for detecting non-wear
time\textsuperscript{\protect\hyperlink{ref-vert_detecting_2022}{168}}.
This aligns with previous heuristic studies that have shown improved
predictive performance when temperature data is
included\textsuperscript{\protect\hyperlink{ref-duncan_wear-time_2018}{112},\protect\hyperlink{ref-zhou_classification_2015}{114}}.
Our own findings also corroborate this, as we observed that adding
surface skin temperature as a variable significantly enhances the
performance of the non-wear time model. However, a critical
consideration is the precise detection of the transition between wear
and non-wear periods, especially given the slow temperature step
response time of sensors. Solely relying on temperature data could
introduce classification delays if the sensor's response time is
sluggish. Combining both temperature and acceleration data is therefore
a more effective
approach\textsuperscript{\protect\hyperlink{ref-zhou_classification_2015}{114}}.
During our study, we noted a 20-minute step response in the Axivity
temperature sensor, which could be attributed to the design of the
device's casing. The sensor's response time may also be influenced by
the attachment method used. If more material is placed between the skin
and the device, delays are likely to occur, suggesting that machine
learning models should perhaps consider the type of sensor attachment in
their algorithms. Additionally, different brands of devices have been
found to have varying optimal temperature thresholds, further
complicating the issue. As noted by Duncan et al.~and Zhou et al.,
algorithmic modifications are needed for devices to function optimally
in different
latitudes\textsuperscript{\protect\hyperlink{ref-duncan_wear-time_2018}{112},\protect\hyperlink{ref-zhou_classification_2015}{114}}.
Therefore, the type of device and its attachment method can be critical
variables for improving the accuracy of non-wear time classification
models.

In the study of accelerometry data processing, the ideal scenario is to
employ a single model that performs reliably across different wear
locations and populations. To evaluate the generalizability and
robustness of the methods used in our study, we included a dataset from
wrist-worn devices for external validation. This ensures that the
performance metrics of our decision tree models are not artificially
inflated due to overfitting or lack of variance between the training and
testing data. External validation involves testing a model with
independently sourced datasets to confirm its performance. If a
predictor set has been inaccurately selected due to characteristics
inherent to the training data, such as technical or sampling bias, it is
likely to perform poorly during external
validation\textsuperscript{\protect\hyperlink{ref-steyerberg_prediction_2016}{169}}.
The rationale behind using external validation is strong: while data
from different sources may have fewer similarities, they can nonetheless
capture important domain-relevant information. A model trained to
identify truly informative predictors will maintain its performance even
when exposed to new data. Therefore, the external validation in our
study acts as a verification step, ensuring that our decision tree
models that pass this criterion are not just robust but also likely to
be interpretable within the
domain\textsuperscript{\protect\hyperlink{ref-altman_prognosis_2009}{170}}.
While Syed et al.'s methodology for identifying non-wear time is
innovative and logically coherent, we believe its performance may vary
depending on the age of the population in the dataset. The approach by
Syed et al.~focuses on identifying the specific shape of the
acceleration signal at the start and end of a non-wear episode. In
contrast, methods that simply identify non-wear time based on the
absence of acceleration are less dependent on the characteristics of the
population, since zero movement during non-wear is a universal trait.

Our results support this idea. The Convolutional Neural Network (CNN)
model developed by Syed et al.~showed poor performance across all wear
locations in our study. One possible reason for this could be the age
differences in the populations of the datasets. The original model was
trained on an older population, aged between 40-84 years (mean = 62.74,
SD = 10.25), whereas our study involved datasets of younger individuals
aged 8.1-17.9 years (mean = 12.14, SD = 2.40) for hip and thigh data,
and 14.5-16.4 years (mean = 15.4, SD = 0.37) for wrist data.
Contrastingly, the sunda\_RF model showed acceptable performance in
identifying non-wear episodes shorter than 60 minutes on both the thigh
and wrist data. This suggests that the model by Sundararajan et al.~is
less affected by population characteristics, as anticipated, compared to
the syed\_CNN model. Another point worth noting is that the syed\_CNN
model was originally trained on data with a frequency of 100 Hz, while
we applied it to data with frequencies of 50 Hz and 25 Hz. Although it's
unclear whether this frequency difference impacted the model's
performance, we believe that the 25 Hz data is sufficient for capturing
true movement behavior, given that movement frequencies are generally
below 5 Hz.

While it's standard to evaluate a machine learning model using a test
split from the same dataset used for training, known as internal
validation, this approach has its limitations. For instance, Syed et
al.~and Sundararajan et al.~report high metrics like sensitivity,
specificity, and accuracy for classifying non-wear time, but these
results are derived from cross-validation without an external validation
dataset\textsuperscript{\protect\hyperlink{ref-sundararajan_sleep_2021}{98},\protect\hyperlink{ref-syed_evaluating_2020}{139}}.
The absence of external validation raises questions about the models'
generalizability. Highly flexible models, without rigorous testing on
independent datasets, risk overfitting or learning dataset-specific
nuances rather than broader, more generalizable characteristics. This
concern is particularly relevant for Syed et al.'s model. Their
methodology could become more robust with training data from a more
varied population and a greater number of participants. Differences in
signal shapes for mounting and unmounting devices may vary with age or
other population characteristics, making a diverse training set
essential for improved generalizability. Given these challenges, future
research should focus on validating models with independent external
datasets prior to publication. While we recognize that accumulating
large and diverse datasets may not always be practically feasible, the
benefits in terms of model reliability and generalizability make it an
important consideration for future work.

The robustness of this study is significantly enhanced by the use of
external validation, which offers strong evidence of methodological
generalizability. However, there are limitations to consider. One major
issue is the absence of a universally accepted gold standard for ground
truth datasets in this research area. This lack of a benchmark makes it
challenging to compare performance metrics across different studies.
Despite this, our approach remains transparent since it relies on raw
accelerometer data, and no part of our data collection or analysis
process is proprietary. It's important to note that our findings are
based on a study population consisting of children and adolescents.
Consequently, the results may not be directly applicable to older age
groups. Additionally, while we chose to develop a decision tree model
for its balance of complexity and interpretability, future research
could explore the efficacy of other machine learning methods like
logistic regression, gradient boosting, or support vector machines.
These alternative algorithms may offer different insights or advantages
that could improve upon our current model.

\hypertarget{methods-to-detect-sleep-and-derive-sleep-quality-metrics}{%
\section{Methods to Detect Sleep and Derive Sleep Quality
Metrics}\label{methods-to-detect-sleep-and-derive-sleep-quality-metrics}}

In our quest to find the most effective method for estimating sleep
based on thigh-worn accelerometers, we scrutinized various models
designed to predict both in-bed and sleep times, as well as associated
sleep quality metrics. These models were trained and assessed using both
raw and median-filtered sleep estimates derived from the ZM EEG-based
sleep monitor. Overall, all sequential models exhibited strong
performance in predicting when subjects were in bed. However,
distinguishing between wakefulness and sleep during these in-bed periods
proved to be more challenging. Interestingly, while the multiclass
biLSTM model excelled in terms of F1 score, precision, and NPV, it
lagged behind in deriving sleep quality metrics when compared to the
XGBoost model. The latter outperformed all others across every
evaluation metric, including epoch-to-epoch prediction and various sleep
quality indicators. Nonetheless, it's worth noting that all models
struggled with low specificity values, indicating a common difficulty in
accurately identifying awake epochs during time spent in bed. We also
observed performance improvement in all models when 5-minute and
10-minute median filters were applied. This filtering approach resulted
in increased total sleep time and sleep efficiency metrics while
reducing wake after sleep onset and the number of awakenings. Of all the
models, the XGBoost demonstrated the smallest bias and the highest
correlation with the ZM sleep quality metrics, making it the most robust
choice for this particular application.

While there is limited existing research on the epoch-to-epoch
effectiveness of thigh-worn accelerometers in classifying in-bed time,
Carlson and
colleagues\textsuperscript{\protect\hyperlink{ref-carlson_validity_2021}{116}}
have offered valuable insights. Their study demonstrated that both a
third-party algorithm called ``ProcessingPal'' and a proprietary
algorithm named ``CREA'' were able to achieve high accuracies of 91\%
and 86\%, respectively. Evaluated against self-reported measures in
adolescents and adults, these algorithms yielded impressive F1 scores as
high as 95\% and 96\%. This is consistent with our sequential models,
which also managed to surpass 95\% in both F1 and accuracy scores for
identifying in-bed time, equated in our study with SPT. However, it's
worth noting that all models in our study, with the exception of
XGBoost, tended to underestimate SPT. The biLSTM model displayed the
most significant underestimation, with a bias of -36 minutes. This
aligns with previous research by Winkler et
al.\textsuperscript{\protect\hyperlink{ref-winkler_identifying_2016}{119}},
who reported a similar trend in both young-middle-aged and older adults.
Their algorithm showed a moderate correlation with diary-recorded waking
times but overestimated waking wear time by more than 30 minutes,
resulting in an underestimation of in-bed time. This underestimation was
further validated by Inan-Eroglu et
al.\textsuperscript{\protect\hyperlink{ref-inan-eroglu_comparison_2021}{117}},
who found an underestimation of 9.8 minutes when comparing Winkler et
al.'s algorithm to self-reported measures in middle-aged adults.
Contrastingly, another study reported only a slight underestimation of
in-bed time in middle-aged and older
adults\textsuperscript{\protect\hyperlink{ref-van_der_berg_identifying_2016}{118}}.
They used a unique algorithmic approach that quantified the number and
duration of sedentary periods to ascertain time in bed and active
periods to identify wake times. Lastly, it's essential to clarify that
strong predictive performance in identifying in-bed time doesn't
automatically imply accurate predictions for broader sleep quality
metrics. Capturing awake periods during in-bed time, a critical factor
for assessing other derived sleep quality metrics, isn't effectively
handled by simply predicting in-bed time. This distinction between
actual sleep and time spent in bed while awake is often overlooked but
is vital for a more comprehensive understanding of sleep quality.

To our knowledge, Johansson and
colleagues\textsuperscript{\protect\hyperlink{ref-johansson_development_2023}{84}}
are the only researchers who have gone beyond merely reporting ``waking
time'' and ``in-bed time'' to provide epoch-to-epoch performance metrics
for sleep scoring with thigh-worn accelerometers. Utilizing a
single-night evaluation dataset comprising 71 adult subjects, they
managed a mean sensitivity of 0.84, a specificity of 0.55, and an
accuracy of 0.80. Similarly, our models achieved a high sensitivity of
above 97\%, but struggled, like Johansson et al.'s algorithm, in
detecting in-bed awake epochs. This struggle is manifested in our low
specificity scores, which ranged from 54.7\% to 76.4\%. This challenge
is not solely confined to thigh-worn devices. Conley et
al.'s\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{69}}
meta-analysis reported issues with wrist-worn accelerometers as well,
noting mean values of 0.89 for sensitivity, 0.88 for accuracy, and a low
0.53 for specificity among healthy adults. Patterson and colleagues also
recently summarized various heuristic algorithms, machine learning, and
deep learning models for sleep prediction, finding mean sensitivity and
specificity scores of 93\% and 60\%, respectively. These data
collectively highlight the persistent difficulty in automating the
identification of periods when individuals are awake yet still in bed.
Interestingly, we noted a divergence in our study regarding the
overestimation of LPS and WASO by several of our models, in contrast to
most previous research. This overestimation is evident in the low NPV
scores, suggesting that only a small fraction of the wake predictions
are accurate. This inconsistency might be attributed to the SMOTE we
used to balance the dataset. If the synthetic `wake' samples created by
SMOTE don't accurately represent the actual `wake' data, it could cause
the models to misclassify certain `sleep' epochs as `wake'.
Consequently, this could lead to inflated LPS and WASO estimates, as the
models would incorrectly identify more instances of wakefulness during
sleep.

The application of the SMOTE in our study likely enhanced the
performance of various models by addressing class imbalance issues.
However, the introduction of synthetic ``wake'' samples through this
method posed a challenge as they might not be fully indicative of
genuine wake data. This could explain why some models, including the
biLSTM which was not trained on SMOTE-processed data, overestimated TST
and SE. Contrarily, the XGBoost model, trained on SMOTE-processed data,
managed to navigate these synthetic ``wake'' samples more effectively
and did not overestimate TST as much as other models. Interestingly,
Bland-Altman statistics for the XGBoost model trained on 5-minute
median-filtered ZM predictions indicated a mean difference of -7 minutes
for TST and -1.1\% for SE. The limits of agreement for these metrics
spanned from -95.5 to 81.4 minutes and -15.6\% to 13.3\% respectively.
This suggests that the XGBoost model successfully maintained a balance
between sensitivity and specificity without being overly swayed by the
synthetic ``wake'' samples. The resilience of the XGBoost model to these
synthetic samples could be attributed to its gradient boosting
mechanism, which allows for iterative learning from prior models'
errors. Such an iterative learning process likely rendered XGBoost more
robust against inaccuracies that might be introduced by synthetic data,
ultimately leading to a better overall model performance.

Sleep detection methods are generally used in two distinct scenarios:
night-only recordings and 24-hour recordings. For night recordings, SE
and LPS can be readily derived since SPT can be inferred from the length
of the recording itself, as indicated by studies from Conley et al.~and
Patterson et
al\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{69},\protect\hyperlink{ref-patterson_40_2023}{171}}.
In contrast, when applied to 24-hour recordings, most sleep detection
methods face the challenge of inferring SPT without the aid of sleep
diaries, as presented by several
studies\textsuperscript{\protect\hyperlink{ref-girschik_validation_2012}{44},\protect\hyperlink{ref-doherty_large_2017}{120},\protect\hyperlink{ref-anderson_assessment_2014}{122}}.
This limitation prevents these methods from generating sleep quality
metrics dependent on SPT. To address this issue, we designed models
capable of distinguishing between in-bed awake time and in-bed asleep
time, as well as out-of-bed awake time, over a full 24-hour period. This
innovation allows our models to estimate a comprehensive range of
commonly used sleep quality metrics. In a similar vein, Van Hees et
al.\textsuperscript{\protect\hyperlink{ref-van_hees_estimating_2018}{100}}
proposed an algorithm for determining SPT using wrist-worn devices, an
approach that was subsequently validated by Plekhanova and her
team\textsuperscript{\protect\hyperlink{ref-plekhanova_validation_2023}{172}}.
When combined with other methods, this algorithm enables the estimation
of additional sleep quality metrics based on the identified SPT. Van
Hees et al.~reported favorable results with low mean differences when
compared to self-reported measures and PSG for SPT, a finding later
corroborated by Plekhanova et al.~However, both studies also highlighted
challenges in achieving good agreement on metrics such as LPS and WASO,
revealing low reliability with PSG. These challenges in accurately
detecting wakefulness during in-bed time are similar to the issues we
encountered in our own study.

In evaluating various sleep quality metrics, our study identified that
LPS consistently exhibited the largest mean error in relation to the
actual time allocated to it. This challenge in accurately classifying
the initial periods of SPT was further corroborated by poor Pearson
correlations between LPS obtained from model predictions and the ZM.
Among all models assessed, the XGBoost model emerged as the most
reliable, yet it overestimated LPS by an average of 26.4 minutes for
models trained on unfiltered ZM predictions. This increased to 28.5 and
34.5 minutes when the training data was 5-minute and 10-minute filtered
ZM predictions, respectively. This discrepancy is not unique to our
study; it is on par with the mean error of 23 minutes in sleep latency
reported by Johansson et
al\textsuperscript{\protect\hyperlink{ref-johansson_development_2023}{84}}.
Johansson and colleagues attribute such inconsistencies to sleep state's
multifaceted and complex physiological nature. Specifically, brief
awakenings or transient sleep episodes may not always result in
detectable thigh movements, complicating their identification and
accurate classification. These observations are consistent with findings
on wrist-worn devices by Conley and
colleagues\textsuperscript{\protect\hyperlink{ref-conley_agreement_2019}{69}},
who reported that correlations between accelerometer data and
polysomnography (PSG) sleep onset latency (equivalent to LPS) varied
greatly across studies. The mean correlation was only 0.2, underscoring
the challenges in leveraging accelerometry alone for estimating LPS.

Moreover, when compared to other models like the Van Hees
algorithm\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{83}},
Oakley
rsc\textsuperscript{\protect\hyperlink{ref-palotti_benchmark_2019}{97}},
and
LSTM-50\textsuperscript{\protect\hyperlink{ref-palotti_benchmark_2019}{97}}
as evaluated in the Patterson et
al.~study\textsuperscript{\protect\hyperlink{ref-patterson_40_2023}{171}},
our XGBoost model displayed narrower LOAs for TST, SE, and WASO.
Interestingly, the LOAs were also narrower when pitted against the
algorithm tailored for thigh-worn devices by Johansson et
al\textsuperscript{\protect\hyperlink{ref-johansson_development_2023}{84}},
albeit not for SPT. Despite these promising facets, it is important to
note that all methods, both from this study and the literature, showcase
wide LOAs. This implies a high level of variability in sleep quality
metrics derived from accelerometry, cautioning against its use as a
stand-alone alternative to EEG-based ZM or PSG for individual-level
sleep assessments. The presence of extreme outliers in our study
appeared to exacerbate the width of LOAs, suggesting that current
methods are better suited for group-level sleep quality metrics. As a
result, there is a pressing need for further refinement to enhance the
reliability and validity of these models for individual sleep
assessments.

In our study, we opted to use the ZM as the reference method for sleep
measurement, as opposed to the generally accepted gold standard, PSG.
While this choice could contribute to the observed discrepancies between
our models and ZM outcomes, we argue that the use of ZM has distinct
advantages. For one, ZM facilitates multiple consecutive nights of
recording in a free-living
environment\textsuperscript{\protect\hyperlink{ref-pedersen_self-administered_2021}{54}},
thereby capturing intra-individual variations in sleep patterns. This is
an aspect often impractical to achieve with PSG. Additionally, the use
of ZM allowed us to incorporate more nights into our study than is
typically possible with PSG-based studies. This is evident when
comparing our data set to the more limited Newcastle dataset, which
consists of only 28
participants\textsuperscript{\protect\hyperlink{ref-hees_novel_2015}{83}}.
Despite its benefits, we found that the raw ZM outputs were not ideally
suited for developing machine learning models, primarily due to a low
signal-to-noise ratio, as indicated in Figure ZM Median
(Figure~\ref{fig-paper3_raw_filt}). The ZM device itself employs certain
filtering processes to mitigate this issue when generating sleep quality
metrics. For example, WASO is determined using contiguous epochs of 3
minutes, and sleep only contributes to sleep quality metrics if 10 out
of 12 minutes are categorized as sleep. To enhance the effectiveness of
our machine learning algorithms, we applied median filters to the raw ZM
predictions, which had a notable impact on the derived sleep quality
metrics. The application of these filters led to several changes.
Specifically, the mean WASO dropped from 39 minutes in the raw
predictions to 30.6 minutes when using a 5-minute median filter, and
further decreased to 22.3 minutes with a 10-minute median filter.
Likewise, TST, SE, and LPS all increased upon the application of the
5-minute and 10-minute median filters. These shifts suggest that the
median filters could potentially reclassify brief instances of
wakefulness as sleep, and similarly, eliminate short awakenings. Despite
these alterations, the sleep quality metrics derived from the
median-filtered predictions remained largely consistent with those from
the raw predictions, validating the approach we took in this study.

Our current study offers significant contributions to the field of sleep
estimation methods, particularly in the use of thigh-worn
accelerometers. One of the primary strengths of the research lies in its
ability to distinguish between in-bed awake time and asleep time, as
well as out-of-bed time. This distinction is crucial for extracting
essential sleep quality metrics. Additionally, by evaluating multiple
nights per subject, the study offers valuable insights into
intra-subject sleep variability, another important factor for sleep
assessment. However, there are limitations to our approach. Most
notably, we utilized the ZM as our reference method, which is not
considered the gold standard for sleep measurement. This choice might
have impacted the validity of our findings. For future work, it would be
beneficial to employ PSG as a reference, despite its own set of
limitations, to provide a more accurate comparison and to easier extend
to comparisons of other studies utilizing PSG as the gold standard.
Another limitation is the lack of external validation for our models,
which confines the applicability of our findings primarily to the
children studied.

\hypertarget{overall-conclusions}{%
\section{Overall Conclusions}\label{overall-conclusions}}

\hypertarget{conclusions}{%
\subsection{Conclusions}\label{conclusions}}

In summing up, our study demonstrates that the use of Audacity for
manually annotating in-bed periods based on thigh- and hip-worn
accelerometer data aligns well with objective EEG-based sleep device
estimates and prospective sleep diaries. Our findings reveal minimal
mean bias and acceptable limits of agreement when comparing time to bed
and time out of bed across these different methods. Additionally, the
manual annotation process proved highly reliable, exhibiting excellent
inter- and intra-rater agreement. Its accuracy in relation to EEG-based
assessments was also comparable to that of sleep diaries. Importantly,
the manual annotation method can be applied to pre-existing raw data
that may not have accompanying sleep records. This offers a significant
advantage for making better use of free-living data resources. The
increased availability of such annotated data can be particularly
beneficial when training data-intensive machine learning algorithms,
potentially enhancing their generalizability in objectively assessing
human behavior. \#\#\# Conclusions

In terms of model performance, we tested a variety of machine learning
and deep learning models to predict in-bed and sleep times as well as
corresponding sleep quality metrics. The sequential models performed
particularly well in predicting in-bed time, although they encountered
difficulties in accurately discerning sleep from wake epochs during that
period. Among all the models evaluated, the XGBoost model stood out for
its superior performance in epoch-to-epoch predictions and sleep quality
metrics.The study also brings attention to the existing limitations of
current sleep detection methods. Specifically, there are challenges in
effectively identifying wake periods during in-bed time, and
improvements are needed to enhance the accuracy of individual sleep
assessments. Overall, we believe our work serves as a foundational step
for future research aimed at refining these models. The ultimate goal is
to offer a more precise and accurate evaluation of sleep patterns and
quality through the use of thigh-worn accelerometers. \#\#\# Conclusions

In this study, we examine the effectiveness and generalizability of both
existing techniques and our newly-developed decision tree models for
classifying non-wear periods in accelerometer data collected in
free-living conditions. While current heuristic methods offer promising
results, they come with inherent limitations. On the other hand, our
findings suggest that some of the newer, more complex machine learning
methods may be prone to overfitting. The quality and quantity of data
are pivotal factors in training a machine learning model, especially for
a straightforward binary classification problem like this, where the aim
is to make the model generalizable to different datasets. To mitigate
over-optimistic projections about a model's performance on unseen data,
we strongly recommend the use of external validation. Additionally,
given the importance of accurately detecting non-wear time as the
initial step in analyzing accelerometer data, we urge researchers to
carefully choose an appropriate method for this critical task.

\hypertarget{thesis-perspectives}{%
\chapter{Thesis Perspectives}\label{thesis-perspectives}}

The importance of sleep health and the limitations of conventional PSG
examinations have highlighted the potential of wearable sensor systems
as complementary measurement methods. In the previous sections of this
thesis, it has been shown that accelerometers as a platform for
long-term activity monitoring can be used to assess quantitative and
qualitative aspects of sleep. Specifically, the findings of this thesis
offer a deep dive into the methods and tools employed in the manual
annotation of in-bed periods, the classification of non-wear periods in
accelerometer data, and the application of various machine learning
models to detect sleep.

The findings regarding in-bed period annotations using Audacity, based
on thigh- and hip-worn accelerometer data, showcased notable alignment
with EEG-based sleep devices and sleep diaries. The approach exhibited
minimal bias, high reliability, and favorable inter-rater agreement.
Particularly, the methodology's adaptability to pre-existing raw data
without sleep records stands out, paving the way for leveraging
free-living data sources. This accessible annotated data holds promise
for honing machine learning algorithms in assessing human behaviors.

In assessing non-wear period classification in accelerometer data, we
assessed established techniques with our novel decision tree models.
Traditional methods, though effective, have their constraints. Notably,
some advanced machine learning models risked overfitting. The integrity
and volume of data remain central to machine learning efficacy,
emphasizing the need for a balanced model generalizable across various
datasets. To ensure pragmatic outcomes, we champion external validation
and underscore the imperative of method precision for initial non-wear
time detection.

Evaluating various models for predicting in-bed and sleep times,
sequential models emerged as adept in predicting in-bed times but
faltered in distinguishing sleep from wake periods. Notably, the XGBoost
model excelled in its predictive capabilities and sleep quality
assessments. Yet, challenges persist in current sleep detection methods,
especially pinpointing wake intervals during in-bed time. Our efforts
underline an urgent need for refining these detection models to achieve
nuanced evaluations of sleep patterns using thigh-worn accelerometers.

Regarding the objectives set in the beginning of the thesis, it can be
stated that:

\begin{itemize}
\item
  A method was successfully introduced for the manual annotation of
  individual bedtime and wake-up times employing raw, unprocessed
  accelerometry data. The annotations' accuracy was validated,
  demonstrating alignment when compared with results from a
  single-channel EEG-based sleep staging system and a conventional sleep
  diary. Both inter-rater and intra-rater reliability evaluations were
  conducted, reinforcing the robustness and consistency of the manual
  annotation approach.
\item
  Decision tree models were effectively evaluated, using data from both
  thigh and hip-worn accelerometers to discern non-wear time in
  accelerometry data. The role of surface skin temperature in this
  context was identified as an important predictor of non-wear. A
  comprehensive comparison was undertaken between machine-learned models
  and heuristic algorithms, analyzing datasets obtained from
  accelerometers positioned on the hip, thigh, and wrist. This
  comparison facilitated a deeper understanding of each method's
  efficacy across different wearable placements.
\item
  A rigorous assessment was conducted on a range of machine learning and
  deep learning models with the intent of estimating in-bed and sleep
  time. All the models included in this analysis were benchmarked
  against an EEG-based sleep tracking monitor to ensure accuracy and
  reliability. The models developed were evaluated for their capability
  to quantify important sleep quality metrics. This evaluation was once
  again benchmarked against the EEG-based sleep tracking device,
  ensuring a robust validation process.
\end{itemize}

\hypertarget{code-availability}{%
\chapter{Code Availability}\label{code-availability}}

All code associated with Paper II, used for data processing and
analysis, and for producing figures, tables, and results, is available
at \url{https://github.com/esbenlykke/nonwear_project}. This specific
codebase requires substantial refactoring and commenting to adhere to
best coding practices. However, upon request, the corresponding author
can assist in utilizing the code if needed.

For Paper III, all code used for data processing, analysis, figure and
table generation, results production, and manuscript pdf document
creation is available at
\url{https://github.com/esbenlykke/sleep_study}. This codebase largely
adheres to good coding practices and should be deployable `out of the
box', provided all necessary dependencies are installed. To facilitate
this, I plan to provide a conda/mamba environment description in the
repository to encompass all required dependencies. Note that the
repository currently contains some redundant scripts; however, I intend
to streamline the content in the future. Additionally, plans are
underway to introduce a Snakemake file to automate the entire process.

I've also developed a tool based on the findings from Paper III. This
tool leverages the best-performing models (specifically, the XGBoost
models trained on 5-minute median-filtered ZM sleep predictions) and is
available at \url{https://github.com/esbenlykke/get_sleep_stats}. When
given the path to a folder with .wav or .cwa raw accelerometer files,
the tool first extracts all relevant features from the raw data. It then
predicts and extracts in-bed periods. Lastly, it predicts sleep time
based on the extracted in-bed periods. The final output includes
timestamps for going to bed and leaving bed, SPT, TST, and SE for each
accelerometer recording.

No code is available for Paper I.

\hypertarget{references}{%
\chapter{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{0}{0}
\leavevmode\vadjust pre{\hypertarget{ref-kraus_physical_2019}{}}%
\CSLLeftMargin{1. }%
\CSLRightInline{Kraus, W. E. \emph{et al.} Physical activity, all-cause
and cardiovascular mortality, and cardiovascular disease. \emph{Med Sci
Sports Exerc} \textbf{51}, 1270--1281 (2019)
doi:\href{https://doi.org/10.1249/MSS.0000000000001939}{10.1249/MSS.0000000000001939}.}

\leavevmode\vadjust pre{\hypertarget{ref-lee_effect_2012}{}}%
\CSLLeftMargin{2. }%
\CSLRightInline{Lee, I.-M. \emph{et al.} Effect of physical inactivity
on major non-communicable diseases worldwide: An analysis of burden of
disease and life expectancy. \emph{Lancet} \textbf{380}, 219--229 (2012)
doi:\href{https://doi.org/10.1016/S0140-6736(12)61031-9}{10.1016/S0140-6736(12)61031-9}.}

\leavevmode\vadjust pre{\hypertarget{ref-wilmot_sedentary_2012}{}}%
\CSLLeftMargin{3. }%
\CSLRightInline{Wilmot, E. G. \emph{et al.} Sedentary time in adults and
the association with diabetes, cardiovascular disease and death:
Systematic review and meta-analysis. \emph{Diabetologia} \textbf{55},
2895--2905 (2012) URL: \url{https://doi.org/10.1007/s00125-012-2677-z}
Accessed 5 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-cappuccio_sleep_2010}{}}%
\CSLLeftMargin{4. }%
\CSLRightInline{Cappuccio, F. P., D'Elia, L., Strazzullo, P. \& Miller,
M. A. Sleep duration and all-cause mortality: A systematic review and
meta-analysis of prospective studies. \emph{Sleep} \textbf{33}, 585--592
(2010)
doi:\href{https://doi.org/10.1093/sleep/33.5.585}{10.1093/sleep/33.5.585}.}

\leavevmode\vadjust pre{\hypertarget{ref-jennum_suxf8vn_sundhed_2015}{}}%
\CSLLeftMargin{5. }%
\CSLRightInline{Jennum, P. \emph{et al.} Søvn og sundhed \textbar{}
Vidensråd for Forebyggelse. URL:
\url{https://vidensraad.dk/rapport/soevn-og-sundhed}.}

\leavevmode\vadjust pre{\hypertarget{ref-kl_physical_2018}{}}%
\CSLLeftMargin{6. }%
\CSLRightInline{Kl, P. \emph{et al.} The physical activity guidelines
for americans. \emph{{JAMA}} \textbf{320}, (2018) URL:
\url{https://pubmed.ncbi.nlm.nih.gov/30418471/} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-el-zine_fysisk_nodate-1}{}}%
\CSLLeftMargin{7. }%
\CSLRightInline{El-Zine, H. Fysisk aktivitet for voksne (18-64 år).}

\leavevmode\vadjust pre{\hypertarget{ref-el-zine_fysisk_nodate}{}}%
\CSLLeftMargin{8. }%
\CSLRightInline{El-Zine, H. Fysisk aktivitet for børn og unge (5-17
år).}

\leavevmode\vadjust pre{\hypertarget{ref-hirshkowitz_2015}{}}%
\CSLLeftMargin{9. }%
\CSLRightInline{Hirshkowitz, M. \emph{et al.} National Sleep
Foundation's sleep time duration recommendations: methodology and
results summary. \emph{Sleep Health} \textbf{1}, 40--43 (2015)
doi:\href{https://doi.org/10.1016/j.sleh.2014.12.010}{10.1016/j.sleh.2014.12.010}.}

\leavevmode\vadjust pre{\hypertarget{ref-biddle_physical_2011}{}}%
\CSLLeftMargin{10. }%
\CSLRightInline{Biddle, S. J. H. \& Asare, M. Physical activity and
mental health in children and adolescents: A review of reviews. \emph{Br
J Sports Med} \textbf{45}, 886--895 (2011)
doi:\href{https://doi.org/10.1136/bjsports-2011-090185}{10.1136/bjsports-2011-090185}.}

\leavevmode\vadjust pre{\hypertarget{ref-warburton_health_2017}{}}%
\CSLLeftMargin{11. }%
\CSLRightInline{Warburton, D. E. R. \& Bredin, S. S. D. Health benefits
of physical activity: A systematic review of current systematic reviews.
\emph{Curr Opin Cardiol} \textbf{32}, 541--556 (2017)
doi:\href{https://doi.org/10.1097/HCO.0000000000000437}{10.1097/HCO.0000000000000437}.}

\leavevmode\vadjust pre{\hypertarget{ref-strath_guide_2013}{}}%
\CSLLeftMargin{12. }%
\CSLRightInline{Strath, S. J. \emph{et al.} Guide to the assessment of
physical activity: Clinical and research applications: A scientific
statement from the american heart association. \emph{Circulation}
\textbf{128}, 2259--2279 (2013)
doi:\href{https://doi.org/10.1161/01.cir.0000435708.67487.da}{10.1161/01.cir.0000435708.67487.da}.}

\leavevmode\vadjust pre{\hypertarget{ref-arem_leisure_2015}{}}%
\CSLLeftMargin{13. }%
\CSLRightInline{Arem, H. \emph{et al.} Leisure time physical activity
and mortality: A detailed pooled analysis of the dose-response
relationship. \emph{{JAMA} Intern Med} \textbf{175}, 959--967 (2015)
doi:\href{https://doi.org/10.1001/jamainternmed.2015.0533}{10.1001/jamainternmed.2015.0533}.}

\leavevmode\vadjust pre{\hypertarget{ref-rollo_whole_2020}{}}%
\CSLLeftMargin{14. }%
\CSLRightInline{Rollo, S., Antsygina, O. \& Tremblay, M. S. The whole
day matters: Understanding 24-hour movement guideline adherence and
relationships with health indicators across the lifespan. \emph{Journal
of Sport and Health Science} \textbf{9}, 493--510 (2020) URL:
\url{https://www.sciencedirect.com/science/article/pii/S2095254620300910}
Accessed 5 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-ma_sleep_2017}{}}%
\CSLLeftMargin{15. }%
\CSLRightInline{Ma, G. Sleep, health, and society. \emph{Sleep medicine
clinics} \textbf{12}, (2017) URL:
\url{https://pubmed.ncbi.nlm.nih.gov/28159089/} Accessed 26 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-worley_2018}{}}%
\CSLLeftMargin{16. }%
\CSLRightInline{Worley, S. L. The Extraordinary Importance of Sleep: The
Detrimental Effects of Inadequate Sleep on Health and Public Safety
Drive an Explosion of Sleep Research. \emph{P \& T: A Peer-Reviewed
Journal for Formulary Management} \textbf{43}, 758--763 (2018).}

\leavevmode\vadjust pre{\hypertarget{ref-matricciani_2019}{}}%
\CSLLeftMargin{17. }%
\CSLRightInline{Matricciani, L., Paquet, C., Galland, B., Short, M. \&
Olds, T. Children's sleep and health: A meta-review. \emph{Sleep
Medicine Reviews} \textbf{46}, 136--150 (2019) URL:
\url{https://www.sciencedirect.com/science/article/pii/S1087079219300188}.}

\leavevmode\vadjust pre{\hypertarget{ref-scott_2021}{}}%
\CSLLeftMargin{18. }%
\CSLRightInline{Scott, A. J., Webb, T. L., Martyn-St James, M., Rowse,
G. \& Weich, S. Improving sleep quality leads to better mental health: A
meta-analysis of randomised controlled trials. \emph{Sleep Medicine
Reviews} \textbf{60}, 101556 (2021) URL:
\url{https://www.sciencedirect.com/science/article/pii/S1087079221001416}.}

\leavevmode\vadjust pre{\hypertarget{ref-consensus_conference_panel_recommended_2015}{}}%
\CSLLeftMargin{19. }%
\CSLRightInline{Consensus Conference Panel \emph{et al.} Recommended
amount of sleep for a healthy adult: A joint consensus statement of the
american academy of sleep medicine and sleep research society. \emph{J
Clin Sleep Med} \textbf{11}, 591--592 (2015)
doi:\href{https://doi.org/10.5664/jcsm.4758}{10.5664/jcsm.4758}.}

\leavevmode\vadjust pre{\hypertarget{ref-ji_2020}{}}%
\CSLLeftMargin{20. }%
\CSLRightInline{Ji, A. \emph{et al.} Interactive effect of sleep
duration and sleep quality on risk of stroke: An 8-year follow-up study
in China. \emph{Scientific Reports} \textbf{10}, 8690 (2020) URL:
\url{https://www.nature.com/articles/s41598-020-65611-y}.}

\leavevmode\vadjust pre{\hypertarget{ref-hale_2020}{}}%
\CSLLeftMargin{21. }%
\CSLRightInline{Hale, L., Troxel, W. \& Buysse, D. J. Sleep Health: An
Opportunity for Public Health to Address Health Equity. \emph{Annual
Review of Public Health} \textbf{41}, 81--99 (2020)
doi:\href{https://doi.org/10.1146/annurev-publhealth-040119-094412}{10.1146/annurev-publhealth-040119-094412}.}

\leavevmode\vadjust pre{\hypertarget{ref-shochat_2014}{}}%
\CSLLeftMargin{22. }%
\CSLRightInline{Shochat, T., Cohen-Zion, M. \& Tzischinsky, O.
Functional consequences of inadequate sleep in adolescents: a systematic
review. \emph{Sleep Medicine Reviews} \textbf{18}, 75--87 (2014)
doi:\href{https://doi.org/10.1016/j.smrv.2013.03.005}{10.1016/j.smrv.2013.03.005}.}

\leavevmode\vadjust pre{\hypertarget{ref-kecklund_2016}{}}%
\CSLLeftMargin{23. }%
\CSLRightInline{Kecklund, G. \& Axelsson, J. Health consequences of
shift work and insufficient sleep. \emph{BMJ (Clinical research ed.)}
\textbf{355}, i5210 (2016)
doi:\href{https://doi.org/10.1136/bmj.i5210}{10.1136/bmj.i5210}.}

\leavevmode\vadjust pre{\hypertarget{ref-obrien_2005}{}}%
\CSLLeftMargin{24. }%
\CSLRightInline{O'Brien, E. M. \& Mindell, J. A. Sleep and risk-taking
behavior in adolescents. \emph{Behavioral Sleep Medicine} \textbf{3},
113--133 (2005) URL: \url{https://doi.org/10.1207/s15402010bsm0303_1}.}

\leavevmode\vadjust pre{\hypertarget{ref-bonnet_1985}{}}%
\CSLLeftMargin{25. }%
\CSLRightInline{Bonnet, M. H. Effect of sleep disruption on sleep,
performance, and mood. \emph{Sleep} \textbf{8}, 11--19 (1985) URL:
\url{https://doi.org/10.1093/sleep/8.1.11}.}

\leavevmode\vadjust pre{\hypertarget{ref-connor_2002}{}}%
\CSLLeftMargin{26. }%
\CSLRightInline{Connor, J. \emph{et al.} Driver sleepiness and risk of
serious injury to car occupants: population based case control study.
\emph{BMJ (Clinical research ed.)} \textbf{324}, 1125 (2002)
doi:\href{https://doi.org/10.1136/bmj.324.7346.1125}{10.1136/bmj.324.7346.1125}.}

\leavevmode\vadjust pre{\hypertarget{ref-dewald_2010}{}}%
\CSLLeftMargin{27. }%
\CSLRightInline{Dewald, J. F., Meijer, A. M., Oort, F. J., Kerkhof, G.
A. \& Bögels, S. M. The influence of sleep quality, sleep duration and
sleepiness on school performance in children and adolescents: A
meta-analytic review. \emph{Sleep Medicine Reviews} \textbf{14},
179--189 (2010)
doi:\href{https://doi.org/10.1016/j.smrv.2009.10.004}{10.1016/j.smrv.2009.10.004}.}

\leavevmode\vadjust pre{\hypertarget{ref-roth_1996}{}}%
\CSLLeftMargin{28. }%
\CSLRightInline{Roth, T. \& Roehrs, T. A. Etiologies and sequelae of
excessive daytime sleepiness. \emph{Clinical Therapeutics} \textbf{18},
562--576 (1996) URL:
\url{https://www.sciencedirect.com/science/article/pii/S0149291896802074}.}

\leavevmode\vadjust pre{\hypertarget{ref-wang_2019}{}}%
\CSLLeftMargin{29. }%
\CSLRightInline{Wang, H. \emph{et al.} Genome-wide association analysis
of self-reported daytime sleepiness identifies 42 loci that suggest
biological subtypes. \emph{Nature Communications} \textbf{10}, 3503
(2019)
doi:\href{https://doi.org/10.1038/s41467-019-11456-7}{10.1038/s41467-019-11456-7}.}

\leavevmode\vadjust pre{\hypertarget{ref-reutrakul_2018}{}}%
\CSLLeftMargin{30. }%
\CSLRightInline{Reutrakul, S. \& Van Cauter, E. Sleep influences on
obesity, insulin resistance, and risk of type 2 diabetes.
\emph{Metabolism: Clinical and Experimental} \textbf{84}, 56--66 (2018)
doi:\href{https://doi.org/10.1016/j.metabol.2018.02.010}{10.1016/j.metabol.2018.02.010}.}

\leavevmode\vadjust pre{\hypertarget{ref-jouxe3o_2018}{}}%
\CSLLeftMargin{31. }%
\CSLRightInline{João, K. A. D. R., Jesus, S. N. de, Carmo, C. \& Pinto,
P. The impact of sleep quality on the mental health of a non-clinical
population. \emph{Sleep Medicine} \textbf{46}, 69--73 (2018)
doi:\href{https://doi.org/10.1016/j.sleep.2018.02.010}{10.1016/j.sleep.2018.02.010}.}

\leavevmode\vadjust pre{\hypertarget{ref-roebuck_2014}{}}%
\CSLLeftMargin{32. }%
\CSLRightInline{Roebuck, A. \emph{et al.} A review of signals used in
sleep analysis. \emph{Physiological measurement} \textbf{35}, R1--57
(2014) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4024062/}.}

\leavevmode\vadjust pre{\hypertarget{ref-stamatakis_2010}{}}%
\CSLLeftMargin{33. }%
\CSLRightInline{Stamatakis, K. A. \& Punjabi, N. M. Effects of sleep
fragmentation on glucose metabolism in normal subjects. \emph{Chest}
\textbf{137}, 95--101 (2010) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2803120/}.}

\leavevmode\vadjust pre{\hypertarget{ref-herzog_2013}{}}%
\CSLLeftMargin{34. }%
\CSLRightInline{Herzog, N. \emph{et al.} Selective slow wave sleep but
not rapid eye movement sleep suppression impairs morning glucose
tolerance in healthy men. \emph{Psychoneuroendocrinology} \textbf{38},
2075--2082 (2013)
doi:\href{https://doi.org/10.1016/j.psyneuen.2013.03.018}{10.1016/j.psyneuen.2013.03.018}.}

\leavevmode\vadjust pre{\hypertarget{ref-cappuccio_2011}{}}%
\CSLLeftMargin{35. }%
\CSLRightInline{Cappuccio, F. P., Cooper, D., D'Elia, L., Strazzullo, P.
\& Miller, M. A. Sleep duration predicts cardiovascular outcomes: a
systematic review and meta-analysis of prospective studies.
\emph{European Heart Journal} \textbf{32}, 1484--1492 (2011)
doi:\href{https://doi.org/10.1093/eurheartj/ehr007}{10.1093/eurheartj/ehr007}.}

\leavevmode\vadjust pre{\hypertarget{ref-cappuccio_2008}{}}%
\CSLLeftMargin{36. }%
\CSLRightInline{Cappuccio, F. P. \emph{et al.} Meta-analysis of short
sleep duration and obesity in children and adults. \emph{Sleep}
\textbf{31}, 619--626 (2008)
doi:\href{https://doi.org/10.1093/sleep/31.5.619}{10.1093/sleep/31.5.619}.}

\leavevmode\vadjust pre{\hypertarget{ref-banks_2007}{}}%
\CSLLeftMargin{37. }%
\CSLRightInline{Banks, S. \& Dinges, D. F. Behavioral and physiological
consequences of sleep restriction. \emph{Journal of Clinical Sleep
Medicine : JCSM : official publication of the American Academy of Sleep
Medicine} \textbf{3}, 519--528 (2007) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1978335/}.}

\leavevmode\vadjust pre{\hypertarget{ref-vancauter_2008}{}}%
\CSLLeftMargin{38. }%
\CSLRightInline{Van Cauter, E., Spiegel, K., Tasali, E. \& Leproult, R.
Metabolic consequences of sleep and sleep loss. \emph{Sleep medicine}
\textbf{9}, S23--S28 (2008) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4444051/}.}

\leavevmode\vadjust pre{\hypertarget{ref-buysse_2014}{}}%
\CSLLeftMargin{39. }%
\CSLRightInline{Buysse, D. J. Sleep health: Can we define it? Does it
matter? \emph{Sleep} \textbf{37}, 9--17 (2014) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3902880/}.}

\leavevmode\vadjust pre{\hypertarget{ref-basnet_2016}{}}%
\CSLLeftMargin{40. }%
\CSLRightInline{Basnet, S. \emph{et al.} Associations of common chronic
non-communicable diseases and medical conditions with sleep-related
problems in a population-based health examination study. \emph{Sleep
Science} \textbf{9}, 249--254 (2016) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5241609/}.}

\leavevmode\vadjust pre{\hypertarget{ref-aserinsky_1953}{}}%
\CSLLeftMargin{41. }%
\CSLRightInline{Aserinsky, E. \& Kleitman, N. Regularly occurring
periods of eye motility, and concomitant phenomena, during sleep.
\emph{Science (New York, N.Y.)} \textbf{118}, 273--274 (1953)
doi:\href{https://doi.org/10.1126/science.118.3062.273}{10.1126/science.118.3062.273}.}

\leavevmode\vadjust pre{\hypertarget{ref-sadeh_2015}{}}%
\CSLLeftMargin{42. }%
\CSLRightInline{Sadeh, A. Iii. Sleep Assessment Methods.
\emph{Monographs of the Society for Research in Child Development}
\textbf{80}, 33--48 (2015) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/mono.12143}.}

\leavevmode\vadjust pre{\hypertarget{ref-ibuxe1uxf1ez_2018}{}}%
\CSLLeftMargin{43. }%
\CSLRightInline{Ibáñez, V., Silva, J. \& Cauli, O. A survey on sleep
assessment methods. \emph{PeerJ} \textbf{6}, e4849 (2018)
doi:\href{https://doi.org/10.7717/peerj.4849}{10.7717/peerj.4849}.}

\leavevmode\vadjust pre{\hypertarget{ref-girschik_validation_2012}{}}%
\CSLLeftMargin{44. }%
\CSLRightInline{Girschik, J., Fritschi, L., Heyworth, J. \& Waters, F.
Validation of self-reported sleep against actigraphy. \emph{J Epidemiol}
\textbf{22}, 462--468 (2012)
doi:\href{https://doi.org/10.2188/jea.je20120012}{10.2188/jea.je20120012}.}

\leavevmode\vadjust pre{\hypertarget{ref-levendowski_2017}{}}%
\CSLLeftMargin{45. }%
\CSLRightInline{Levendowski, D. J. \emph{et al.} The Accuracy,
Night-to-Night Variability, and Stability of Frontopolar Sleep
Electroencephalography Biomarkers. \emph{Journal of clinical sleep
medicine: JCSM: official publication of the American Academy of Sleep
Medicine} \textbf{13}, 791--803 (2017)
doi:\href{https://doi.org/10.5664/jcsm.6618}{10.5664/jcsm.6618}.}

\leavevmode\vadjust pre{\hypertarget{ref-redline_2013}{}}%
\CSLLeftMargin{46. }%
\CSLRightInline{Redline, S., Dean, D. \& Sanders, M. H. Entering the era
of {``}big data{''}: Getting our metrics right. \emph{Sleep}
\textbf{36}, 465--469 (2013) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3612262/}.}

\leavevmode\vadjust pre{\hypertarget{ref-berthomier_2013}{}}%
\CSLLeftMargin{47. }%
\CSLRightInline{Berthomier, C. \& Brandewinder, M. Sleep scoring: man
vs. machine? \emph{Sleep and Breathing} \textbf{17}, 461--462 (2013)
URL: \url{https://doi.org/10.1007/s11325-012-0715-1}.}

\leavevmode\vadjust pre{\hypertarget{ref-malhotra_2013}{}}%
\CSLLeftMargin{48. }%
\CSLRightInline{A, M. \emph{et al.} Performance of an automated
polysomnography scoring system versus computer-assisted manual scoring.
\emph{Sleep} \textbf{36}, (2013) URL:
\url{https://pubmed.ncbi.nlm.nih.gov/23565003/}.}

\leavevmode\vadjust pre{\hypertarget{ref-koley_2012}{}}%
\CSLLeftMargin{49. }%
\CSLRightInline{Koley, B. \& Dey, D. An ensemble system for automatic
sleep stage classification using single channel EEG signal.
\emph{Computers in Biology and Medicine} \textbf{42}, 1186--1195 (2012)
URL:
\url{https://www.sciencedirect.com/science/article/pii/S0010482512001588}.}

\leavevmode\vadjust pre{\hypertarget{ref-fraiwan_2012}{}}%
\CSLLeftMargin{50. }%
\CSLRightInline{Fraiwan, L., Lweesy, K., Khasawneh, N., Wenz, H. \&
Dickhaus, H. Automated sleep stage identification system based on
time{\textendash}frequency analysis of a single EEG channel and random
forest classifier. \emph{Computer Methods and Programs in Biomedicine}
\textbf{108}, 10--19 (2012) URL:
\url{https://www.sciencedirect.com/science/article/pii/S0169260711003105}.}

\leavevmode\vadjust pre{\hypertarget{ref-zhu_2014}{}}%
\CSLLeftMargin{51. }%
\CSLRightInline{Zhu, G., Li, Y. \& Wen, P. P. Analysis and
classification of sleep stages based on difference visibility graphs
from a single-channel EEG signal. \emph{IEEE journal of biomedical and
health informatics} \textbf{18}, 1813--1821 (2014)
doi:\href{https://doi.org/10.1109/JBHI.2014.2303991}{10.1109/JBHI.2014.2303991}.}

\leavevmode\vadjust pre{\hypertarget{ref-kaplan_performance_2014}{}}%
\CSLLeftMargin{52. }%
\CSLRightInline{Kaplan, R. F., Wang, Y., Loparo, K. A., Kelly, M. R. \&
Bootzin, R. R. Performance evaluation of an automated single-channel
sleep--wake detection algorithm. \emph{Nat Sci Sleep} \textbf{6},
113--122 (2014) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4206400/} Accessed 13
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-wang_evaluation_2015}{}}%
\CSLLeftMargin{53. }%
\CSLRightInline{Wang, Y., Loparo, K. A., Kelly, M. R. \& Kaplan, R. F.
Evaluation of an automated single-channel sleep staging algorithm.
\emph{Nat Sci Sleep} \textbf{7}, 101--111 (2015) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4583116/} Accessed 13
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-pedersen_self-administered_2021}{}}%
\CSLLeftMargin{54. }%
\CSLRightInline{Pedersen, J., Rasmussen, M. G. B., Olesen, L. G.,
Kristensen, P. L. \& Grøntved, A. Self-administered
electroencephalography-based sleep assessment: Compliance and perceived
feasibility in children and adults. \emph{Sleep Science and Practice}
\textbf{5}, 8 (2021) URL:
\url{https://doi.org/10.1186/s41606-021-00059-1} Accessed 22 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-silva_2011}{}}%
\CSLLeftMargin{55. }%
\CSLRightInline{Silva, G. E., Vana, K. D., Goodwin, J. L., Sherrill, D.
L. \& Quan, S. F. Identification of patients with sleep disordered
breathing: Comparing the four-variable screening tool, STOP, STOP-bang,
and epworth sleepiness scales. \emph{Journal of Clinical Sleep Medicine}
\textbf{07}, 467--472 (2011) URL:
\url{https://jcsm.aasm.org/doi/10.5664/JCSM.1308}.}

\leavevmode\vadjust pre{\hypertarget{ref-el-sayed_2012}{}}%
\CSLLeftMargin{56. }%
\CSLRightInline{El-Sayed, I. H. Comparison of four sleep questionnaires
for screening obstructive sleep apnea. \emph{Egyptian Journal of Chest
Diseases and Tuberculosis} \textbf{61}, 433--441 (2012) URL:
\url{https://www.sciencedirect.com/science/article/pii/S0422763812000453}.}

\leavevmode\vadjust pre{\hypertarget{ref-firat_2012}{}}%
\CSLLeftMargin{57. }%
\CSLRightInline{Firat, H., Yuceege, M., Demir, A. \& Ardic, S.
Comparison of four established questionnaires to identify highway bus
drivers at risk for obstructive sleep apnea in Turkey. \emph{Sleep and
Biological Rhythms} \textbf{10}, 231--236 (2012) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1479-8425.2012.00566.x}.}

\leavevmode\vadjust pre{\hypertarget{ref-luo_2014}{}}%
\CSLLeftMargin{58. }%
\CSLRightInline{Luo, J., Huang, R., Zhong, X., Xiao, Y. \& Zhou, J.
STOP-Bang questionnaire is superior to Epworth sleepiness scales, Berlin
questionnaire, and STOP questionnaire in screening obstructive sleep
apnea hypopnea syndrome patients. \emph{Chinese Medical Journal}
\textbf{127}, 3065--3070 (2014).}

\leavevmode\vadjust pre{\hypertarget{ref-pataka_2014}{}}%
\CSLLeftMargin{59. }%
\CSLRightInline{Pataka, A., Daskalopoulou, E., Kalamaras, G., Fekete
Passa, K. \& Argyropoulou, P. Evaluation of five different
questionnaires for assessing sleep apnea syndrome in a sleep clinic.
\emph{Sleep Medicine} \textbf{15}, 776--781 (2014) URL:
\url{https://www.sciencedirect.com/science/article/pii/S1389945714001476}.}

\leavevmode\vadjust pre{\hypertarget{ref-chasens_2009}{}}%
\CSLLeftMargin{60. }%
\CSLRightInline{Chasens, E. R., Ratcliffe, S. J. \& Weaver, T. E.
Development of the FOSQ-10: A short version of the functional outcomes
of sleep questionnaire. \emph{Sleep} \textbf{32}, 915--919 (2009) URL:
\url{https://doi.org/10.1093/sleep/32.7.915}.}

\leavevmode\vadjust pre{\hypertarget{ref-lauderdale_2008}{}}%
\CSLLeftMargin{61. }%
\CSLRightInline{Lauderdale, D. S., Knutson, K. L., Yan, L. L., Liu, K.
\& Rathouz, P. J. Sleep duration: How well do self-reports reflect
objective measures? The CARDIA sleep study. \emph{Epidemiology
(Cambridge, Mass.)} \textbf{19}, 838--845 (2008) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2785092/}.}

\leavevmode\vadjust pre{\hypertarget{ref-thurman_2018}{}}%
\CSLLeftMargin{62. }%
\CSLRightInline{Thurman, S. M. \emph{et al.} Individual differences in
compliance and agreement for sleep logs and wrist actigraphy: A
longitudinal study of naturalistic sleep in healthy adults. \emph{PloS
One} \textbf{13}, e0191883 (2018)
doi:\href{https://doi.org/10.1371/journal.pone.0191883}{10.1371/journal.pone.0191883}.}

\leavevmode\vadjust pre{\hypertarget{ref-migueles_accelerometer_2017}{}}%
\CSLLeftMargin{63. }%
\CSLRightInline{Migueles, J. H. \emph{et al.} Accelerometer data
collection and processing criteria to assess physical activity and other
outcomes: A systematic review and practical considerations. \emph{Sports
Med} \textbf{47}, 1821--1845 (2017) URL:
\url{https://doi.org/10.1007/s40279-017-0716-0} Accessed 12 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-heesch_2018}{}}%
\CSLLeftMargin{64. }%
\CSLRightInline{Heesch, K. C., Hill, R. L., Aguilar-Farias, N., Uffelen,
J. G. Z. van \& Pavey, T. Validity of objective methods for measuring
sedentary behaviour in older adults: a systematic review. \emph{The
International Journal of Behavioral Nutrition and Physical Activity}
\textbf{15}, 119 (2018)
doi:\href{https://doi.org/10.1186/s12966-018-0749-2}{10.1186/s12966-018-0749-2}.}

\leavevmode\vadjust pre{\hypertarget{ref-skotte_detection_2014}{}}%
\CSLLeftMargin{65. }%
\CSLRightInline{Skotte, J., Korshøj, M., Kristiansen, J., Hanisch, C. \&
Holtermann, A. Detection of physical activity types using triaxial
accelerometers. \emph{Journal of Physical Activity and Health}
\textbf{11}, 76--84 (2014) URL:
\url{https://journals.humankinetics.com/view/journals/jpah/11/1/article-p76.xml}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-bruxf8nd_2020}{}}%
\CSLLeftMargin{66. }%
\CSLRightInline{Brønd, J. C., Grøntved, A., Andersen, L. B., Arvidsson,
D. \& Olesen, L. G. Simple Method for the Objective Activity Type
Assessment with Preschoolers, Children and Adolescents. \emph{Children
(Basel, Switzerland)} \textbf{7}, 72 (2020)
doi:\href{https://doi.org/10.3390/children7070072}{10.3390/children7070072}.}

\leavevmode\vadjust pre{\hypertarget{ref-arvidsson_re-examination_2019}{}}%
\CSLLeftMargin{67. }%
\CSLRightInline{Arvidsson, D. \emph{et al.} Re-examination of
accelerometer data processing and calibration for the assessment of
physical activity intensity. \emph{Scand J Med Sci Sports} \textbf{29},
1442--1452 (2019)
doi:\href{https://doi.org/10.1111/sms.13470}{10.1111/sms.13470}.}

\leavevmode\vadjust pre{\hypertarget{ref-chen_2005}{}}%
\CSLLeftMargin{68. }%
\CSLRightInline{Chen, K. Y. \& Bassett, D. R. The technology of
accelerometry-based activity monitors: current and future.
\emph{Medicine and Science in Sports and Exercise} \textbf{37},
S490--500 (2005)
doi:\href{https://doi.org/10.1249/01.mss.0000185571.49104.82}{10.1249/01.mss.0000185571.49104.82}.}

\leavevmode\vadjust pre{\hypertarget{ref-conley_agreement_2019}{}}%
\CSLLeftMargin{69. }%
\CSLRightInline{Conley, S. \emph{et al.} Agreement between actigraphic
and polysomnographic measures of sleep in adults with and without
chronic conditions: A systematic review and meta-analysis. \emph{Sleep
Medicine Reviews} \textbf{46}, 151--160 (2019) URL:
\url{https://www.sciencedirect.com/science/article/pii/S108707921930019X}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-meredith-jones_2016}{}}%
\CSLLeftMargin{70. }%
\CSLRightInline{Meredith-Jones, K., Williams, S., Galland, B., Kennedy,
G. \& Taylor, R. 24 h Accelerometry: impact of sleep-screening methods
on estimates of sedentary behaviour and physical activity while awake.
\emph{Journal of Sports Sciences} \textbf{34}, 679--685 (2016)
doi:\href{https://doi.org/10.1080/02640414.2015.1068438}{10.1080/02640414.2015.1068438}.}

\leavevmode\vadjust pre{\hypertarget{ref-tudor-locke_2012}{}}%
\CSLLeftMargin{71. }%
\CSLRightInline{Tudor-Locke, C., Camhi, S. M. \& Troiano, R. P. A
catalog of rules, variables, and definitions applied to accelerometer
data in the National Health and Nutrition Examination Survey, 2003-2006.
\emph{Preventing Chronic Disease} \textbf{9}, E113 (2012)
doi:\href{https://doi.org/10.5888/pcd9.110332}{10.5888/pcd9.110332}.}

\leavevmode\vadjust pre{\hypertarget{ref-sadeh_activity-based_1994}{}}%
\CSLLeftMargin{72. }%
\CSLRightInline{Sadeh, A., Sharkey, K. M. \& Carskadon, M. A.
Activity-based sleep-wake identification: An empirical test of
methodological issues. \emph{Sleep} \textbf{17}, 201--207 (1994)
doi:\href{https://doi.org/10.1093/sleep/17.3.201}{10.1093/sleep/17.3.201}.}

\leavevmode\vadjust pre{\hypertarget{ref-cole_automatic_1992}{}}%
\CSLLeftMargin{73. }%
\CSLRightInline{Cole, R. J., Kripke, D. F., Gruen, W., Mullaney, D. J.
\& Gillin, J. C. Automatic sleep/wake identification from wrist
activity. \emph{Sleep} \textbf{15}, 461--469 (1992)
doi:\href{https://doi.org/10.1093/sleep/15.5.461}{10.1093/sleep/15.5.461}.}

\leavevmode\vadjust pre{\hypertarget{ref-hjorth_measure_2012}{}}%
\CSLLeftMargin{74. }%
\CSLRightInline{Hjorth, M. F. \emph{et al.} Measure of sleep and
physical activity by a single accelerometer: Can a waist-worn actigraph
adequately measure sleep in children? \emph{Sleep and Biological
Rhythms} \textbf{10}, 328--335 (2012) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1479-8425.2012.00578.x}
Accessed 20 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-tilmanne_2009}{}}%
\CSLLeftMargin{75. }%
\CSLRightInline{Tilmanne, J., Urbain, J., Kothare, M. V., Wouwer, A. V.
\& Kothare, S. V. Algorithms for sleep-wake identification using
actigraphy: a comparative study and new results. \emph{Journal of Sleep
Research} \textbf{18}, 85--98 (2009)
doi:\href{https://doi.org/10.1111/j.1365-2869.2008.00706.x}{10.1111/j.1365-2869.2008.00706.x}.}

\leavevmode\vadjust pre{\hypertarget{ref-desouza_2003}{}}%
\CSLLeftMargin{76. }%
\CSLRightInline{Souza, L. de \emph{et al.} Further validation of
actigraphy for sleep studies. \emph{Sleep} \textbf{26}, 81--85 (2003)
doi:\href{https://doi.org/10.1093/sleep/26.1.81}{10.1093/sleep/26.1.81}.}

\leavevmode\vadjust pre{\hypertarget{ref-littner_2003}{}}%
\CSLLeftMargin{77. }%
\CSLRightInline{Littner, M. \emph{et al.} Practice parameters for the
role of actigraphy in the study of sleep and circadian rhythms: an
update for 2002. \emph{Sleep} \textbf{26}, 337--341 (2003)
doi:\href{https://doi.org/10.1093/sleep/26.3.337}{10.1093/sleep/26.3.337}.}

\leavevmode\vadjust pre{\hypertarget{ref-sazonov_activity-based_2004}{}}%
\CSLLeftMargin{78. }%
\CSLRightInline{Sazonov, E., Sazonova, N., Schuckers, S., Neuman, M. \&
CHIME Study Group. Activity-based sleep-wake identification in infants.
\emph{Physiol Meas} \textbf{25}, 1291--1304 (2004)
doi:\href{https://doi.org/10.1088/0967-3334/25/5/018}{10.1088/0967-3334/25/5/018}.}

\leavevmode\vadjust pre{\hypertarget{ref-granovsky_actigraphy-based_2018}{}}%
\CSLLeftMargin{79. }%
\CSLRightInline{Granovsky, L., Shalev, G., Yacovzada, N.-S., Frank, Y.
\& Fine, S. Actigraphy-based sleep/wake pattern detection using
convolutional neural networks. \emph{{ArXiv}} (2018) URL:
\url{https://www.semanticscholar.org/paper/Actigraphy-based-Sleep-Wake-Pattern-Detection-using-Granovsky-Shalev/3b3043d8816e9caecb3ee2a52597da08c535bb95}
Accessed 21 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-smith_2018}{}}%
\CSLLeftMargin{80. }%
\CSLRightInline{Smith, M. T. \emph{et al.} Use of Actigraphy for the
Evaluation of Sleep Disorders and Circadian Rhythm Sleep-Wake Disorders:
An American Academy of Sleep Medicine Clinical Practice Guideline.
\emph{Journal of clinical sleep medicine: JCSM: official publication of
the American Academy of Sleep Medicine} \textbf{14}, 1231--1237 (2018)
doi:\href{https://doi.org/10.5664/jcsm.7230}{10.5664/jcsm.7230}.}

\leavevmode\vadjust pre{\hypertarget{ref-neishabouri_2022}{}}%
\CSLLeftMargin{81. }%
\CSLRightInline{Neishabouri, A. \emph{et al.} Quantification of
acceleration as activity counts in ActiGraph wearable. \emph{Scientific
Reports} \textbf{12}, 11958 (2022) URL:
\url{https://www.nature.com/articles/s41598-022-16003-x}.}

\leavevmode\vadjust pre{\hypertarget{ref-webster_activity-based_1982}{}}%
\CSLLeftMargin{82. }%
\CSLRightInline{Webster, J. B., Kripke, D. F., Messin, S., Mullaney, D.
J. \& Wyborney, G. An activity-based sleep monitor system for ambulatory
use. \emph{Sleep} \textbf{5}, 389--399 (1982)
doi:\href{https://doi.org/10.1093/sleep/5.4.389}{10.1093/sleep/5.4.389}.}

\leavevmode\vadjust pre{\hypertarget{ref-hees_novel_2015}{}}%
\CSLLeftMargin{83. }%
\CSLRightInline{Hees, V. T. van \emph{et al.} A novel, open access
method to assess sleep duration using a wrist-worn accelerometer.
\emph{{PLOS} {ONE}} \textbf{10}, e0142533 (2015) URL:
\url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0142533}
Accessed 13 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-johansson_development_2023}{}}%
\CSLLeftMargin{84. }%
\CSLRightInline{Johansson, P. J. \emph{et al.} Development and
performance of a sleep estimation algorithm using a single accelerometer
placed on the thigh: An evaluation against polysomnography.
\emph{Journal of Sleep Research} \textbf{32}, e13725 (2023) URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/jsr.13725} Accessed
9 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-hastie01statisticallearning}{}}%
\CSLLeftMargin{85. }%
\CSLRightInline{Hastie, T., Tibshirani, R. \& Friedman, J. \emph{The
elements of statistical learning}. (Springer New York Inc., 2001).}

\leavevmode\vadjust pre{\hypertarget{ref-bishop_2006}{}}%
\CSLLeftMargin{86. }%
\CSLRightInline{Bishop, C. M. \emph{Pattern recognition and machine
learning}. (Springer, 2006).}

\leavevmode\vadjust pre{\hypertarget{ref-Goodfellow-et-al-2016}{}}%
\CSLLeftMargin{87. }%
\CSLRightInline{Goodfellow, I., Bengio, Y. \& Courville, A. \emph{Deep
learning}. (MIT Press, 2016).}

\leavevmode\vadjust pre{\hypertarget{ref-sutton_1998}{}}%
\CSLLeftMargin{88. }%
\CSLRightInline{Sutton, R. S. \& Barto, A. G. \emph{Reinforcement
learning: an introduction}. (MIT Press, 1998).}

\leavevmode\vadjust pre{\hypertarget{ref-kutner_2005}{}}%
\CSLLeftMargin{89. }%
\CSLRightInline{\emph{Applied linear statistical models}. (McGraw-Hill
Irwin, 2005).}

\leavevmode\vadjust pre{\hypertarget{ref-cortes_1995}{}}%
\CSLLeftMargin{90. }%
\CSLRightInline{Cortes, C. \& Vapnik, V. Support-vector networks.
\emph{Machine Learning} \textbf{20}, 273--297 (1995) URL:
\url{https://doi.org/10.1007/BF00994018}.}

\leavevmode\vadjust pre{\hypertarget{ref-macqueen_1967}{}}%
\CSLLeftMargin{91. }%
\CSLRightInline{MacQueen, J. Some methods for classification and
analysis of multivariate observations. in vol. 5.1 281--298 (University
of California Press, 1967). URL:
\url{https://projecteuclid.org/ebooks/berkeley-symposium-on-mathematical-statistics-and-probability/Proceedings-of-the-Fifth-Berkeley-Symposium-on-Mathematical-Statistics-and/chapter/Some-methods-for-classification-and-analysis-of-multivariate-observations/bsmsp/1200512992}.}

\leavevmode\vadjust pre{\hypertarget{ref-McCullagh_1989}{}}%
\CSLLeftMargin{92. }%
\CSLRightInline{McCullagh, P. \& Nelder, J. A. \emph{Generalized linear
models}. (Chapman \& Hall / CRC, 1989).}

\leavevmode\vadjust pre{\hypertarget{ref-quinlan_1986}{}}%
\CSLLeftMargin{93. }%
\CSLRightInline{Quinlan, J. R. Induction of decision trees.
\emph{Machine Learning} \textbf{1}, 81--106 (1986) URL:
\url{https://doi.org/10.1007/BF00116251}.}

\leavevmode\vadjust pre{\hypertarget{ref-Chen_xgboost_2016}{}}%
\CSLLeftMargin{94. }%
\CSLRightInline{Chen, T. \& Guestrin, C. {XGBoost}: A scalable tree
boosting system. in \emph{Proceedings of the 22nd ACM SIGKDD
international conference on knowledge discovery and data mining}
785--794 (ACM, 2016). URL:
\url{http://doi.acm.org/10.1145/2939672.2939785}.}

\leavevmode\vadjust pre{\hypertarget{ref-graves_2005}{}}%
\CSLLeftMargin{95. }%
\CSLRightInline{Graves, A. \& Schmidhuber, J. International Joint
Conference on Neural Networks 2005. in vol. 4 2047--2052 (IEEE, 2005).
URL: \url{http://ieeexplore.ieee.org/document/1556215/}.}

\leavevmode\vadjust pre{\hypertarget{ref-paruthi_consensus_2016}{}}%
\CSLLeftMargin{96. }%
\CSLRightInline{Paruthi, S. \emph{et al.} Consensus statement of the
american academy of sleep medicine on the recommended amount of sleep
for healthy children: Methodology and discussion. \emph{J Clin Sleep
Med} \textbf{12}, 1549--1561 (2016)
doi:\href{https://doi.org/10.5664/jcsm.6288}{10.5664/jcsm.6288}.}

\leavevmode\vadjust pre{\hypertarget{ref-palotti_benchmark_2019}{}}%
\CSLLeftMargin{97. }%
\CSLRightInline{Palotti, J. \emph{et al.} Benchmark on a large cohort
for sleep-wake classification with machine learning techniques.
\emph{npj Digit. Med.} \textbf{2}, 1--9 (2019) URL:
\url{https://www.nature.com/articles/s41746-019-0126-9} Accessed 12 June
2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-sundararajan_sleep_2021}{}}%
\CSLLeftMargin{98. }%
\CSLRightInline{Sundararajan, K. \emph{et al.} Sleep classification from
wrist-worn accelerometer data using random forests. \emph{Sci Rep}
\textbf{11}, 24 (2021) URL:
\url{https://www.nature.com/articles/s41598-020-79217-x} Accessed 13
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-lutsey_objectively_2015}{}}%
\CSLLeftMargin{99. }%
\CSLRightInline{Lutsey, P. L. \emph{et al.} Objectively measured sleep
characteristics and prevalence of coronary artery calcification: The
multi-ethnic study of atherosclerosis sleep study. \emph{Thorax}
\textbf{70}, 880--887 (2015) URL:
\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4858321/} Accessed 12
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-van_hees_estimating_2018}{}}%
\CSLLeftMargin{100. }%
\CSLRightInline{Hees, V. T. van \emph{et al.} Estimating sleep
parameters using an accelerometer without sleep diary. \emph{Sci Rep}
\textbf{8}, 12975 (2018)
doi:\href{https://doi.org/10.1038/s41598-018-31266-z}{10.1038/s41598-018-31266-z}.}

\leavevmode\vadjust pre{\hypertarget{ref-dowd_systematic_2018}{}}%
\CSLLeftMargin{101. }%
\CSLRightInline{Dowd, K. P. \emph{et al.} A systematic literature review
of reviews on techniques for physical activity measurement in adults: A
{DEDIPAC} study. \emph{International Journal of Behavioral Nutrition and
Physical Activity} \textbf{15}, 15 (2018) URL:
\url{https://doi.org/10.1186/s12966-017-0636-2} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-loyen_sedentary_2017}{}}%
\CSLLeftMargin{102. }%
\CSLRightInline{Loyen, A. \emph{et al.} Sedentary time and physical
activity surveillance through accelerometer pooling in four european
countries. \emph{Sports Med} \textbf{47}, 1421--1435 (2017)
doi:\href{https://doi.org/10.1007/s40279-016-0658-y}{10.1007/s40279-016-0658-y}.}

\leavevmode\vadjust pre{\hypertarget{ref-montoye_raw_2018}{}}%
\CSLLeftMargin{103. }%
\CSLRightInline{Montoye, A. H. K. \emph{et al.} Raw and count data
comparability of hip-worn {ActiGraph} {GT}3X+ and link accelerometers.
\emph{Med Sci Sports Exerc} \textbf{50}, 1103--1112 (2018)
doi:\href{https://doi.org/10.1249/MSS.0000000000001534}{10.1249/MSS.0000000000001534}.}

\leavevmode\vadjust pre{\hypertarget{ref-migueles_comparability_2019}{}}%
\CSLLeftMargin{104. }%
\CSLRightInline{Migueles, J. H. \emph{et al.} Comparability of
accelerometer signal aggregation metrics across placements and dominant
wrist cut points for the assessment of physical activity in adults.
\emph{Sci Rep} \textbf{9}, 18235 (2019) URL:
\url{https://www.nature.com/articles/s41598-019-54267-y} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-lee_missing_2018}{}}%
\CSLLeftMargin{105. }%
\CSLRightInline{Lee, J. A. \& Gill, J. Missing value imputation for
physical activity data measured by accelerometer. \emph{Stat Methods Med
Res} \textbf{27}, 490--506 (2018)
doi:\href{https://doi.org/10.1177/0962280216633248}{10.1177/0962280216633248}.}

\leavevmode\vadjust pre{\hypertarget{ref-ainsworth_recommendations_2012}{}}%
\CSLLeftMargin{106. }%
\CSLRightInline{Ainsworth, B. E. \emph{et al.} Recommendations to
improve the accuracy of estimates of physical activity derived from self
report. \emph{J Phys Act Health} \textbf{9 Suppl 1}, S76--84 (2012)
doi:\href{https://doi.org/10.1123/jpah.9.s1.s76}{10.1123/jpah.9.s1.s76}.}

\leavevmode\vadjust pre{\hypertarget{ref-hecht_methodology_2009}{}}%
\CSLLeftMargin{107. }%
\CSLRightInline{Hecht, A., Ma, S., Porszasz, J., Casaburi, R. \& COPD
Clinical Research Network. Methodology for using long-term accelerometry
monitoring to describe daily activity patterns in {COPD}. \emph{{COPD}}
\textbf{6}, 121--129 (2009)
doi:\href{https://doi.org/10.1080/15412550902755044}{10.1080/15412550902755044}.}

\leavevmode\vadjust pre{\hypertarget{ref-ruiz_objectively_2011}{}}%
\CSLLeftMargin{108. }%
\CSLRightInline{Ruiz, J. R. \emph{et al.} Objectively measured physical
activity and sedentary time in european adolescents: The {HELENA} study.
\emph{Am J Epidemiol} \textbf{174}, 173--184 (2011)
doi:\href{https://doi.org/10.1093/aje/kwr068}{10.1093/aje/kwr068}.}

\leavevmode\vadjust pre{\hypertarget{ref-troiano_how_2020}{}}%
\CSLLeftMargin{109. }%
\CSLRightInline{Troiano, R. P., Stamatakis, E. \& Bull, F. C. How can
global physical activity surveillance adapt to evolving physical
activity guidelines? Needs, challenges and future directions. \emph{Br J
Sports Med} \textbf{54}, 1468--1473 (2020) URL:
\url{https://bjsm.bmj.com/content/54/24/1468} Accessed 12 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-aadland_comparison_2018}{}}%
\CSLLeftMargin{110. }%
\CSLRightInline{Aadland, E., Andersen, L. B., Anderssen, S. A. \&
Resaland, G. K. A comparison of 10 accelerometer non-wear time criteria
and logbooks in children. \emph{{BMC} Public Health} \textbf{18}, 323
(2018) URL: \url{https://doi.org/10.1186/s12889-018-5212-4} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-toftager_accelerometer_2013}{}}%
\CSLLeftMargin{111. }%
\CSLRightInline{Toftager, M. \emph{et al.} Accelerometer data reduction
in adolescents: Effects on sample retention and bias.
\emph{International Journal of Behavioral Nutrition and Physical
Activity} \textbf{10}, 140 (2013) URL:
\url{https://doi.org/10.1186/1479-5868-10-140} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-duncan_wear-time_2018}{}}%
\CSLLeftMargin{112. }%
\CSLRightInline{Duncan, S. \emph{et al.} Wear-time compliance with a
dual-accelerometer system for capturing 24-h behavioural profiles in
children and adults. \emph{Int J Environ Res Public Health} \textbf{15},
1296 (2018)
doi:\href{https://doi.org/10.3390/ijerph15071296}{10.3390/ijerph15071296}.}

\leavevmode\vadjust pre{\hypertarget{ref-rasmussen_short-term_2020}{}}%
\CSLLeftMargin{113. }%
\CSLRightInline{Rasmussen, M. G. B. \emph{et al.} Short-term efficacy of
reducing screen media use on physical activity, sleep, and physiological
stress in families with children aged 4--14: Study protocol for the
{SCREENS} randomized controlled trial. \emph{{BMC} Public Health}
\textbf{20}, 380 (2020) URL:
\url{https://doi.org/10.1186/s12889-020-8458-6} Accessed 12 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-zhou_classification_2015}{}}%
\CSLLeftMargin{114. }%
\CSLRightInline{Zhou, S.-M. \emph{et al.} Classification of
accelerometer wear and non-wear events in seconds for monitoring
free-living physical activity. \emph{{BMJ} Open} \textbf{5}, e007447
(2015) URL: \url{https://bmjopen.bmj.com/content/5/5/e007447} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-syed_novel_2021}{}}%
\CSLLeftMargin{115. }%
\CSLRightInline{Syed, S., Morseth, B., Hopstock, L. A. \& Horsch, A. A
novel algorithm to detect non-wear time from raw accelerometer data
using deep convolutional neural networks. \emph{Sci Rep} \textbf{11},
8832 (2021) URL:
\url{https://www.nature.com/articles/s41598-021-87757-z} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-carlson_validity_2021}{}}%
\CSLLeftMargin{116. }%
\CSLRightInline{Carlson, J. A. \emph{et al.} Validity of two awake
wear-time classification algorithms for {activPAL} in youth, adults, and
older adults. \emph{Journal for the Measurement of Physical Behaviour}
\textbf{4}, 151--162 (2021) URL:
\url{https://journals.humankinetics.com/view/journals/jmpb/4/2/article-p151.xml}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-inan-eroglu_comparison_2021}{}}%
\CSLLeftMargin{117. }%
\CSLRightInline{Inan-Eroglu, E. \emph{et al.} Comparison of a thigh-worn
accelerometer algorithm with diary estimates of time in bed and time
asleep: The 1970 british cohort study. \emph{Journal for the Measurement
of Physical Behaviour} \textbf{4}, 60--67 (2021) URL:
\url{https://journals.humankinetics.com/view/journals/jmpb/4/1/article-p60.xml}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-van_der_berg_identifying_2016}{}}%
\CSLLeftMargin{118. }%
\CSLRightInline{Berg, J. D. van der \emph{et al.} Identifying waking
time in 24-h accelerometry data in adults using an automated algorithm.
\emph{Journal of Sports Sciences} \textbf{34}, 1867--1873 (2016) URL:
\url{https://doi.org/10.1080/02640414.2016.1140908} Accessed 12 June
2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-winkler_identifying_2016}{}}%
\CSLLeftMargin{119. }%
\CSLRightInline{Winkler, E. A. H. \emph{et al.} Identifying adults'
valid waking wear time by automated estimation in {activPAL} data
collected with a 24 h wear protocol. \emph{Physiol. Meas.} \textbf{37},
1653 (2016) URL: \url{https://dx.doi.org/10.1088/0967-3334/37/10/1653}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-doherty_large_2017}{}}%
\CSLLeftMargin{120. }%
\CSLRightInline{Doherty, A. \emph{et al.} Large scale population
assessment of physical activity using wrist worn accelerometers: The
{UK} biobank study. \emph{{PLOS} {ONE}} \textbf{12}, e0169649 (2017)
URL:
\url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0169649}
Accessed 12 July 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-dasilva_2014}{}}%
\CSLLeftMargin{121. }%
\CSLRightInline{Silva, I. C. da \emph{et al.} Physical activity levels
in three Brazilian birth cohorts as assessed with raw triaxial wrist
accelerometry. \emph{International Journal of Epidemiology} \textbf{43},
1959--1968 (2014)
doi:\href{https://doi.org/10.1093/ije/dyu203}{10.1093/ije/dyu203}.}

\leavevmode\vadjust pre{\hypertarget{ref-anderson_assessment_2014}{}}%
\CSLLeftMargin{122. }%
\CSLRightInline{Anderson, K. N. \emph{et al.} Assessment of sleep and
circadian rhythm disorders in the very old: The newcastle 85+ cohort
study. \emph{Age and Ageing} \textbf{43}, 57--63 (2014) URL:
\url{https://doi.org/10.1093/ageing/aft153} Accessed 12 July 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-lockley_1999}{}}%
\CSLLeftMargin{123. }%
\CSLRightInline{Lockley, S. W., Skene, D. J. \& Arendt, J. Comparison
between subjective and actigraphic measurement of sleep and sleep
rhythms. \emph{Journal of Sleep Research} \textbf{8}, 175--183 (1999)
URL:
\url{https://onlinelibrary.wiley.com/doi/abs/10.1046/j.1365-2869.1999.00155.x}.}

\leavevmode\vadjust pre{\hypertarget{ref-skovgaard_manual_2021}{}}%
\CSLLeftMargin{124. }%
\CSLRightInline{Skovgaard, E. L., Pedersen, J., Møller, N. C., Grøntved,
A. \& Brønd, J. C. Manual annotation of time in bed using free-living
recordings of accelerometry data. \emph{Sensors (Basel)} \textbf{21},
8442 (2021)
doi:\href{https://doi.org/10.3390/s21248442}{10.3390/s21248442}.}

\leavevmode\vadjust pre{\hypertarget{ref-rasmussen_feasibility_2021}{}}%
\CSLLeftMargin{125. }%
\CSLRightInline{Rasmussen, M. G. B. \emph{et al.} Feasibility of two
screen media reduction interventions: Results from the {SCREENS} pilot
trial. \emph{{PLOS} {ONE}} \textbf{16}, e0259657 (2021) URL:
\url{https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0259657}
Accessed 12 June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-jaeschke_variability_2018}{}}%
\CSLLeftMargin{126. }%
\CSLRightInline{Jaeschke, L., Steinbrecher, A., Jeran, S., Konigorski,
S. \& Pischon, T. Variability and reliability study of overall physical
activity and activity intensity levels using 24~h-accelerometry-assessed
data. \emph{{BMC} Public Health} \textbf{18}, 530 (2018) URL:
\url{https://doi.org/10.1186/s12889-018-5415-8} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-audacity}{}}%
\CSLLeftMargin{127. }%
\CSLRightInline{Audacity Team. Audacity\textregistered{} software is
copyright © 1999--2021 audacity team. (2021).}

\leavevmode\vadjust pre{\hypertarget{ref-visplore}{}}%
\CSLLeftMargin{128. }%
\CSLRightInline{Visplore {\textendash} software for visual time series
analysis. URL: \url{https://visplore.com/home-11-2022/}.}

\leavevmode\vadjust pre{\hypertarget{ref-label_studio}{}}%
\CSLLeftMargin{129. }%
\CSLRightInline{Open Source Data Labeling. URL:
\url{https://labelstud.io/}.}

\leavevmode\vadjust pre{\hypertarget{ref-shrout_1979}{}}%
\CSLLeftMargin{130. }%
\CSLRightInline{Shrout, P. E. \& Fleiss, J. L. Intraclass correlations:
Uses in assessing rater reliability. \emph{Psychological Bulletin}
\textbf{86}, 420--428 (1979)
doi:\href{https://doi.org/10.1037/0033-2909.86.2.420}{10.1037/0033-2909.86.2.420}.}

\leavevmode\vadjust pre{\hypertarget{ref-mcgraw_1996}{}}%
\CSLLeftMargin{131. }%
\CSLRightInline{McGraw, K. O. \& Wong, S. P. Forming inferences about
some intraclass correlation coefficients. \emph{Psychological Methods}
\textbf{1}, 30--46 (1996)
doi:\href{https://doi.org/10.1037/1082-989X.1.1.30}{10.1037/1082-989X.1.1.30}.}

\leavevmode\vadjust pre{\hypertarget{ref-koo_guideline_2016}{}}%
\CSLLeftMargin{132. }%
\CSLRightInline{Koo, T. K. \& Li, M. Y. A guideline of selecting and
reporting intraclass correlation coefficients for reliability research.
\emph{J Chiropr Med} \textbf{15}, 155--163 (2016)
doi:\href{https://doi.org/10.1016/j.jcm.2016.02.012}{10.1016/j.jcm.2016.02.012}.}

\leavevmode\vadjust pre{\hypertarget{ref-bland_measuring_1999}{}}%
\CSLLeftMargin{133. }%
\CSLRightInline{Bland, J. M. \& Altman, D. G. Measuring agreement in
method comparison studies. \emph{Stat Methods Med Res} \textbf{8},
135--160 (1999) URL: \url{https://doi.org/10.1177/096228029900800204}
Accessed 9 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-skovgaard_generalizability_2023}{}}%
\CSLLeftMargin{134. }%
\CSLRightInline{Skovgaard, E. L. \emph{et al.} Generalizability and
performance of methods to detect non-wear with free-living accelerometer
recordings. \emph{Sci Rep} \textbf{13}, 2496 (2023) URL:
\url{https://www.nature.com/articles/s41598-023-29666-x} Accessed 26
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-pedersen_protocol_2018}{}}%
\CSLLeftMargin{135. }%
\CSLRightInline{Pedersen, N. H. \emph{et al.} Protocol for evaluating
the impact of a national school policy on physical activity levels in
danish children and adolescents: The PHASAR study - a natural
experiment. \emph{BMC Public Health} \textbf{18}, 1245 (2018) URL:
\url{https://doi.org/10.1186/s12889-018-6144-8}.}

\leavevmode\vadjust pre{\hypertarget{ref-troiano_physical_2008}{}}%
\CSLLeftMargin{136. }%
\CSLRightInline{Troiano, R. P. \emph{et al.} Physical activity in the
united states measured by accelerometer. \emph{Med Sci Sports Exerc}
\textbf{40}, 181--188 (2008)
doi:\href{https://doi.org/10.1249/mss.0b013e31815a51b3}{10.1249/mss.0b013e31815a51b3}.}

\leavevmode\vadjust pre{\hypertarget{ref-choi_validation_2011}{}}%
\CSLLeftMargin{137. }%
\CSLRightInline{Choi, L., Liu, Z., Matthews, C. E. \& Buchowski, M. S.
Validation of accelerometer wear and nonwear time classification
algorithm. \emph{Med Sci Sports Exerc} \textbf{43}, 357--364 (2011)
doi:\href{https://doi.org/10.1249/MSS.0b013e3181ed61a3}{10.1249/MSS.0b013e3181ed61a3}.}

\leavevmode\vadjust pre{\hypertarget{ref-van_hees_estimation_2011}{}}%
\CSLLeftMargin{138. }%
\CSLRightInline{Hees, V. T. van \emph{et al.} Estimation of daily energy
expenditure in pregnant and non-pregnant women using a wrist-worn
tri-axial accelerometer. \emph{{PLoS} One} \textbf{6}, e22922 (2011)
doi:\href{https://doi.org/10.1371/journal.pone.0022922}{10.1371/journal.pone.0022922}.}

\leavevmode\vadjust pre{\hypertarget{ref-syed_evaluating_2020}{}}%
\CSLLeftMargin{139. }%
\CSLRightInline{Syed, S., Morseth, B., Hopstock, L. A. \& Horsch, A.
Evaluating the performance of raw and epoch non-wear algorithms using
multiple accelerometers and electrocardiogram recordings. \emph{Sci Rep}
\textbf{10}, 5866 (2020) URL:
\url{https://www.nature.com/articles/s41598-020-62821-2} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-kuhn_tidymodels_2020}{}}%
\CSLLeftMargin{140. }%
\CSLRightInline{Kuhn, M. \& Wickham, H. \emph{Tidymodels: A collection
of packages for modeling and machine learning using tidyverse
principles.} (2020). URL: \url{https://www.tidymodels.org}.}

\leavevmode\vadjust pre{\hypertarget{ref-rpart}{}}%
\CSLLeftMargin{141. }%
\CSLRightInline{Therneau, T. \& Atkinson, B. \emph{Rpart: Recursive
partitioning and regression trees}. (2022). URL:
\url{https://CRAN.R-project.org/package=rpart}.}

\leavevmode\vadjust pre{\hypertarget{ref-pedersen_effects_2022}{}}%
\CSLLeftMargin{142. }%
\CSLRightInline{Pedersen, J. \emph{et al.} Effects of Limiting
Recreational Screen Media Use on Physical Activity and Sleep in Families
With Children: A Cluster Randomized Clinical Trial. \emph{JAMA
pediatrics} \textbf{176}, 741--749 (2022)
doi:\href{https://doi.org/10.1001/jamapediatrics.2022.1519}{10.1001/jamapediatrics.2022.1519}.}

\leavevmode\vadjust pre{\hypertarget{ref-walch_sleep_2019}{}}%
\CSLLeftMargin{143. }%
\CSLRightInline{Walch, O., Huang, Y., Forger, D. \& Goldstein, C. Sleep
stage prediction with raw acceleration and photoplethysmography heart
rate data derived from a consumer wearable device. \emph{Sleep}
\textbf{42}, zsz180 (2019) URL:
\url{https://doi.org/10.1093/sleep/zsz180} Accessed 13 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-galland_2018}{}}%
\CSLLeftMargin{144. }%
\CSLRightInline{Galland, B. C. \emph{et al.} Establishing normal values
for pediatric nighttime sleep measured by actigraphy: a systematic
review and meta-analysis. \emph{Sleep} \textbf{41}, (2018)
doi:\href{https://doi.org/10.1093/sleep/zsy017}{10.1093/sleep/zsy017}.}

\leavevmode\vadjust pre{\hypertarget{ref-ohayon_2017}{}}%
\CSLLeftMargin{145. }%
\CSLRightInline{Ohayon, M. \emph{et al.} National Sleep Foundation's
sleep quality recommendations: first report. \emph{Sleep Health}
\textbf{3}, 6--19 (2017)
doi:\href{https://doi.org/10.1016/j.sleh.2016.11.006}{10.1016/j.sleh.2016.11.006}.}

\leavevmode\vadjust pre{\hypertarget{ref-galland_normal_2012}{}}%
\CSLLeftMargin{146. }%
\CSLRightInline{Galland, B. C., Taylor, B. J., Elder, D. E. \& Herbison,
P. Normal sleep patterns in infants and children: A systematic review of
observational studies. \emph{Sleep Med Rev} \textbf{16}, 213--222 (2012)
doi:\href{https://doi.org/10.1016/j.smrv.2011.06.001}{10.1016/j.smrv.2011.06.001}.}

\leavevmode\vadjust pre{\hypertarget{ref-hochreiter_long_1997}{}}%
\CSLLeftMargin{147. }%
\CSLRightInline{Hochreiter, S. \& Schmidhuber, J. Long short-term
memory. \emph{Neural Computation} \textbf{9}, 1735--1780 (1997) URL:
\url{https://doi.org/10.1162/neco.1997.9.8.1735} Accessed 12 June 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-sano_multimodal_2019}{}}%
\CSLLeftMargin{148. }%
\CSLRightInline{Sano, A., Chen, W., Lopez-Martinez, D., Taylor, S. \&
Picard, R. W. Multimodal ambulatory sleep detection using {LSTM}
recurrent neural networks. \emph{{IEEE} J Biomed Health Inform}
\textbf{23}, 1607--1617 (2019)
doi:\href{https://doi.org/10.1109/JBHI.2018.2867619}{10.1109/JBHI.2018.2867619}.}

\leavevmode\vadjust pre{\hypertarget{ref-chen_attention_2021}{}}%
\CSLLeftMargin{149. }%
\CSLRightInline{Chen, Z., Wu, M., Cui, W., Liu, C. \& Li, X. An
attention based {CNN}-{LSTM} approach for sleep-wake detection with
heterogeneous sensors. \emph{{IEEE} J Biomed Health Inform} \textbf{25},
3270--3277 (2021)
doi:\href{https://doi.org/10.1109/JBHI.2020.3006145}{10.1109/JBHI.2020.3006145}.}

\leavevmode\vadjust pre{\hypertarget{ref-friedman_glmnet_2010}{}}%
\CSLLeftMargin{150. }%
\CSLRightInline{Friedman, J., Hastie, T. \& Tibshirani, R.
Regularization Paths for Generalized Linear Models via Coordinate
Descent. \emph{Journal of Statistical Software} \textbf{33}, 1--22
(2010).}

\leavevmode\vadjust pre{\hypertarget{ref-nnet}{}}%
\CSLLeftMargin{151. }%
\CSLRightInline{Venables, W. N. \& Ripley, B. D. \emph{Modern applied
statistics with s}. (Springer, 2002). URL:
\url{https://www.stats.ox.ac.uk/pub/MASS4/}.}

\leavevmode\vadjust pre{\hypertarget{ref-xgboost}{}}%
\CSLLeftMargin{152. }%
\CSLRightInline{Chen, T. \emph{et al.} \emph{Xgboost: Extreme gradient
boosting}. (2023). URL:
\url{https://CRAN.R-project.org/package=xgboost}.}

\leavevmode\vadjust pre{\hypertarget{ref-chawla_smote_2002}{}}%
\CSLLeftMargin{153. }%
\CSLRightInline{Chawla, N. V., Bowyer, K. W., Hall, L. O. \& Kegelmeyer,
W. P. {SMOTE}: Synthetic minority over-sampling technique. \emph{Journal
of Artificial Intelligence Research} \textbf{16}, 321--357 (2002) URL:
\url{https://www.jair.org/index.php/jair/article/view/10302} Accessed 22
June 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-themis}{}}%
\CSLLeftMargin{154. }%
\CSLRightInline{Hvitfeldt, E. \emph{Themis: Extra recipes steps for
dealing with unbalanced data}. (2023). URL:
\url{https://CRAN.R-project.org/package=themis}.}

\leavevmode\vadjust pre{\hypertarget{ref-kushida_comparison_2001}{}}%
\CSLLeftMargin{155. }%
\CSLRightInline{Kushida, C. A. \emph{et al.} Comparison of actigraphic,
polysomnographic, and subjective assessment of sleep parameters in
sleep-disordered patients. \emph{Sleep Med} \textbf{2}, 389--396 (2001)
doi:\href{https://doi.org/10.1016/s1389-9457(00)00098-8}{10.1016/s1389-9457(00)00098-8}.}

\leavevmode\vadjust pre{\hypertarget{ref-rcoreteam_2023}{}}%
\CSLLeftMargin{156. }%
\CSLRightInline{R Core Team. \emph{R: A language and environment for
statistical computing}. (R Foundation for Statistical Computing, 2023).
URL: \url{https://www.R-project.org/}.}

\leavevmode\vadjust pre{\hypertarget{ref-wickham_tidyverse_2019}{}}%
\CSLLeftMargin{157. }%
\CSLRightInline{Wickham, H. \emph{et al.} Welcome to the tidyverse.
\emph{Journal of Open Source Software} \textbf{4}, 1686 (2019)
doi:\href{https://doi.org/10.21105/joss.01686}{10.21105/joss.01686}.}

\leavevmode\vadjust pre{\hypertarget{ref-vanrossum_python_2009}{}}%
\CSLLeftMargin{158. }%
\CSLRightInline{Van Rossum, G. \& Drake, F. L. \emph{Python 3 reference
manual}. (CreateSpace, 2009).}

\leavevmode\vadjust pre{\hypertarget{ref-paszke_pytorch_2019}{}}%
\CSLLeftMargin{159. }%
\CSLRightInline{Paszke, A. \emph{et al.} PyTorch: An imperative style,
high-performance deep learning library. in 80248035 (Curran Associates,
Inc., 2019). URL:
\url{http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}.}

\leavevmode\vadjust pre{\hypertarget{ref-aili_reliability_2017}{}}%
\CSLLeftMargin{160. }%
\CSLRightInline{Aili, K., Åström-Paulsson, S., Stoetzer, U.,
Svartengren, M. \& Hillert, L. Reliability of actigraphy and subjective
sleep measurements in adults: The design of sleep assessments. \emph{J
Clin Sleep Med} \textbf{13}, 39--47 (2017)
doi:\href{https://doi.org/10.5664/jcsm.6384}{10.5664/jcsm.6384}.}

\leavevmode\vadjust pre{\hypertarget{ref-haghayegh_application_2020}{}}%
\CSLLeftMargin{161. }%
\CSLRightInline{Haghayegh, S., Khoshnevis, S., Smolensky, M. H. \&
Diller, K. R. Application of deep learning to improve sleep scoring of
wrist actigraphy. \emph{Sleep Med} \textbf{74}, 235--241 (2020)
doi:\href{https://doi.org/10.1016/j.sleep.2020.05.008}{10.1016/j.sleep.2020.05.008}.}

\leavevmode\vadjust pre{\hypertarget{ref-yavuz-kodat_2019}{}}%
\CSLLeftMargin{162. }%
\CSLRightInline{Yavuz-Kodat, E. \emph{et al.} Validity of Actigraphy
Compared to Polysomnography for Sleep Assessment in Children With Autism
Spectrum Disorder. \emph{Frontiers in Psychiatry} \textbf{10}, 551
(2019)
doi:\href{https://doi.org/10.3389/fpsyt.2019.00551}{10.3389/fpsyt.2019.00551}.}

\leavevmode\vadjust pre{\hypertarget{ref-aasm}{}}%
\CSLLeftMargin{163. }%
\CSLRightInline{AASM scoring manual - american academy of sleep
medicine. URL:
\url{https://aasm.org/clinical-resources/scoring-manual/}.}

\leavevmode\vadjust pre{\hypertarget{ref-hutto_identifying_2013}{}}%
\CSLLeftMargin{164. }%
\CSLRightInline{Hutto, B. \emph{et al.} Identifying accelerometer
nonwear and wear time in older adults. \emph{International Journal of
Behavioral Nutrition and Physical Activity} \textbf{10}, 120 (2013) URL:
\url{https://doi.org/10.1186/1479-5868-10-120} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-cooper_objectively_2015}{}}%
\CSLLeftMargin{165. }%
\CSLRightInline{Cooper, A. R. \emph{et al.} Objectively measured
physical activity and sedentary time in youth: The international
children's accelerometry database ({ICAD}). \emph{International Journal
of Behavioral Nutrition and Physical Activity} \textbf{12}, 113 (2015)
URL: \url{https://doi.org/10.1186/s12966-015-0274-5} Accessed 5 August
2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-kwon_breaks_2012}{}}%
\CSLLeftMargin{166. }%
\CSLRightInline{Kwon, S., Burns, T. L., Levy, S. M. \& Janz, K. F.
Breaks in sedentary time during childhood and adolescence: Iowa bone
development study. \emph{Med Sci Sports Exerc} \textbf{44}, 1075--1080
(2012) URL: \url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3623750/}
Accessed 5 August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-barouni_ambulatory_2020}{}}%
\CSLLeftMargin{167. }%
\CSLRightInline{Barouni, A. \emph{et al.} Ambulatory sleep scoring using
accelerometers-distinguishing between nonwear and sleep/wake states.
\emph{{PeerJ}} \textbf{8}, e8284 (2020)
doi:\href{https://doi.org/10.7717/peerj.8284}{10.7717/peerj.8284}.}

\leavevmode\vadjust pre{\hypertarget{ref-vert_detecting_2022}{}}%
\CSLLeftMargin{168. }%
\CSLRightInline{Vert, A. \emph{et al.} Detecting accelerometer non-wear
periods using change in acceleration combined with rate-of-change in
temperature. \emph{{BMC} Medical Research Methodology} \textbf{22}, 147
(2022) URL: \url{https://doi.org/10.1186/s12874-022-01633-6} Accessed 5
August 2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-steyerberg_prediction_2016}{}}%
\CSLLeftMargin{169. }%
\CSLRightInline{Steyerberg, E. W. \& Harrell, F. E. Prediction models
need appropriate internal, internal-external, and external validation.
\emph{J Clin Epidemiol} \textbf{69}, 245--247 (2016)
doi:\href{https://doi.org/10.1016/j.jclinepi.2015.04.005}{10.1016/j.jclinepi.2015.04.005}.}

\leavevmode\vadjust pre{\hypertarget{ref-altman_prognosis_2009}{}}%
\CSLLeftMargin{170. }%
\CSLRightInline{Altman, D. G., Vergouwe, Y., Royston, P. \& Moons, K. G.
M. Prognosis and prognostic research: Validating a prognostic model.
\emph{{BMJ}} \textbf{338}, b605 (2009) URL:
\url{https://www.bmj.com/content/338/bmj.b605} Accessed 5 August 2023,
2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-patterson_40_2023}{}}%
\CSLLeftMargin{171. }%
\CSLRightInline{Patterson, M. R. \emph{et al.} 40 years of actigraphy in
sleep medicine and current state of the art algorithms. \emph{npj Digit.
Med.} \textbf{6}, 1--7 (2023) URL:
\url{https://www.nature.com/articles/s41746-023-00802-1} Accessed 9 June
2023, 2023:2023.}

\leavevmode\vadjust pre{\hypertarget{ref-plekhanova_validation_2023}{}}%
\CSLLeftMargin{172. }%
\CSLRightInline{Plekhanova, T. \emph{et al.} Validation of an automated
sleep detection algorithm using data from multiple accelerometer brands.
\emph{J Sleep Res} \textbf{32}, e13760 (2023)
doi:\href{https://doi.org/10.1111/jsr.13760}{10.1111/jsr.13760}.}

\end{CSLReferences}

\hypertarget{list-of-appendices}{%
\chapter{List of Appendices}\label{list-of-appendices}}

\begin{itemize}
\item
  \textbf{Appendix I}: Manual Annotation of Time in Bed Using
  Free-Living Recordings of Accelerometry Data
\item
  \textbf{Appendix II}: Generalizability and performance of methods to
  detect non‑wear with free‑living accelerometer recordings
\item
  \textbf{Appendix III}: Improving Sleep Quality Estimation in Children
  and Adolescents: A Comparative Study of Machine Learning and Deep
  Learning Techniques Utilizing Free-Living Accelerometer Data from
  Thigh-Worn Devices and EEG-Based Sleep Tracking
\item
  \textbf{Appendix IV}: Supplementary Material for Paper III
\end{itemize}

\newpage

\begin{center}

\textbf{\textsf{\Huge Appendix I}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix I}

\vspace{2cm}

\textsf{\Huge Manual Annotation of Time in Bed Using Free-Living Accelerometry Data}

\vspace{5cm}

This paper was published in \textbf{Sensors} and is used here under the terms and conditions of the Creative Commons Attribution (CC BY) license (\href{https://creativecommons.org/licenses/by/4.0/}{https://creativecommons.org/licenses/by/4.0/})

\vspace{1cm}

DOI: \href{https://doi.org/10.3390/s21248442}{https://doi.org/10.3390/s21248442}

\end{center}

\includepdf[pages=-]{my_papers/paper1.pdf}

\begin{center}

\textbf{\textsf{\Huge Appendix II}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix II}

\vspace{2cm}

\textsf{\Huge Generalizability and Performance of Methods to Detect Non-Wear With Free-Living Accelerometer Recordings}

\vspace{5cm}

This paper was published in \textbf{Scientific Reports} and is used here under the terms and conditions of the Creative Commons Attribution (CC BY) license (\href{https://creativecommons.org/licenses/by/4.0/}{https://creativecommons.org/licenses/by/4.0/})

\vspace{1cm}

DOI: \href{https://doi.org/10.1038/s41598-023-29666-x}{https://doi.org/10.1038/s41598-023-29666-x}

\end{center}

\includepdf[pages=-]{my_papers/paper2.pdf}

\begin{center}

\textbf{\textsf{\Huge Appendix III}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix III}

\vspace{2cm}

\textsf{\Huge Improving Sleep Quality Estimation in Children and Adolescents: A Comparative Study of Machine Learning and Deep Learning Techniques Utilizing Free-Living Accelerometer Data from Thigh-Worn Devices and EEG-Based Sleep Tracking}

\vspace{5cm}

This manuscript is under preparation for submission to \href{https://academic.oup.com/sleep}{\textbf{SLEEP}}, the official journal of the Sleep Research Society (SRS).

\vspace{1cm}

\end{center}

\includepdf[pages=-]{my_papers/paper3.pdf}

\begin{center}

\textbf{\textsf{\Huge Appendix IV}}

\phantomsection

\addcontentsline{toc}{subsection}{Appendix IV}

\vspace{1cm}

\textsf{\Huge Supplementary Material for Paper III}

\end{center}

\includepdf[pages=-]{paper3_supp.pdf}


\backmatter

\end{document}
